Initialization time: 2025-05-19 12:35:52
wandb: Currently logged in as: maria-i-paiva (maria-i-paiva-inesc-tec) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_101/version_1/wandb/run-20250519_123602-2yxr6mck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_3d_101_1_fold1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maria-i-paiva-inesc-tec/comparative_study_3d_norm
wandb: üöÄ View run at https://wandb.ai/maria-i-paiva-inesc-tec/comparative_study_3d_norm/runs/2yxr6mck
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 14 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 14 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 14 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
wandb:                                                                                
wandb: üöÄ View run vgg16_3d_101_1_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/comparative_study_3d_norm/runs/2yxr6mck
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/maria-i-paiva-inesc-tec/comparative_study_3d_norm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_101/version_1/wandb/run-20250519_123602-2yxr6mck/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_101/version_2/wandb/run-20250519_135235-79btepr0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_3d_101_2_fold1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maria-i-paiva-inesc-tec/comparative_study_3d_norm
wandb: üöÄ View run at https://wandb.ai/maria-i-paiva-inesc-tec/comparative_study_3d_norm/runs/79btepr0
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 14 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 14 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
srun: got SIGCONT
slurmstepd-01.ctm-deep-09: error: *** JOB 4136 ON 01.ctm-deep-09 CANCELLED AT 2025-05-19T14:18:35 ***
srun: forcing job termination
slurmstepd-01.ctm-deep-09: error: *** STEP 4136.0 ON 01.ctm-deep-09 CANCELLED AT 2025-05-19T14:18:35 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.

**************************************************  Experiment 101 | Version 1 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'sct_nod_err']

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'sct_nod_err']
...model pipeline for data fold 1 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_101/version_1/execution_datetimes.json

**************************************************  Experiment 101 | Version 2 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'sct_nod_err']

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'sct_nod_err']
