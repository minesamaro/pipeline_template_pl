Initialization time: 2025-07-01 11:53:16

**************************************************  Experiment 78 | Version 1 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

âœ… Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

âœ… Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 4, 1.0: 12}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 1, 1.0: 1}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {1.0: 2}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 3, 1.0: 13}
    Batch label distribution: {0.0: 1, 1.0: 1}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

âœ… Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

âœ… Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Currently logged in as: maria-i-paiva (maria-i-paiva-inesc-tec) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_115622-x2g4vild
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_1_fold1
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/x2g4vild
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–â–â–â–â–â–â–
wandb:          test_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 test_auroc â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–ƒâ–„â–ƒâ–â–…â–…â–…â–ˆâ–„â–ƒâ–…â–ƒâ–…â–†â–„â–ˆâ–…â–†â–…â–…â–â–ƒâ–‚â–…â–†â–„â–ƒâ–ƒâ–‚â–„â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–…â–„
wandb:                 train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.44608
wandb:                 train_loss 2.0909
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_1_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/x2g4vild
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_115622-x2g4vild/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_121218-dsmi775e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_1_fold2
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/dsmi775e
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–â–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–â–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 test_auroc â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–ˆâ–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–â–â–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–…â–ˆâ–‡â–‡â–†â–…â–†â–†â–…â–‡â–…â–‡â–„â–ƒâ–…â–„â–…â–†â–â–…â–â–„â–„â–„â–…â–…â–‡â–„â–ˆâ–†â–ƒâ–…â–ƒâ–„â–„â–…â–ƒâ–„â–ƒâ–ƒ
wandb:                 train_loss â–ˆâ–‚â–â–‚â–ƒâ–ƒâ–„â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–â–„â–â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–‚â–„â–ƒâ–‚â–„â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–ˆâ–â–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.46387
wandb:                 train_loss 2.09538
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_1_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/dsmi775e
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_121218-dsmi775e/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_123930-32c6c74j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_1_fold3
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/32c6c74j
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–ˆâ–â–â–ˆâ–ˆâ–â–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          test_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 test_auroc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–â–â–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–ƒâ–…â–„â–…â–†â–„â–…â–„â–‡â–ƒâ–†â–‚â–ƒâ–†â–„â–„â–‡â–‡â–…â–†â–…â–ƒâ–‚â–ˆâ–‚â–ˆâ–ƒâ–…â–â–ƒâ–ƒâ–„â–…â–†â–ƒâ–‚â–„â–…â–…â–‚
wandb:                 train_loss â–…â–ƒâ–ƒâ–„â–„â–â–‡â–„â–ƒâ–‡â–„â–„â–ƒâ–„â–†â–ƒâ–ƒâ–„â–ˆâ–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–†â–ƒâ–‡â–â–„â–†â–ƒâ–ƒâ–‚â–ƒâ–„
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–â–ˆâ–ˆâ–â–â–â–â–ˆâ–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–â–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.5245
wandb:                 train_loss 2.09383
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_1_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/32c6c74j
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_123930-32c6c74j/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/execution_datetimes.json

**************************************************  Experiment 78 | Version 2 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

âœ… Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

âœ… Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 8, 1.0: 10}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 20, 1.0: 12}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 12, 1.0: 6}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 12, 1.0: 20}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 9, 1.0: 9}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

âœ… Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

âœ… Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_130121-1q9m1vqw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_2_fold1
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/1q9m1vqw
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–
wandb:          test_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 test_auroc â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–â–â–ˆâ–ˆâ–ˆ
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–†â–ˆâ–†â–‚â–‡â–‚â–ƒâ–…â–â–†â–…â–†â–‚â–ƒâ–‡â–…â–…â–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–‚â–„â–â–‚â–‚â–†â–‚â–‚â–‚â–„â–…â–ƒâ–„â–‡â–„â–ƒâ–ƒ
wandb:                 train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–ˆâ–ˆ
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.52064
wandb:                 train_loss 2.09495
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_2_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/1q9m1vqw
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_130121-1q9m1vqw/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_131739-68muygtk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_2_fold2
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/68muygtk
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆ
wandb:          test_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 test_auroc â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–…â–ƒâ–†â–ƒâ–‡â–ˆâ–‡â–‡â–‡â–…â–ˆâ–„â–†â–†â–ˆâ–…â–„â–…â–„â–„â–…â–ƒâ–†â–…â–‡â–„â–„â–†â–ƒâ–†â–†â–†â–†â–†â–â–…â–…â–ˆâ–‡â–ƒ
wandb:                 train_loss â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–„â–ˆâ–‡â–â–‡â–ƒâ–…â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–†â–†â–‡â–‡
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–â–ˆâ–â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.48408
wandb:                 train_loss 2.09323
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_2_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/68muygtk
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_131739-68muygtk/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_135501-4nms00n1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_2_fold3
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4nms00n1
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          test_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 test_auroc â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–‡â–…â–„â–†â–ƒâ–ƒâ–…â–†â–ˆâ–…â–ƒâ–ƒâ–†â–†â–„â–â–ƒâ–„â–ƒâ–…â–†â–„â–†â–„â–…â–…â–ƒâ–„â–†â–ƒâ–„â–…â–‡â–„â–…â–ƒâ–…â–ƒâ–‡â–…
wandb:                 train_loss â–ƒâ–…â–„â–ƒâ–‚â–ˆâ–…â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–„â–â–â–„â–ƒâ–ƒâ–†â–ƒâ–„â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–„â–ƒâ–…â–ƒ
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–â–â–â–â–â–â–â–ˆâ–â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–„â–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.53257
wandb:                 train_loss 2.09392
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_2_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4nms00n1
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_135501-4nms00n1/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/execution_datetimes.json

**************************************************  Experiment 78 | Version 4 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

âœ… Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

âœ… Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 28, 1.0: 36}
    Batch label distribution: {0.0: 8, 1.0: 10}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 28, 1.0: 36}
    Batch label distribution: {0.0: 12, 1.0: 6}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 39, 1.0: 25}
    Batch label distribution: {0.0: 31, 1.0: 33}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 9, 1.0: 9}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

âœ… Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

âœ… Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_142201-q4m0potr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_4_fold1
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/q4m0potr
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–
wandb:          test_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 test_auroc â–ˆâ–â–ƒâ–†â–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–†â–„â–„â–ƒâ–ƒâ–â–ˆâ–‡â–†â–ƒâ–‡â–†â–†â–…â–†â–ˆâ–†â–ƒâ–ƒâ–‡â–†â–ƒâ–‡â–ƒâ–ˆâ–…â–ˆâ–„â–…â–…â–…â–ˆâ–„â–‚â–„â–†â–ƒâ–„â–„â–…
wandb:                 train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–â–â–â–â–â–â–â–
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–†â–…â–„â–„â–…â–â–…â–†â–†â–…â–†â–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.43369
wandb:                 train_loss 2.09274
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_4_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/q4m0potr
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_142201-q4m0potr/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_144208-dkqr9qcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_4_fold2
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/dkqr9qcx
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 test_auroc â–â–…â–…â–†â–‚â–‚â–‚â–„â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–„â–„â–†â–ˆâ–†â–„â–ƒâ–„â–„â–„â–ƒâ–„â–ƒâ–…â–‚â–ƒâ–„â–„â–…â–ƒâ–‚â–ƒâ–„â–‚â–‚â–â–„â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–†â–ƒâ–„
wandb:                 train_loss â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–„â–‚â–ƒâ–‚â–‚â–‚â–ƒ
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–â–ˆâ–‡â–‡â–ˆâ–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.4843
wandb:                 train_loss 2.09472
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_4_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/dkqr9qcx
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_144208-dkqr9qcx/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_150318-suyo5g0u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_4_fold3
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/suyo5g0u
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           test_accuracy0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          test_accuracy0.75 â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 test_auroc â–â–ˆâ–…â–…â–…â–ˆâ–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: test_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_precision0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train_auroc â–†â–ƒâ–‚â–â–„â–†â–…â–†â–ƒâ–…â–‡â–ƒâ–…â–„â–„â–…â–…â–ƒâ–‡â–…â–†â–ƒâ–‚â–‡â–…â–‡â–†â–…â–†â–„â–‚â–…â–ˆâ–†â–„â–†â–†â–„â–‚â–ƒ
wandb:                 train_loss â–ˆâ–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            val_accuracy0.5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           val_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  val_auroc â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val_balanced_accuracy0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_precision0.5 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.25 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.44371
wandb:                 train_loss 2.0945
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_4_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/suyo5g0u
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_150318-suyo5g0u/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/execution_datetimes.json

**************************************************  Experiment 78 | Version 6 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

âœ… Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

âœ… Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 4, 1.0: 12}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 1, 1.0: 1}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 4, 1.0: 12}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 1, 1.0: 1}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 1, 1.0: 1}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

âœ… Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

âœ… Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_154104-qwvyllgu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_6_fold1
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/qwvyllgu
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–‚â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:           test_accuracy0.5 â–ˆâ–â–‚â–ˆâ–ˆâ–†â–†â–…â–†â–†â–‡â–‡â–‡â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–†â–†â–†â–‡â–‡â–‡â–†â–†â–†
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–†â–ˆâ–‡â–†â–†â–…â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–…
wandb:                 test_auroc â–‚â–„â–‚â–„â–â–‡â–ˆâ–„â–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: test_balanced_accuracy0.25 â–„â–„â–„â–„â–…â–ƒâ–„â–‚â–‚â–â–ƒâ–„â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–†
wandb:  test_balanced_accuracy0.5 â–ˆâ–‚â–„â–„â–â–‡â–‡â–…â–ƒâ–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb: test_balanced_accuracy0.75 â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–ˆâ–„â–‡â–â–…â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:         test_precision0.25 â–â–â–ƒâ–„â–†â–â–‚â–…â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…â–‡â–ˆâ–†â–†â–‡â–…â–‡â–‡â–…â–…
wandb:          test_precision0.5 â–â–…â–†â–‡â–‡â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:         test_precision0.75 â–â–â–â–â–â–â–†â–†â–ˆâ–ƒâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:            test_recall0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–„â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:             test_recall0.5 â–†â–†â–ˆâ–†â–‡â–†â–„â–„â–„â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:            test_recall0.75 â–â–â–â–‚â–â–…â–†â–ˆâ–†â–…â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:                train_auroc â–â–‚â–‚â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–ˆâ–†â–ƒâ–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–‚â–â–‚â–‚â–ˆâ–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:            val_accuracy0.5 â–â–ƒâ–ˆâ–ˆâ–‡â–†â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           val_accuracy0.75 â–ˆâ–†â–â–‡â–‡â–‡â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–†
wandb:                  val_auroc â–â–ˆâ–„â–†â–†â–ƒâ–„â–†â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:  val_balanced_accuracy0.25 â–â–â–â–‚â–â–ƒâ–‚â–†â–„â–†â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:   val_balanced_accuracy0.5 â–â–„â–ƒâ–â–â–„â–ˆâ–‡â–â–†â–ƒâ–†â–‚â–…â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„
wandb:  val_balanced_accuracy0.75 â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–…â–„â–„â–ˆâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:          val_precision0.25 â–â–â–â–â–‚â–„â–â–„â–‚â–â–„â–ˆâ–„â–ƒâ–ƒâ–…â–…â–…â–…â–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:           val_precision0.5 â–†â–â–â–†â–†â–â–†â–…â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:          val_precision0.75 â–â–â–â–â–â–„â–â–…â–â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:             val_recall0.25 â–ˆâ–ˆâ–ˆâ–…â–†â–‚â–…â–ƒâ–…â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–†â–ˆâ–â–â–‡â–‚â–ƒâ–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:             val_recall0.75 â–â–â–â–â–â–„â–†â–…â–†â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.63291
wandb:           test_accuracy0.5 0.64557
wandb:          test_accuracy0.75 0.67089
wandb:                 test_auroc 0.49364
wandb: test_balanced_accuracy0.25 0.53941
wandb:  test_balanced_accuracy0.5 0.51483
wandb: test_balanced_accuracy0.75 0.53178
wandb:         test_precision0.25 0.30435
wandb:          test_precision0.5 0.27778
wandb:         test_precision0.75 0.3125
wandb:            test_recall0.25 0.35
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.25
wandb:                train_auroc 1
wandb:                 train_loss 0.03825
wandb:           val_accuracy0.25 0.64762
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.70476
wandb:                  val_auroc 0.59518
wandb:  val_balanced_accuracy0.25 0.53359
wandb:   val_balanced_accuracy0.5 0.55891
wandb:  val_balanced_accuracy0.75 0.57157
wandb:          val_precision0.25 0.2963
wandb:           val_precision0.5 0.34783
wandb:          val_precision0.75 0.38095
wandb:             val_recall0.25 0.30769
wandb:              val_recall0.5 0.30769
wandb:             val_recall0.75 0.30769
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_6_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/qwvyllgu
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_154104-qwvyllgu/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_161036-n8g0apz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_6_fold2
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/n8g0apz3
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading history steps 214-214, summary, console lines 4-5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–‚â–â–‚â–†â–„â–„â–„â–†â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡
wandb:           test_accuracy0.5 â–ˆâ–â–ƒâ–ˆâ–…â–ƒâ–…â–†â–…â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–â–â–†â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb:                 test_auroc â–ˆâ–ˆâ–â–â–…â–„â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†
wandb: test_balanced_accuracy0.25 â–„â–†â–†â–†â–ƒâ–‡â–‡â–ˆâ–â–…â–„â–…â–„â–ƒâ–‚â–ƒâ–„â–„â–„â–ƒâ–„â–…â–…â–„â–„â–ƒâ–„â–…â–„â–…â–…â–…â–…â–…â–…â–‚â–…â–„â–…â–…
wandb:  test_balanced_accuracy0.5 â–†â–†â–†â–ˆâ–ˆâ–â–‚â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–„â–ƒâ–„
wandb: test_balanced_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–ƒâ–‚â–„â–„â–ƒâ–‚â–‚â–‚â–„â–„â–„â–‚â–„â–„â–„â–„â–„â–„â–„
wandb:         test_precision0.25 â–†â–†â–…â–†â–†â–ˆâ–„â–ƒâ–â–ƒâ–ƒâ–â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–…â–„â–„â–„â–ƒâ–„â–‚â–„â–‚
wandb:          test_precision0.5 â–‡â–ˆâ–â–ƒâ–‡â–†â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–„â–„â–„â–…â–ƒâ–…â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         test_precision0.75 â–â–â–â–â–â–â–â–†â–…â–ƒâ–ˆâ–‡â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–†â–„â–„â–„â–„â–†â–„â–†â–†â–†â–†â–†â–†â–„â–„
wandb:            test_recall0.25 â–ˆâ–ˆâ–ƒâ–…â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:             test_recall0.5 â–â–ˆâ–‡â–‡â–†â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:            test_recall0.75 â–â–â–â–â–â–â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–†â–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–ƒ
wandb:                train_auroc â–â–‚â–„â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–‡â–ˆâ–‡â–‡â–…â–„â–‚â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–ƒâ–ƒâ–„â–„â–„â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡
wandb:            val_accuracy0.5 â–ˆâ–ˆâ–â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–†â–…â–…â–†â–†â–†â–†â–…â–†â–†â–…â–†â–†â–†â–…â–…â–…â–…â–…
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ƒâ–‡â–‡â–„â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒ
wandb:                  val_auroc â–â–‡â–†â–ˆâ–†â–†â–†â–†â–†â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–…â–…â–†â–†â–†â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…
wandb:  val_balanced_accuracy0.25 â–…â–â–…â–ˆâ–‚â–„â–ˆâ–ƒâ–…â–‚â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–…â–…â–…â–„â–„â–„â–…â–…â–„â–…â–„â–…â–„â–„â–…â–„â–„â–…â–„
wandb:   val_balanced_accuracy0.5 â–ƒâ–ƒâ–„â–†â–ˆâ–†â–ƒâ–â–ƒâ–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–ƒ
wandb:  val_balanced_accuracy0.75 â–‡â–„â–‡â–†â–ˆâ–…â–…â–â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†
wandb:          val_precision0.25 â–…â–…â–†â–‡â–ˆâ–„â–…â–‡â–â–â–‡â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–…â–…â–„â–„â–ƒâ–‡â–„â–„â–ˆâ–†â–ƒâ–„â–„â–ˆâ–ˆâ–‡â–ƒâ–†
wandb:           val_precision0.5 â–â–‡â–ˆâ–ˆâ–†â–†â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:          val_precision0.75 â–â–â–â–â–â–â–‡â–„â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:             val_recall0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–„â–…â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–ˆâ–†â–†â–„â–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             val_recall0.75 â–â–â–â–â–â–â–â–ˆâ–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.62025
wandb:           test_accuracy0.5 0.63291
wandb:          test_accuracy0.75 0.63291
wandb:                 test_auroc 0.49322
wandb: test_balanced_accuracy0.25 0.48136
wandb:  test_balanced_accuracy0.5 0.45678
wandb: test_balanced_accuracy0.75 0.44025
wandb:         test_precision0.25 0.22222
wandb:          test_precision0.5 0.15385
wandb:         test_precision0.75 0.09091
wandb:            test_recall0.25 0.2
wandb:             test_recall0.5 0.1
wandb:            test_recall0.75 0.05
wandb:                train_auroc 0.99973
wandb:                 train_loss 0.03434
wandb:           val_accuracy0.25 0.61905
wandb:            val_accuracy0.5 0.6381
wandb:           val_accuracy0.75 0.64762
wandb:                  val_auroc 0.47493
wandb:  val_balanced_accuracy0.25 0.4888
wandb:   val_balanced_accuracy0.5 0.50146
wandb:  val_balanced_accuracy0.75 0.50779
wandb:          val_precision0.25 0.23077
wandb:           val_precision0.5 0.25
wandb:          val_precision0.75 0.26087
wandb:             val_recall0.25 0.23077
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.23077
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_6_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/n8g0apz3
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_161036-n8g0apz3/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_163840-67lminf8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_6_fold3
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/67lminf8
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           test_accuracy0.5 â–â–‡â–‡â–…â–‡â–ˆâ–†â–…â–†â–†â–†â–…â–…â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–…â–…â–â–„â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                 test_auroc â–â–‚â–â–ˆâ–‡â–ƒâ–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…
wandb: test_balanced_accuracy0.25 â–‡â–‡â–‡â–‡â–ˆâ–ƒâ–†â–„â–…â–†â–†â–â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:  test_balanced_accuracy0.5 â–‡â–†â–‚â–ˆâ–„â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: test_balanced_accuracy0.75 â–…â–…â–ˆâ–…â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.25 â–…â–…â–†â–ˆâ–…â–ƒâ–…â–‚â–„â–„â–„â–„â–„â–„â–„â–ƒâ–â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:          test_precision0.5 â–„â–…â–ˆâ–„â–ˆâ–…â–…â–…â–„â–‡â–„â–ƒâ–ƒâ–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.75 â–â–‡â–ˆâ–â–‡â–†â–‡â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:            test_recall0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–ˆâ–‚â–‚â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.75 â–â–ˆâ–â–â–…â–‡â–‚â–…â–ˆâ–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:                train_auroc â–â–‚â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–†â–…â–…â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–†â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:            val_accuracy0.5 â–ˆâ–ˆâ–â–‚â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:           val_accuracy0.75 â–‡â–‡â–‡â–‡â–‡â–â–ˆâ–ˆâ–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                  val_auroc â–â–ƒâ–â–„â–…â–†â–…â–†â–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:  val_balanced_accuracy0.25 â–â–â–ƒâ–‚â–…â–…â–…â–„â–„â–ˆâ–‡â–„â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:   val_balanced_accuracy0.5 â–ƒâ–ƒâ–ƒâ–ˆâ–…â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–‚â–„â–‚â–ˆâ–„â–…â–…â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:          val_precision0.25 â–â–â–â–â–‚â–…â–…â–ˆâ–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:           val_precision0.5 â–â–†â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:          val_precision0.75 â–â–â–â–…â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:             val_recall0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–â–ˆâ–‡â–‡â–ˆâ–„â–ƒâ–ƒâ–‡â–…â–„â–ƒâ–„â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:             val_recall0.75 â–â–â–â–â–â–ˆâ–‡â–‡â–‡â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.58228
wandb:           test_accuracy0.5 0.58228
wandb:          test_accuracy0.75 0.59494
wandb:                 test_auroc 0.54068
wandb: test_balanced_accuracy0.25 0.45593
wandb:  test_balanced_accuracy0.5 0.43941
wandb: test_balanced_accuracy0.75 0.44788
wandb:         test_precision0.25 0.19048
wandb:          test_precision0.5 0.15789
wandb:         test_precision0.75 0.16667
wandb:            test_recall0.25 0.2
wandb:             test_recall0.5 0.15
wandb:            test_recall0.75 0.15
wandb:                train_auroc 1.0
wandb:                 train_loss 1e-05
wandb:           val_accuracy0.25 0.67619
wandb:            val_accuracy0.5 0.66667
wandb:           val_accuracy0.75 0.66667
wandb:                  val_auroc 0.62634
wandb:  val_balanced_accuracy0.25 0.56548
wandb:   val_balanced_accuracy0.5 0.54625
wandb:  val_balanced_accuracy0.75 0.53335
wandb:          val_precision0.25 0.34615
wandb:           val_precision0.5 0.32
wandb:          val_precision0.75 0.30435
wandb:             val_recall0.25 0.34615
wandb:              val_recall0.5 0.30769
wandb:             val_recall0.75 0.26923
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_6_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/67lminf8
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_163840-67lminf8/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/execution_datetimes.json

**************************************************  Experiment 78 | Version 7 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

âœ… Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

âœ… Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 12, 1.0: 20}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 11, 1.0: 7}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 12, 1.0: 20}
    Batch label distribution: {0.0: 20, 1.0: 12}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 10, 1.0: 8}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 6, 1.0: 26}
    Batch label distribution: {0.0: 12, 1.0: 20}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 8, 1.0: 10}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

âœ… Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

âœ… Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_165921-4ayj65le
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_7_fold1
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4ayj65le
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–…â–…â–‚â–„â–†â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           test_accuracy0.5 â–‚â–„â–‚â–â–ˆâ–ƒâ–‚â–„â–„â–„â–…â–…â–„â–ƒâ–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ƒâ–…â–â–ƒâ–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„
wandb:                 test_auroc â–…â–†â–‡â–†â–â–…â–ˆâ–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb: test_balanced_accuracy0.25 â–…â–…â–…â–…â–…â–…â–…â–â–‚â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  test_balanced_accuracy0.5 â–‡â–†â–†â–„â–…â–„â–†â–ƒâ–â–†â–…â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: test_balanced_accuracy0.75 â–†â–†â–†â–ƒâ–â–‚â–†â–ˆâ–…â–†â–…â–…â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†
wandb:         test_precision0.25 â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–„â–â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–†â–‡â–‡â–‡â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡
wandb:          test_precision0.5 â–â–â–â–†â–„â–…â–„â–‡â–…â–…â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         test_precision0.75 â–â–â–â–â–â–†â–ˆâ–†â–ƒâ–„â–‡â–†â–†â–…â–‡â–‡â–‡â–‡â–‡â–‡â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–‡
wandb:            test_recall0.25 â–ˆâ–‡â–‡â–„â–„â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–ˆâ–â–â–â–â–â–â–‡â–‡â–†â–…â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:            test_recall0.75 â–â–â–â–â–â–…â–ˆâ–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡
wandb:                train_auroc â–â–‚â–‚â–ƒâ–‚â–ƒâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–…â–„â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–â–â–â–‚â–„â–ƒâ–„â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:            val_accuracy0.5 â–ˆâ–ˆâ–â–ƒâ–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ˆâ–†â–‡â–â–„â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:                  val_auroc â–„â–‚â–…â–…â–†â–‡â–„â–…â–…â–ˆâ–â–‚â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  val_balanced_accuracy0.25 â–‚â–‚â–‚â–†â–‚â–†â–…â–†â–ˆâ–ˆâ–â–†â–†â–…â–‡â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:   val_balanced_accuracy0.5 â–…â–…â–‡â–†â–â–ˆâ–„â–‡â–„â–ˆâ–ˆâ–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–‡â–†â–†â–†â–†â–†â–†â–†
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–â–â–ˆâ–‚â–…â–‚â–ˆâ–‡â–†â–‚â–‡â–„â–„â–„â–†â–†â–†â–†â–†â–†â–†â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:          val_precision0.25 â–â–â–â–â–â–„â–ƒâ–…â–ˆâ–†â–‡â–†â–‡â–†â–†â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:           val_precision0.5 â–…â–â–â–â–â–†â–â–†â–…â–‡â–ˆâ–‡â–†â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          val_precision0.75 â–â–â–â–â–â–â–‡â–ˆâ–†â–ˆâ–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             val_recall0.25 â–ˆâ–ˆâ–ˆâ–†â–†â–ƒâ–„â–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–ˆâ–â–â–â–â–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:             val_recall0.75 â–â–â–â–‡â–†â–…â–ƒâ–…â–„â–ˆâ–„â–„â–„â–…â–…â–…â–…â–…â–„â–„â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.64557
wandb:           test_accuracy0.5 0.67089
wandb:          test_accuracy0.75 0.65823
wandb:                 test_auroc 0.51737
wandb: test_balanced_accuracy0.25 0.54788
wandb:  test_balanced_accuracy0.5 0.53178
wandb: test_balanced_accuracy0.75 0.50678
wandb:         test_precision0.25 0.31818
wandb:          test_precision0.5 0.3125
wandb:         test_precision0.75 0.26667
wandb:            test_recall0.25 0.35
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.2
wandb:                train_auroc 0.99936
wandb:                 train_loss 0.06128
wandb:           val_accuracy0.25 0.65714
wandb:            val_accuracy0.5 0.71429
wandb:           val_accuracy0.75 0.72381
wandb:                  val_auroc 0.60419
wandb:  val_balanced_accuracy0.25 0.52702
wandb:   val_balanced_accuracy0.5 0.565
wandb:  val_balanced_accuracy0.75 0.57132
wandb:          val_precision0.25 0.29167
wandb:           val_precision0.5 0.38889
wandb:          val_precision0.75 0.41176
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.26923
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_7_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4ayj65le
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_165921-4ayj65le/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_172806-mk8z6too
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_7_fold2
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/mk8z6too
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–†â–…â–†â–…â–†â–…â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           test_accuracy0.5 â–ƒâ–„â–„â–‚â–â–…â–…â–ˆâ–†â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–‡â–…â–…â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb:                 test_auroc â–ˆâ–…â–‡â–„â–â–†â–„â–ƒâ–„â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb: test_balanced_accuracy0.25 â–…â–…â–†â–ˆâ–‡â–ƒâ–†â–â–„â–‚â–†â–„â–†â–†â–†â–„â–„â–„â–†â–†â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–â–„â–†â–„â–„â–„â–„â–…â–„
wandb:  test_balanced_accuracy0.5 â–…â–‡â–…â–â–ˆâ–‡â–„â–†â–‡â–‡â–†â–†â–‡â–…â–‡â–…â–…â–‡â–‡â–…â–‡â–‡â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–…â–…â–…â–…â–…
wandb: test_balanced_accuracy0.75 â–ˆâ–ˆâ–â–ƒâ–„â–ƒâ–‚â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–
wandb:         test_precision0.25 â–†â–†â–‡â–ˆâ–‚â–â–„â–…â–†â–†â–…â–ˆâ–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–…â–…â–…â–…â–…â–ˆâ–…
wandb:          test_precision0.5 â–ˆâ–‡â–ƒâ–‡â–‚â–…â–„â–ƒâ–‡â–†â–…â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–â–„â–â–â–„â–â–â–â–â–‚â–‚â–ƒâ–â–â–â–â–
wandb:         test_precision0.75 â–â–â–â–„â–…â–†â–‡â–…â–†â–ˆâ–†â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:            test_recall0.25 â–ˆâ–ˆâ–ˆâ–…â–„â–â–â–‚â–‚â–‚â–ƒâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–„â–‡â–…â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:            test_recall0.75 â–â–â–…â–‚â–ˆâ–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„
wandb:                train_auroc â–â–â–‚â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–…â–†â–…â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–‚â–‚â–„â–ƒâ–ˆâ–…â–†â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:            val_accuracy0.5 â–‚â–ˆâ–‚â–â–ƒâ–…â–…â–†â–…â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚
wandb:                  val_auroc â–…â–„â–‡â–‡â–â–ƒâ–„â–„â–„â–ƒâ–ˆâ–…â–‡â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  val_balanced_accuracy0.25 â–†â–â–†â–‡â–ƒâ–†â–‡â–†â–ˆâ–…â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†
wandb:   val_balanced_accuracy0.5 â–â–‡â–‚â–„â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‡â–„â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–â–â–â–â–â–ƒâ–
wandb:  val_balanced_accuracy0.75 â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–â–ƒâ–ƒâ–…â–†â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚
wandb:          val_precision0.25 â–…â–…â–ƒâ–†â–…â–â–†â–…â–‚â–†â–ˆâ–‚â–…â–‡â–‡â–‡â–‡â–‡â–…â–‡â–…â–‡â–‡â–…â–…â–„â–…â–„â–„â–…â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„
wandb:           val_precision0.5 â–†â–„â–â–†â–‡â–„â–…â–„â–†â–ˆâ–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–„
wandb:          val_precision0.75 â–â–â–ƒâ–‡â–ˆâ–„â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:             val_recall0.25 â–ˆâ–„â–ˆâ–„â–…â–…â–ƒâ–ƒâ–„â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–‡â–ˆâ–‡â–â–„â–†â–„â–…â–ƒâ–‚â–„â–†â–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb:             val_recall0.75 â–â–‚â–â–â–‚â–ˆâ–‡â–‚â–„â–‡â–‡â–†â–‡â–ˆâ–„â–ˆâ–„â–…â–…â–…â–…â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.60759
wandb:           test_accuracy0.5 0.60759
wandb:          test_accuracy0.75 0.62025
wandb:                 test_auroc 0.49873
wandb: test_balanced_accuracy0.25 0.48941
wandb:  test_balanced_accuracy0.5 0.43983
wandb: test_balanced_accuracy0.75 0.44831
wandb:         test_precision0.25 0.2381
wandb:          test_precision0.5 0.13333
wandb:         test_precision0.75 0.14286
wandb:            test_recall0.25 0.25
wandb:             test_recall0.5 0.1
wandb:            test_recall0.75 0.1
wandb:                train_auroc 0.99973
wandb:                 train_loss 0.0337
wandb:           val_accuracy0.25 0.61905
wandb:            val_accuracy0.5 0.6381
wandb:           val_accuracy0.75 0.6381
wandb:                  val_auroc 0.5129
wandb:  val_balanced_accuracy0.25 0.4888
wandb:   val_balanced_accuracy0.5 0.48856
wandb:  val_balanced_accuracy0.75 0.48856
wandb:          val_precision0.25 0.23077
wandb:           val_precision0.5 0.22727
wandb:          val_precision0.75 0.22727
wandb:             val_recall0.25 0.23077
wandb:              val_recall0.5 0.19231
wandb:             val_recall0.75 0.19231
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_7_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/mk8z6too
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_172806-mk8z6too/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_175407-4fttunxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_7_fold3
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4fttunxw
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           test_accuracy0.5 â–ƒâ–†â–…â–â–…â–‡â–‡â–†â–‡â–ˆâ–ˆâ–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ƒâ–ƒâ–ƒâ–‚â–â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒ
wandb:                 test_auroc â–‚â–â–â–†â–†â–…â–„â–…â–„â–…â–…â–…â–„â–ƒâ–„â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: test_balanced_accuracy0.25 â–…â–…â–…â–…â–…â–†â–‡â–ˆâ–„â–ƒâ–‚â–…â–‚â–„â–‚â–‚â–ƒâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  test_balanced_accuracy0.5 â–‡â–„â–ˆâ–ˆâ–„â–‡â–†â–ƒâ–â–ƒâ–ƒâ–†â–„â–…â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test_balanced_accuracy0.75 â–ˆâ–ˆâ–…â–ˆâ–ˆâ–„â–…â–ƒâ–„â–…â–„â–†â–‡â–ƒâ–‚â–‚â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         test_precision0.25 â–†â–†â–†â–‡â–ˆâ–„â–ƒâ–†â–â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:          test_precision0.5 â–‡â–‡â–ˆâ–…â–„â–ˆâ–ƒâ–„â–†â–„â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.75 â–â–â–â–â–‡â–ˆâ–†â–ˆâ–‡â–†â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:            test_recall0.25 â–ˆâ–…â–…â–…â–„â–ƒâ–â–‚â–ƒâ–ƒâ–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–ˆâ–â–â–†â–‡â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:            test_recall0.75 â–â–â–â–â–ˆâ–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:                train_auroc â–ƒâ–ƒâ–‚â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–‡â–…â–…â–ƒâ–ƒâ–â–â–â–â–â–‚â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–â–‚â–…â–‡â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            val_accuracy0.5 â–â–ˆâ–ˆâ–…â–…â–†â–‡â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–â–‡â–ƒâ–ˆâ–ƒâ–„â–„â–ƒâ–„â–„â–…â–„â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:                  val_auroc â–‚â–â–ƒâ–…â–‚â–ƒâ–…â–…â–…â–†â–ˆâ–‡â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:  val_balanced_accuracy0.25 â–â–â–ƒâ–ƒâ–ˆâ–ƒâ–…â–„â–‚â–‚â–…â–†â–‡â–†â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:   val_balanced_accuracy0.5 â–…â–â–„â–ˆâ–…â–‡â–‚â–ƒâ–„â–†â–ˆâ–…â–ˆâ–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  val_balanced_accuracy0.75 â–â–â–ƒâ–ƒâ–…â–ƒâ–ƒâ–‡â–„â–‡â–…â–ˆâ–…â–ƒâ–‚â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:          val_precision0.25 â–â–â–‚â–ƒâ–…â–‚â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           val_precision0.5 â–â–‡â–†â–‡â–†â–‡â–‡â–†â–ˆâ–‡â–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:          val_precision0.75 â–â–â–â–â–â–‡â–‡â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:             val_recall0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:              val_recall0.5 â–â–â–‡â–†â–ˆâ–†â–„â–„â–ƒâ–„â–„â–…â–…â–ƒâ–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:             val_recall0.75 â–â–â–â–â–ƒâ–‚â–…â–…â–„â–…â–ˆâ–†â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.55696
wandb:           test_accuracy0.5 0.55696
wandb:          test_accuracy0.75 0.58228
wandb:                 test_auroc 0.56186
wandb: test_balanced_accuracy0.25 0.40593
wandb:  test_balanced_accuracy0.5 0.40593
wandb: test_balanced_accuracy0.75 0.42288
wandb:         test_precision0.25 0.10526
wandb:          test_precision0.5 0.10526
wandb:         test_precision0.75 0.11765
wandb:            test_recall0.25 0.1
wandb:             test_recall0.5 0.1
wandb:            test_recall0.75 0.1
wandb:                train_auroc 1
wandb:                 train_loss 0.0
wandb:           val_accuracy0.25 0.65714
wandb:            val_accuracy0.5 0.65714
wandb:           val_accuracy0.75 0.65714
wandb:                  val_auroc 0.56767
wandb:  val_balanced_accuracy0.25 0.55282
wandb:   val_balanced_accuracy0.5 0.55282
wandb:  val_balanced_accuracy0.75 0.55282
wandb:          val_precision0.25 0.32143
wandb:           val_precision0.5 0.32143
wandb:          val_precision0.75 0.32143
wandb:             val_recall0.25 0.34615
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.34615
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_7_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4fttunxw
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_175407-4fttunxw/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/execution_datetimes.json

**************************************************  Experiment 78 | Version 9 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

âœ… Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

âœ… Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 37, 1.0: 27}
    Batch label distribution: {0.0: 34, 1.0: 30}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 11, 1.0: 7}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 38, 1.0: 26}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 28, 1.0: 36}
    Batch label distribution: {0.0: 8, 1.0: 10}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 30, 1.0: 34}
    Batch label distribution: {0.0: 28, 1.0: 36}
    Batch label distribution: {0.0: 8, 1.0: 10}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

âœ… Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

âœ… Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_181320-caqwg6zj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_9_fold1
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/caqwg6zj
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–ƒâ–â–â–ƒâ–†â–ƒâ–…â–…â–…â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:           test_accuracy0.5 â–â–„â–ˆâ–â–ˆâ–‚â–„â–„â–…â–„â–„â–†â–†â–…â–‡â–‡â–…â–†â–†â–…â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–â–‡â–†â–†â–‡â–…â–‚â–…â–ˆâ–†â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:                 test_auroc â–…â–„â–…â–„â–‚â–ƒâ–„â–ƒâ–â–†â–‡â–†â–„â–ˆâ–ˆâ–…â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb: test_balanced_accuracy0.25 â–„â–„â–„â–„â–„â–…â–„â–â–„â–†â–‚â–ƒâ–â–ƒâ–‡â–…â–ˆâ–…â–„â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†
wandb:  test_balanced_accuracy0.5 â–‡â–„â–â–â–…â–‚â–…â–‡â–ƒâ–„â–…â–†â–‡â–…â–‡â–†â–‡â–ƒâ–‡â–„â–‡â–‡â–†â–†â–†â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–ˆ
wandb: test_balanced_accuracy0.75 â–â–â–â–â–â–â–â–â–â–‚â–‡â–‚â–ˆâ–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         test_precision0.25 â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–â–„â–ƒâ–‡â–„â–‚â–ƒâ–…â–„â–ƒâ–„â–ˆâ–‡â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:          test_precision0.5 â–…â–„â–„â–„â–â–„â–„â–„â–„â–ƒâ–„â–ƒâ–…â–„â–„â–ƒâ–„â–…â–ˆâ–„â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…
wandb:         test_precision0.75 â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–‚â–‚â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:            test_recall0.25 â–ˆâ–ˆâ–†â–ˆâ–ˆâ–…â–…â–…â–‚â–ˆâ–„â–ƒâ–‚â–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–ˆâ–‡â–…â–ˆâ–…â–â–ƒâ–„â–ƒâ–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:            test_recall0.75 â–â–â–â–â–â–â–…â–ƒâ–‡â–†â–†â–†â–‚â–†â–ˆâ–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:                train_auroc â–â–„â–„â–ƒâ–„â–…â–„â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–†â–„â–‚â–‚â–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–ƒâ–â–†â–„â–ƒâ–ƒâ–…â–…â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:            val_accuracy0.5 â–ˆâ–†â–ˆâ–â–ƒâ–ƒâ–…â–‡â–ƒâ–†â–…â–…â–‡â–†â–†â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–â–„â–‡â–†â–…â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:                  val_auroc â–„â–‡â–‡â–â–ƒâ–…â–‡â–…â–…â–†â–ˆâ–‡â–†â–‡â–†â–†â–‡â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:  val_balanced_accuracy0.25 â–â–â–â–â–â–â–„â–†â–â–ˆâ–„â–ƒâ–„â–†â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:   val_balanced_accuracy0.5 â–‡â–…â–‡â–†â–â–ƒâ–„â–…â–ˆâ–ˆâ–†â–‡â–…â–…â–…â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…
wandb:  val_balanced_accuracy0.75 â–â–â–â–â–ˆâ–ƒâ–…â–„â–â–‚â–ƒâ–…â–ƒâ–…â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–†â–†â–†
wandb:          val_precision0.25 â–â–â–â–â–â–‚â–‚â–ƒâ–‚â–â–‡â–†â–„â–†â–…â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:           val_precision0.5 â–†â–…â–†â–â–…â–†â–†â–„â–„â–‡â–‡â–†â–‡â–ˆâ–†â–‡â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†
wandb:          val_precision0.75 â–â–â–â–â–…â–‡â–â–‡â–„â–‡â–„â–…â–†â–‡â–†â–ˆâ–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:             val_recall0.25 â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–„â–‚â–â–…â–ƒâ–‚â–…â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–†â–â–ƒâ–â–…â–â–†â–ˆâ–‡â–…â–†â–†â–†â–ƒâ–„â–…â–„â–ƒâ–†â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:             val_recall0.75 â–â–â–â–â–‚â–„â–‚â–ƒâ–†â–ƒâ–„â–‚â–ˆâ–…â–ˆâ–ƒâ–ƒâ–ƒâ–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.63291
wandb:           test_accuracy0.5 0.68354
wandb:          test_accuracy0.75 0.6962
wandb:                 test_auroc 0.50254
wandb: test_balanced_accuracy0.25 0.53941
wandb:  test_balanced_accuracy0.5 0.54025
wandb: test_balanced_accuracy0.75 0.51568
wandb:         test_precision0.25 0.30435
wandb:          test_precision0.5 0.33333
wandb:         test_precision0.75 0.3
wandb:            test_recall0.25 0.35
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.15
wandb:                train_auroc 1
wandb:                 train_loss 0.03415
wandb:           val_accuracy0.25 0.64762
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.72381
wandb:                  val_auroc 0.58569
wandb:  val_balanced_accuracy0.25 0.52069
wandb:   val_balanced_accuracy0.5 0.54601
wandb:  val_balanced_accuracy0.75 0.57132
wandb:          val_precision0.25 0.28
wandb:           val_precision0.5 0.33333
wandb:          val_precision0.75 0.41176
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.26923
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_9_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/caqwg6zj
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_181320-caqwg6zj/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_184013-yc223myu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_9_fold2
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/yc223myu
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–…â–â–ƒâ–ˆâ–…â–†â–‡â–…â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           test_accuracy0.5 â–‚â–†â–â–‚â–„â–ˆâ–ƒâ–…â–…â–ƒâ–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–„â–ƒ
wandb:          test_accuracy0.75 â–„â–ˆâ–ƒâ–â–‚â–„â–‡â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                 test_auroc â–ƒâ–ƒâ–…â–…â–ˆâ–ƒâ–„â–…â–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: test_balanced_accuracy0.25 â–†â–…â–†â–‡â–…â–‡â–ˆâ–„â–…â–„â–…â–†â–ˆâ–‡â–‚â–ƒâ–ƒâ–„â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  test_balanced_accuracy0.5 â–‡â–ˆâ–ˆâ–ˆâ–„â–…â–â–„â–…â–†â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: test_balanced_accuracy0.75 â–ˆâ–ˆâ–ƒâ–…â–…â–…â–…â–„â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         test_precision0.25 â–ˆâ–‡â–ˆâ–‡â–‡â–…â–‡â–‡â–†â–…â–„â–„â–†â–ƒâ–…â–„â–ƒâ–„â–„â–„â–â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–„â–„â–„
wandb:          test_precision0.5 â–â–â–ˆâ–‡â–‡â–†â–ƒâ–„â–„â–„â–‚â–„â–ƒâ–‚â–ƒâ–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         test_precision0.75 â–â–â–â–â–„â–ƒâ–ƒâ–‚â–ˆâ–„â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:            test_recall0.25 â–ˆâ–ˆâ–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–„â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:             test_recall0.5 â–…â–‡â–ˆâ–„â–…â–„â–‚â–‚â–‚â–‚â–ƒâ–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:            test_recall0.75 â–â–ƒâ–â–â–†â–ƒâ–†â–ˆâ–†â–ƒâ–ƒâ–ƒâ–†â–ƒâ–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                train_auroc â–â–â–â–…â–…â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–…â–„â–„â–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–‚â–‚â–„â–…â–„â–ƒâ–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡
wandb:            val_accuracy0.5 â–â–ˆâ–ƒâ–…â–ƒâ–ƒâ–†â–„â–†â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ˆâ–†â–â–…â–ƒâ–…â–†â–ƒâ–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–†â–…â–†â–…â–†â–…â–†â–†â–†â–†â–†â–†â–…â–…
wandb:                  val_auroc â–ƒâ–ˆâ–‡â–…â–†â–„â–†â–â–‡â–„â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–„â–„â–„â–„â–„â–„â–„
wandb:  val_balanced_accuracy0.25 â–…â–‡â–ƒâ–ˆâ–…â–…â–…â–†â–â–‡â–„â–„â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–„â–…â–…â–…â–…â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…
wandb:   val_balanced_accuracy0.5 â–…â–ˆâ–ƒâ–â–‚â–†â–â–ƒâ–‚â–ƒâ–â–‚â–â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:  val_balanced_accuracy0.75 â–†â–„â–†â–‡â–†â–†â–†â–ˆâ–‡â–…â–â–‚â–‡â–‚â–‚â–…â–…â–…â–…â–…â–…â–„â–‚â–â–â–â–â–â–‚â–‚â–…â–…â–…â–‚â–‚â–…â–‡â–‡â–‡â–…
wandb:          val_precision0.25 â–†â–†â–‡â–ˆâ–†â–‚â–ƒâ–„â–†â–ƒâ–‡â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–„â–„â–…â–„â–„â–…â–„â–„â–„â–„â–„â–„
wandb:           val_precision0.5 â–ˆâ–…â–†â–ƒâ–†â–†â–„â–â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–†â–…â–…â–…â–…â–…â–…â–…
wandb:          val_precision0.75 â–â–ˆâ–â–â–ƒâ–ƒâ–…â–…â–„â–â–…â–…â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–„
wandb:             val_recall0.25 â–‡â–ˆâ–ˆâ–†â–…â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–â–ƒâ–†â–†â–‡â–ˆâ–†â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:             val_recall0.75 â–ƒâ–â–â–†â–â–‚â–…â–‚â–ˆâ–…â–†â–…â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.55696
wandb:           test_accuracy0.5 0.55696
wandb:          test_accuracy0.75 0.56962
wandb:                 test_auroc 0.43729
wandb: test_balanced_accuracy0.25 0.42246
wandb:  test_balanced_accuracy0.5 0.38941
wandb: test_balanced_accuracy0.75 0.39788
wandb:         test_precision0.25 0.14286
wandb:          test_precision0.5 0.05882
wandb:         test_precision0.75 0.0625
wandb:            test_recall0.25 0.15
wandb:             test_recall0.5 0.05
wandb:            test_recall0.75 0.05
wandb:                train_auroc 0.99955
wandb:                 train_loss 0.06291
wandb:           val_accuracy0.25 0.6
wandb:            val_accuracy0.5 0.62857
wandb:           val_accuracy0.75 0.6381
wandb:                  val_auroc 0.44133
wandb:  val_balanced_accuracy0.25 0.47614
wandb:   val_balanced_accuracy0.5 0.49513
wandb:  val_balanced_accuracy0.75 0.50146
wandb:          val_precision0.25 0.21429
wandb:           val_precision0.5 0.24
wandb:          val_precision0.75 0.25
wandb:             val_recall0.25 0.23077
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.23077
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_9_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/yc223myu
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_184013-yc223myu/logs
wandb: creating run
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_191001-m0jn6pyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_9_fold3
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/m0jn6pyy
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–â–…â–…â–ƒâ–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           test_accuracy0.5 â–…â–â–…â–â–‚â–…â–ˆâ–‡â–…â–†â–†â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–†â–„â–â–ƒâ–ƒâ–„â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:                 test_auroc â–‡â–†â–…â–…â–ˆâ–„â–„â–â–ƒâ–‚â–…â–†â–‚â–…â–…â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: test_balanced_accuracy0.25 â–ˆâ–ˆâ–†â–ˆâ–‡â–ˆâ–â–â–„â–†â–ƒâ–†â–…â–â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:  test_balanced_accuracy0.5 â–†â–ˆâ–‡â–„â–„â–â–ƒâ–„â–…â–†â–…â–ˆâ–†â–†â–†â–†â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb: test_balanced_accuracy0.75 â–‡â–‡â–ˆâ–‡â–‡â–‚â–â–‡â–‚â–ƒâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:         test_precision0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–…â–‡â–â–ˆâ–†â–†â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…
wandb:          test_precision0.5 â–â–â–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–„â–…â–…â–…â–„â–…â–†â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:         test_precision0.75 â–â–â–â–â–â–â–ƒâ–ˆâ–„â–…â–„â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:            test_recall0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–„â–‡â–ƒâ–…â–‚â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–â–†â–ˆâ–ˆâ–„â–‚â–…â–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:            test_recall0.75 â–â–ƒâ–â–â–â–ƒâ–ƒâ–†â–†â–…â–†â–…â–ƒâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                train_auroc â–â–‚â–â–„â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–ˆâ–ˆâ–†â–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–„â–â–ƒâ–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            val_accuracy0.5 â–ˆâ–ˆâ–‚â–â–…â–†â–†â–„â–„â–†â–†â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–…â–„â–†â–…â–ˆâ–„â–…â–†â–‡â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:                  val_auroc â–†â–â–ˆâ–†â–ˆâ–…â–ˆâ–…â–ƒâ–ƒâ–†â–…â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  val_balanced_accuracy0.25 â–‚â–‚â–‡â–†â–‡â–â–„â–â–„â–†â–ˆâ–…â–…â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:   val_balanced_accuracy0.5 â–â–†â–‡â–…â–‚â–â–ƒâ–„â–‚â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  val_balanced_accuracy0.75 â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–…â–…â–„â–…â–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          val_precision0.25 â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–â–ƒâ–‡â–†â–‡â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:           val_precision0.5 â–…â–â–â–†â–â–…â–…â–…â–†â–†â–…â–ˆâ–‡â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:          val_precision0.75 â–„â–â–â–â–â–â–ˆâ–â–‡â–…â–„â–…â–„â–†â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:             val_recall0.25 â–ˆâ–ˆâ–‡â–ˆâ–†â–…â–‡â–ƒâ–„â–…â–„â–„â–ƒâ–‚â–ƒâ–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:              val_recall0.5 â–ˆâ–‡â–â–‡â–ˆâ–â–„â–‚â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–ƒâ–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:             val_recall0.75 â–â–â–â–â–â–ƒâ–‚â–‡â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.59494
wandb:           test_accuracy0.5 0.60759
wandb:          test_accuracy0.75 0.64557
wandb:                 test_auroc 0.45424
wandb: test_balanced_accuracy0.25 0.46441
wandb:  test_balanced_accuracy0.5 0.47288
wandb: test_balanced_accuracy0.75 0.49831
wandb:         test_precision0.25 0.2
wandb:          test_precision0.5 0.21053
wandb:         test_precision0.75 0.25
wandb:            test_recall0.25 0.2
wandb:             test_recall0.5 0.2
wandb:            test_recall0.75 0.2
wandb:                train_auroc 1
wandb:                 train_loss 1e-05
wandb:           val_accuracy0.25 0.67619
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.72381
wandb:                  val_auroc 0.55501
wandb:  val_balanced_accuracy0.25 0.56548
wandb:   val_balanced_accuracy0.5 0.57181
wandb:  val_balanced_accuracy0.75 0.59713
wandb:          val_precision0.25 0.34615
wandb:           val_precision0.5 0.36
wandb:          val_precision0.75 0.42857
wandb:             val_recall0.25 0.34615
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.34615
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_9_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/m0jn6pyy
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_191001-m0jn6pyy/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/execution_datetimes.json

**************************************************  Experiment 78 | Version 11 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

âœ… Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

âœ… Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 3, 1.0: 13}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 1, 1.0: 1}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 3, 1.0: 13}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 2}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {1.0: 2}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

âœ… Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

âœ… Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_194151-lc0p70m1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_11_fold1
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/lc0p70m1
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–â–ƒâ–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:           test_accuracy0.5 â–†â–ƒâ–ˆâ–â–â–…â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–‡â–‡â–†â–†â–†â–†â–†â–†â–†
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ƒâ–ƒâ–‚â–…â–„â–…â–„â–…â–„â–„â–„â–ƒâ–„â–ƒâ–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–â–â–â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„
wandb:                 test_auroc â–„â–„â–„â–ƒâ–„â–â–ƒâ–…â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: test_balanced_accuracy0.25 â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–ˆâ–‚â–ƒâ–„â–„â–„â–…â–…â–…â–„â–„â–„â–„â–…â–…â–…â–…â–…â–„â–„â–…â–…â–†â–…â–…â–…â–…â–„â–„â–…â–…â–„â–…
wandb:  test_balanced_accuracy0.5 â–‚â–â–ƒâ–„â–„â–†â–ˆâ–…â–†â–…â–…â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–…â–†â–…â–†â–†
wandb: test_balanced_accuracy0.75 â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–„â–…â–†â–„â–„â–„â–„â–„â–…â–…â–„â–„â–„â–„â–‚â–„â–‚â–‚â–„â–„â–…
wandb:         test_precision0.25 â–â–â–â–â–â–â–â–â–â–â–ƒâ–‚â–„â–„â–„â–…â–„â–„â–…â–„â–…â–†â–„â–„â–†â–‡â–…â–†â–…â–…â–„â–„â–…â–…â–†â–„â–„â–„â–ˆâ–†
wandb:          test_precision0.5 â–ƒâ–‚â–‚â–‚â–â–ƒâ–„â–„â–†â–†â–„â–ˆâ–†â–„â–„â–ˆâ–†â–„â–…â–…â–„â–„â–…â–…â–„â–…â–†â–†â–†â–…â–…â–…â–†â–„â–„â–ƒâ–…â–„â–„â–„
wandb:         test_precision0.75 â–â–â–â–â–â–ˆâ–†â–†â–ˆâ–…â–†â–ƒâ–…â–†â–…â–†â–…â–†â–…â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–„â–„â–…â–…â–…â–…
wandb:            test_recall0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–…â–„â–…â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:             test_recall0.5 â–ˆâ–ˆâ–‚â–†â–ˆâ–„â–‡â–â–â–†â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:            test_recall0.75 â–â–â–â–â–‚â–„â–ˆâ–…â–„â–…â–„â–„â–‡â–„â–‡â–‡â–‡â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–…â–‡â–…â–…â–‡â–‡â–…â–…â–…â–‡â–…â–„â–‡
wandb:                train_auroc â–â–„â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–â–â–â–…â–…â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡
wandb:            val_accuracy0.5 â–„â–â–ˆâ–â–‚â–„â–†â–†â–†â–†â–…â–‡â–…â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–‡â–‡â–†
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–„â–„â–„â–ƒâ–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–ƒâ–ƒâ–…â–‚â–…â–â–„â–ƒâ–‚â–„â–„â–…â–…â–„
wandb:                  val_auroc â–‡â–‡â–†â–…â–‡â–†â–â–ƒâ–†â–†â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„
wandb:  val_balanced_accuracy0.25 â–…â–…â–…â–…â–…â–…â–ˆâ–†â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚
wandb:   val_balanced_accuracy0.5 â–†â–„â–…â–ˆâ–â–ˆâ–ƒâ–ƒâ–„â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–„â–‚
wandb:  val_balanced_accuracy0.75 â–†â–†â–†â–†â–†â–â–‚â–„â–ˆâ–‡â–ƒâ–†â–…â–„â–…â–…â–„â–„â–…â–…â–„â–„â–…â–…â–„â–„â–„â–†â–†â–„â–„â–„â–„â–‚â–‚â–ƒâ–„â–†â–…â–‚
wandb:          val_precision0.25 â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–…â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:           val_precision0.5 â–ˆâ–‚â–‡â–…â–„â–‡â–‡â–†â–…â–…â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–â–‚
wandb:          val_precision0.75 â–â–â–â–â–â–â–â–ˆâ–†â–â–†â–„â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–†â–†
wandb:             val_recall0.25 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–…â–†â–…â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val_recall0.5 â–†â–ˆâ–ƒâ–…â–†â–„â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:             val_recall0.75 â–â–â–â–â–â–‡â–â–ˆâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.67089
wandb:           test_accuracy0.5 0.6962
wandb:          test_accuracy0.75 0.6962
wandb:                 test_auroc 0.57034
wandb: test_balanced_accuracy0.25 0.54831
wandb:  test_balanced_accuracy0.5 0.5322
wandb: test_balanced_accuracy0.75 0.51568
wandb:         test_precision0.25 0.33333
wandb:          test_precision0.5 0.33333
wandb:         test_precision0.75 0.3
wandb:            test_recall0.25 0.3
wandb:             test_recall0.5 0.2
wandb:            test_recall0.75 0.15
wandb:                train_auroc 0.99964
wandb:                 train_loss 0.04064
wandb:           val_accuracy0.25 0.55238
wandb:            val_accuracy0.5 0.60952
wandb:           val_accuracy0.75 0.66667
wandb:                  val_auroc 0.4888
wandb:  val_balanced_accuracy0.25 0.4187
wandb:   val_balanced_accuracy0.5 0.45667
wandb:  val_balanced_accuracy0.75 0.49464
wandb:          val_precision0.25 0.13793
wandb:           val_precision0.5 0.17391
wandb:          val_precision0.75 0.23529
wandb:             val_recall0.25 0.15385
wandb:              val_recall0.5 0.15385
wandb:             val_recall0.75 0.15385
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_11_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/lc0p70m1
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_194151-lc0p70m1/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_201321-lbmythpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_11_fold2
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/lbmythpo
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           test_accuracy0.5 â–ˆâ–â–â–†â–ƒâ–‚â–‚â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–†â–†â–†â–ƒâ–‡â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:                 test_auroc â–ƒâ–‡â–†â–ˆâ–‡â–‡â–„â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒ
wandb: test_balanced_accuracy0.25 â–†â–ˆâ–†â–†â–ˆâ–…â–†â–ƒâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  test_balanced_accuracy0.5 â–‡â–ˆâ–â–‚â–ƒâ–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–
wandb: test_balanced_accuracy0.75 â–ˆâ–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–‚â–„â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:         test_precision0.25 â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–…â–…â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:          test_precision0.5 â–‡â–‡â–ˆâ–…â–…â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         test_precision0.75 â–â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:            test_recall0.25 â–ˆâ–ˆâ–‡â–†â–†â–â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:             test_recall0.5 â–†â–†â–ˆâ–†â–…â–…â–â–â–‚â–ƒâ–…â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            test_recall0.75 â–â–â–ƒâ–ƒâ–â–ˆâ–ƒâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                train_auroc â–â–‚â–‚â–ƒâ–ƒâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–‡â–‡â–†â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–‚â–ƒâ–…â–…â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:            val_accuracy0.5 â–â–ƒâ–â–‚â–‚â–ˆâ–ˆâ–‡â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†â–†
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–ƒâ–‚â–„â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–„â–„â–â–‚â–ƒ
wandb:                  val_auroc â–ˆâ–…â–ƒâ–†â–â–„â–„â–„â–„â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:  val_balanced_accuracy0.25 â–†â–†â–ˆâ–ˆâ–†â–‡â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–†â–†â–ƒâ–ƒâ–ƒ
wandb:   val_balanced_accuracy0.5 â–‡â–â–†â–ˆâ–‡â–…â–‡â–ƒâ–ƒâ–…â–…â–…â–…â–ƒâ–„â–…â–…â–„â–„â–…â–„â–„â–…â–…â–†â–„â–…â–ƒâ–…â–…â–…â–„â–†â–„â–„â–„â–…â–‡â–…â–…
wandb:  val_balanced_accuracy0.75 â–…â–‚â–…â–‚â–ˆâ–â–†â–„â–†â–…â–…â–…â–†â–…â–…â–…â–…â–†â–†â–†â–…â–†â–…â–…â–…â–…â–…â–…â–†â–†â–†â–…â–†â–†â–†â–‚â–…â–…â–…â–…
wandb:          val_precision0.25 â–‡â–ˆâ–‡â–‡â–â–…â–â–ƒâ–â–â–â–â–â–â–‚â–â–â–„â–â–‚â–„â–â–â–â–â–‚â–‚â–‚â–„â–â–‚â–‚â–‚â–‚â–‡â–†â–ƒâ–ƒâ–ƒâ–„
wandb:           val_precision0.5 â–…â–†â–…â–„â–†â–â–ƒâ–…â–„â–ˆâ–„â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–„â–„â–„â–ƒ
wandb:          val_precision0.75 â–â–â–„â–‡â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:             val_recall0.25 â–ˆâ–ˆâ–†â–…â–†â–…â–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–
wandb:              val_recall0.5 â–‚â–ˆâ–ƒâ–†â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚
wandb:             val_recall0.75 â–â–â–â–â–â–‚â–‡â–‡â–â–ˆâ–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.53165
wandb:           test_accuracy0.5 0.53165
wandb:          test_accuracy0.75 0.5443
wandb:                 test_auroc 0.46017
wandb: test_balanced_accuracy0.25 0.40551
wandb:  test_balanced_accuracy0.5 0.37246
wandb: test_balanced_accuracy0.75 0.38093
wandb:         test_precision0.25 0.13043
wandb:          test_precision0.5 0.05263
wandb:         test_precision0.75 0.05556
wandb:            test_recall0.25 0.15
wandb:             test_recall0.5 0.05
wandb:            test_recall0.75 0.05
wandb:                train_auroc 0.99973
wandb:                 train_loss 0.03442
wandb:           val_accuracy0.25 0.61905
wandb:            val_accuracy0.5 0.64762
wandb:           val_accuracy0.75 0.67619
wandb:                  val_auroc 0.48832
wandb:  val_balanced_accuracy0.25 0.463
wandb:   val_balanced_accuracy0.5 0.48199
wandb:  val_balanced_accuracy0.75 0.50097
wandb:          val_precision0.25 0.18182
wandb:           val_precision0.5 0.21053
wandb:          val_precision0.75 0.25
wandb:             val_recall0.25 0.15385
wandb:              val_recall0.5 0.15385
wandb:             val_recall0.75 0.15385
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_11_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/lbmythpo
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_201321-lbmythpo/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_203505-8w98jt3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_11_fold3
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/8w98jt3d
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 â–â–â–â–‚â–ƒâ–„â–†â–„â–†â–†â–‡â–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:           test_accuracy0.5 â–â–ƒâ–…â–„â–„â–…â–†â–‚â–‡â–ˆâ–†â–‡â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:          test_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–†â–„â–ƒâ–‚â–…â–†â–ƒâ–„â–…â–ƒâ–…â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:                 test_auroc â–„â–…â–‡â–„â–ˆâ–„â–‡â–‚â–â–ƒâ–‚â–†â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: test_balanced_accuracy0.25 â–‡â–‡â–…â–‡â–…â–â–‚â–ˆâ–ˆâ–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:  test_balanced_accuracy0.5 â–…â–‡â–ˆâ–‡â–†â–…â–â–‚â–‡â–†â–…â–†â–ˆâ–‡â–„â–ˆâ–‡â–†â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb: test_balanced_accuracy0.75 â–…â–ƒâ–â–†â–‡â–ƒâ–ƒâ–†â–„â–ˆâ–‡â–†â–‡â–ƒâ–‡â–„â–ˆâ–„â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:         test_precision0.25 â–…â–„â–„â–…â–…â–‚â–ƒâ–‚â–ƒâ–â–ˆâ–…â–…â–‚â–…â–„â–‚â–„â–„â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒ
wandb:          test_precision0.5 â–…â–â–ˆâ–ƒâ–…â–†â–ƒâ–ƒâ–ˆâ–…â–„â–‡â–†â–…â–„â–„â–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:         test_precision0.75 â–â–â–â–…â–…â–…â–†â–†â–ˆâ–…â–‡â–‡â–‡â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:            test_recall0.25 â–ˆâ–ˆâ–ˆâ–…â–„â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test_recall0.5 â–ˆâ–†â–†â–…â–„â–„â–â–ƒâ–â–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:            test_recall0.75 â–â–â–…â–‚â–…â–ˆâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:                train_auroc â–â–‚â–‚â–„â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 train_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–„â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           val_accuracy0.25 â–â–â–ƒâ–…â–…â–…â–†â–†â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            val_accuracy0.5 â–â–ƒâ–ˆâ–†â–‡â–†â–ƒâ–†â–…â–†â–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           val_accuracy0.75 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‡â–â–„â–†â–†â–‡â–…â–…â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–†â–…â–…â–…â–…â–†â–…â–…â–†
wandb:                  val_auroc â–‚â–â–ƒâ–„â–…â–…â–†â–ˆâ–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–†â–†â–†â–‡â–‡â–†â–†
wandb:  val_balanced_accuracy0.25 â–„â–„â–…â–„â–„â–â–ƒâ–ˆâ–„â–‡â–‚â–ƒâ–„â–…â–†â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:   val_balanced_accuracy0.5 â–â–ƒâ–„â–‚â–ˆâ–ƒâ–…â–ƒâ–†â–ˆâ–„â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  val_balanced_accuracy0.75 â–…â–„â–ˆâ–„â–â–…â–†â–†â–…â–ƒâ–„â–…â–…â–„â–„â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–†â–†â–†â–…â–…â–…â–…â–†â–†â–†â–†â–…
wandb:          val_precision0.25 â–…â–…â–…â–…â–†â–†â–„â–‡â–†â–â–ˆâ–†â–‡â–ˆâ–†â–ˆâ–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡
wandb:           val_precision0.5 â–‚â–ƒâ–ƒâ–â–…â–‚â–„â–†â–„â–ƒâ–ˆâ–„â–†â–†â–‚â–‚â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          val_precision0.75 â–â–ˆâ–â–â–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–…â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:             val_recall0.25 â–‡â–ˆâ–‡â–â–ƒâ–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:              val_recall0.5 â–ˆâ–†â–ˆâ–…â–†â–â–…â–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„
wandb:             val_recall0.75 â–â–â–â–„â–‡â–„â–„â–‚â–„â–…â–…â–ˆâ–‡â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.56962
wandb:           test_accuracy0.5 0.62025
wandb:          test_accuracy0.75 0.63291
wandb:                 test_auroc 0.45085
wandb: test_balanced_accuracy0.25 0.46398
wandb:  test_balanced_accuracy0.5 0.49788
wandb: test_balanced_accuracy0.75 0.50636
wandb:         test_precision0.25 0.20833
wandb:          test_precision0.5 0.25
wandb:         test_precision0.75 0.26316
wandb:            test_recall0.25 0.25
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.25
wandb:                train_auroc 1
wandb:                 train_loss 4e-05
wandb:           val_accuracy0.25 0.68571
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.68571
wandb:                  val_auroc 0.54649
wandb:  val_balanced_accuracy0.25 0.54601
wandb:   val_balanced_accuracy0.5 0.54601
wandb:  val_balanced_accuracy0.75 0.5202
wandb:          val_precision0.25 0.33333
wandb:           val_precision0.5 0.33333
wandb:          val_precision0.75 0.29412
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.19231
wandb: 
wandb: ğŸš€ View run vgg16_2d_78_11_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/8w98jt3d
wandb: â­ï¸ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_203505-8w98jt3d/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/execution_datetimes.json

**************************************************  Experiment 78 | Version 12 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

âœ… Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

âœ… Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 20, 1.0: 12}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 3, 1.0: 15}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 5, 1.0: 13}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 12, 1.0: 6}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

âœ… Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

âœ… Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_12/wandb/run-20250701_205522-7iemeeif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_12_fold1
wandb: â­ï¸ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: ğŸš€ View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/7iemeeif
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
srun: got SIGCONT
slurmstepd-02.ctm-deep-05: error: *** JOB 13665 ON 02.ctm-deep-05 CANCELLED AT 2025-07-01T21:20:00 ***
slurmstepd-02.ctm-deep-05: error: *** STEP 13665.0 ON 02.ctm-deep-05 CANCELLED AT 2025-07-01T21:20:00 ***
srun: forcing job termination
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
Exception ignored in: <function _releaseLock at 0x7f9ec2711940>
Traceback (most recent call last):
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/logging/__init__.py", line 237, in _releaseLock
    def _releaseLock():
    
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3623617) is killed by signal: Terminated. 
Error executing job with overrides: []
Traceback (most recent call last):
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1132, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/multiprocessing/queues.py", line 114, in get
    raise Empty
_queue.Empty

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/nas-ctm01/homes/mipaiva/pipeline_template_pl/slurm_files/shell_script_files/../../src/scripts/run_experiment_pipeline.py", line 54, in run_hyperparameter_grid_based_execution_pipeline
    run_experiment_pipeline(config)
  File "/nas-ctm01/homes/mipaiva/pipeline_template_pl/slurm_files/shell_script_files/../../src/scripts/run_experiment_pipeline.py", line 167, in run_experiment_pipeline
    model_pipeline.train_model()
  File "/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/model/model_pipeline.py", line 68, in train_model
    self.pytorch_lightning_trainer.fit(
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 134, in run
    self.on_advance_end()
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 249, in on_advance_end
    self.val_loop.run()
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py", line 181, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 108, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
                                       ^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py", line 126, in __next__
    batch = super().__next__()
            ^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py", line 58, in __next__
    batch = next(self.iterator)
            ^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py", line 285, in __next__
    out = next(self._iterator)
          ^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py", line 123, in __next__
    out = next(self.iterators[0])
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1294, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1145, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 3624143, 3624206, 3624269) exited unexpectedly

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7f9ccb8fe200>
Traceback (most recent call last):
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 94, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 228, in teardown
    self._client.send_server_request(
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in send_server_request
    self._send_message(msg)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 151, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe
srun: error: 02.ctm-deep-05: task 0: Exited with exit code 1
