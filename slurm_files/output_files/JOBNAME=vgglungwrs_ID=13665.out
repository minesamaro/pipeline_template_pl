Initialization time: 2025-07-01 11:53:16

**************************************************  Experiment 78 | Version 1 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

✅ Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 4, 1.0: 12}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 1, 1.0: 1}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {1.0: 2}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 3, 1.0: 13}
    Batch label distribution: {0.0: 1, 1.0: 1}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Currently logged in as: maria-i-paiva (maria-i-paiva-inesc-tec) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_115622-x2g4vild
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_1_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/x2g4vild
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██▁▁▁▁▁▁▁
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁███████████████████████████████████████
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████▁████████
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁█████████████████▁▁▁█████████
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▃▄▃▁▅▅▅█▄▃▅▃▅▆▄█▅▆▅▅▁▃▂▅▆▄▃▃▂▄▄▄▄▄▄▃▄▃▅▄
wandb:                 train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 █▁▁▁▁▁▁▁▁▁███████████████▁▁▁████████████
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 █▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████▁▁███████████
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.44608
wandb:                 train_loss 2.0909
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_1_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/x2g4vild
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_115622-x2g4vild/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_121218-dsmi775e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_1_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/dsmi775e
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ▁███▁█▁▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 █▁▁▁▁▁▁▁▁███████████████████████████████
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▁█▁▁▁█▁▁█▁▁████████████████████████
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▅█▇▇▆▅▆▆▅▇▅▇▄▃▅▄▅▆▁▅▁▄▄▄▅▅▇▄█▆▃▅▃▄▄▅▃▄▃▃
wandb:                 train_loss █▂▁▂▃▃▄▂▂▂▃▂▂▂▃▁▁▄▁▃▂▃▁▃▃▂▂▂▄▃▂▄▂▂▃▂▂▃▂▂
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ██████▁▁███▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▁▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁█▁▁▁█▁▁▁▁▁▁█▁▁██▁▁█████████████████████
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 █▁▁██▁███▁██████████████████████████████
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.46387
wandb:                 train_loss 2.09538
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_1_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/dsmi775e
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_121218-dsmi775e/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_123930-32c6c74j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_1_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/32c6c74j
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 █▁▁██▁▁▁█▁▁█▁▁█████████▁▁▁▁▁▁███████████
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁███▁██▁█████▁█▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁██▁█▁██▁██▁█▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▃▅▄▅▆▄▅▄▇▃▆▂▃▆▄▄▇▇▅▆▅▃▂█▂█▃▅▁▃▃▄▅▆▃▂▄▅▅▂
wandb:                 train_loss ▅▃▃▄▄▁▇▄▃▇▄▄▃▄▆▃▃▄█▂▅▃▃▃▂▃▃▃▄▆▃▇▁▄▆▃▃▂▃▄
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁██▁▁▁▁███▁▁█▁████████████▁▁▁███████████
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁███▁██████▁▁█▁▁▁▁▁▁█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ██▁█▁██████▁▁▁▁▁▁▁▁▁▁▁███▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.5245
wandb:                 train_loss 2.09383
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_1_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/32c6c74j
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/wandb/run-20250701_123930-32c6c74j/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_1/execution_datetimes.json

**************************************************  Experiment 78 | Version 2 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

✅ Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 8, 1.0: 10}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 20, 1.0: 12}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 12, 1.0: 6}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 12, 1.0: 20}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 9, 1.0: 9}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_130121-1q9m1vqw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_2_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/1q9m1vqw
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ██████████████████▁▁▁▁▁▁▁▁▁▁█▁▁▁████▁▁▁▁
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁███████████████████████████████████████
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████▁████▁▁▁▁▁▁▁▁███
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████▁█▁███▁▁▁███
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▆█▆▂▇▂▃▅▁▆▅▆▂▃▇▅▅▃▃▃▇▃▃▂▄▁▂▂▆▂▂▂▄▅▃▄▇▄▃▃
wandb:                 train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁███████████████▁▁▁▁▁▁▁▁▁▁▁▁█▁▁████████▁
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████▁▁███▁▁▁▁▁▁██
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████▁████▁▁▁▁▁███
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.52064
wandb:                 train_loss 2.09495
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_2_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/1q9m1vqw
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_130121-1q9m1vqw/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_131739-68muygtk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_2_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/68muygtk
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ▁█▁▁▁▁▁▁▁▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 █▁▁██████████▁▁███████████████████████▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ██████████▁▁██▁████████████████████████▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▅▃▆▃▇█▇▇▇▅█▄▆▆█▅▄▅▄▄▅▃▆▅▇▄▄▆▃▆▆▆▆▆▁▅▅█▇▃
wandb:                 train_loss ▇▇▇▇▇▆▇▆▇▆▇▇▇▇▇▇▇▇▄█▇▁▇▃▅▇▆▇▇▇▇▇▆█▇▇▆▆▇▇
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁█▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁▁██████████▁██▁██████████████████████▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▁▁████████▁█▁▁▁▁██████████████████████▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.48408
wandb:                 train_loss 2.09323
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_2_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/68muygtk
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_131739-68muygtk/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_135501-4nms00n1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_2_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4nms00n1
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 █▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▇▅▄▆▃▃▅▆█▅▃▃▆▆▄▁▃▄▃▅▆▄▆▄▅▅▃▄▆▃▄▅▇▄▅▃▅▃▇▅
wandb:                 train_loss ▃▅▄▃▂█▅▁▃▃▃▃▄▂▄▁▁▄▃▃▆▃▄▃▅▃▄▃▃▃▃▃▃▃▅▅▄▃▅▃
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁▁▁▁▁▁▁█▁█▁▁████████████████████████████
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▄██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁██████▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▁▁██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.53257
wandb:                 train_loss 2.09392
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_2_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4nms00n1
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/wandb/run-20250701_135501-4nms00n1/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_2/execution_datetimes.json

**************************************************  Experiment 78 | Version 4 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

✅ Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 28, 1.0: 36}
    Batch label distribution: {0.0: 8, 1.0: 10}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 28, 1.0: 36}
    Batch label distribution: {0.0: 12, 1.0: 6}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 39, 1.0: 25}
    Batch label distribution: {0.0: 31, 1.0: 33}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 9, 1.0: 9}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_142201-q4m0potr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_4_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/q4m0potr
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc █▁▃▆██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ████▁███████████████████████████████████
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████▁▁▁█████
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████▁▁█████
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▆▄▄▃▃▁█▇▆▃▇▆▆▅▆█▆▃▃▇▆▃▇▃█▅█▄▅▅▅█▄▂▄▆▃▄▄▅
wandb:                 train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▆▅▄▄▅▁▅▆▆▅▆█▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████▁██████
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████▁████████
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.43369
wandb:                 train_loss 2.09274
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_4_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/q4m0potr
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_142201-q4m0potr/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_144208-dkqr9qcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_4_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/dkqr9qcx
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▅▅▆▂▂▂▄█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ███████████▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ███████████████▁▁▁▁▁▁▁▁▁▁███████████████
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▄▄▆█▆▄▃▄▄▄▃▄▃▅▂▃▄▄▅▃▂▃▄▂▂▁▄▃▃▅▃▄▃▄▃▃▂▆▃▄
wandb:                 train_loss █▂▂▃▂▂▃▂▂▃▂▃▃▂▂▂▃▂▃▂▂▂▂▂▂▂▂▃▂▂▁▂▂▄▂▃▂▂▂▃
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▁█▇▇█▄▄▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ███▁████████████████████████████████████
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ████████████▁▁▁▁▁▁▁▁▁▁▁█████████████████
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.4843
wandb:                 train_loss 2.09472
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_4_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/dkqr9qcx
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_144208-dkqr9qcx/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_150318-suyo5g0u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_4_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/suyo5g0u
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ██████████████████████▁█▁▁▁▁▁▁▁█████████
wandb:          test_accuracy0.75 █▁██████████████████████████████████████
wandb:                 test_auroc ▁█▅▅▅█▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████▁▁▁▁▁▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁███████▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▆▃▂▁▄▆▅▆▃▅▇▃▅▄▄▅▅▃▇▅▆▃▂▇▅▇▆▅▆▄▂▅█▆▄▆▆▄▂▃
wandb:                 train_loss █▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 █████████████████████████▁▁▁▁▁▁█████████
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▁▃████▅██▅██████████████████████████████
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████▁▁▁▁▁▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.44371
wandb:                 train_loss 2.0945
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_78_4_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/suyo5g0u
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/wandb/run-20250701_150318-suyo5g0u/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_4/execution_datetimes.json

**************************************************  Experiment 78 | Version 6 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

✅ Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 4, 1.0: 12}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 1, 1.0: 1}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 4, 1.0: 12}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 1, 1.0: 1}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 1, 1.0: 1}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_154104-qwvyllgu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_6_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/qwvyllgu
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▂▆█▇███████████████████████▇█▇██████▇
wandb:           test_accuracy0.5 █▁▂██▆▆▅▆▆▇▇▇▆▆▆▇▆▆▆▆▆▆▇▇▆▆▇▇▇▆▆▆▆▇▇▇▆▆▆
wandb:          test_accuracy0.75 █████▁▆█▇▆▆▅▆▆▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▅▆▆▆▆▆▆▆▅
wandb:                 test_auroc ▂▄▂▄▁▇█▄▃▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: test_balanced_accuracy0.25 ▄▄▄▄▅▃▄▂▂▁▃▄▁▇█████████▇▇█▇▇▇▇▇▆▆▇▇▇▇▇▇▆
wandb:  test_balanced_accuracy0.5 █▂▄▄▁▇▇▅▃▄▆▆▆▆▆▆▆▆▆▆▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: test_balanced_accuracy0.75 ▅▅▅▅▅▅▅▅▅▆█▄▇▁▅██▇▇▇▇▇▇▇▇▇▇▇███████████▇
wandb:         test_precision0.25 ▁▁▃▄▆▁▂▅▁█████▇▇████▇▇▇▇▇▇▇▇▇▅▇█▆▆▇▅▇▇▅▅
wandb:          test_precision0.5 ▁▅▆▇▇▅▆█████████▇██████████████████████▇
wandb:         test_precision0.75 ▁▁▁▁▁▁▆▆█▃▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test_recall0.25 █████▇▇█▇▄▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂
wandb:             test_recall0.5 ▆▆█▆▇▆▄▄▄▂▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test_recall0.75 ▁▁▁▂▁▅▆█▆▅█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:                train_auroc ▁▂▂▆▇███████████████████████████████████
wandb:                 train_loss ███▆▃▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▂▁▂▂█▅▇▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            val_accuracy0.5 ▁▃██▇▆▇▆▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           val_accuracy0.75 █▆▁▇▇▇▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▆▇▇▇▆▇▇▆
wandb:                  val_auroc ▁█▄▆▆▃▄▆█▅██████████████████▇▇▇▇▇██▇▇▇▇▇
wandb:  val_balanced_accuracy0.25 ▁▁▁▂▁▃▂▆▄▆█▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▅▃▃▃▃▃▃▃▃▃▃▃▃
wandb:   val_balanced_accuracy0.5 ▁▄▃▁▁▄█▇▁▆▃▆▂▅▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▅▄▄▄▄▄
wandb:  val_balanced_accuracy0.75 ▂▂▂▂▂▂▁▃▅▄▄█▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:          val_precision0.25 ▁▁▁▁▂▄▁▄▂▁▄█▄▃▃▅▅▅▅▅▄▃▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:           val_precision0.5 ▆▁▁▆▆▁▆▅▆▇▆▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:          val_precision0.75 ▁▁▁▁▁▄▁▅▁▅█▇███████████████████▇▇█▇███▇▇
wandb:             val_recall0.25 ███▅▆▂▅▃▅▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▆█▁▁▇▂▃▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:             val_recall0.75 ▁▁▁▁▁▄▆▅▆▅██████████████████▇███████████
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.63291
wandb:           test_accuracy0.5 0.64557
wandb:          test_accuracy0.75 0.67089
wandb:                 test_auroc 0.49364
wandb: test_balanced_accuracy0.25 0.53941
wandb:  test_balanced_accuracy0.5 0.51483
wandb: test_balanced_accuracy0.75 0.53178
wandb:         test_precision0.25 0.30435
wandb:          test_precision0.5 0.27778
wandb:         test_precision0.75 0.3125
wandb:            test_recall0.25 0.35
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.25
wandb:                train_auroc 1
wandb:                 train_loss 0.03825
wandb:           val_accuracy0.25 0.64762
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.70476
wandb:                  val_auroc 0.59518
wandb:  val_balanced_accuracy0.25 0.53359
wandb:   val_balanced_accuracy0.5 0.55891
wandb:  val_balanced_accuracy0.75 0.57157
wandb:          val_precision0.25 0.2963
wandb:           val_precision0.5 0.34783
wandb:          val_precision0.75 0.38095
wandb:             val_recall0.25 0.30769
wandb:              val_recall0.5 0.30769
wandb:             val_recall0.75 0.30769
wandb: 
wandb: 🚀 View run vgg16_2d_78_6_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/qwvyllgu
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_154104-qwvyllgu/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_161036-n8g0apz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_6_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/n8g0apz3
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading history steps 214-214, summary, console lines 4-5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▂▁▂▆▄▄▄▆█▇█▇▇▇▇▇▇▇██▇▇▇▇▇▇██▇▇█▇█▇█▇▇▇
wandb:           test_accuracy0.5 █▁▃█▅▃▅▆▅▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:          test_accuracy0.75 ███▇█▇▁▁▆▄▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂
wandb:                 test_auroc ██▁▁▅▄▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▆
wandb: test_balanced_accuracy0.25 ▄▆▆▆▃▇▇█▁▅▄▅▄▃▂▃▄▄▄▃▄▅▅▄▄▃▄▅▄▅▅▅▅▅▅▂▅▄▅▅
wandb:  test_balanced_accuracy0.5 ▆▆▆██▁▂▃▄▄▃▄▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▃▃▃▄▄▄▃▄▃▄
wandb: test_balanced_accuracy0.75 ████▁▁▃▄▃▄▃▃▂▃▃▃▃▃▂▅▂▃▂▄▄▃▂▂▂▄▄▄▂▄▄▄▄▄▄▄
wandb:         test_precision0.25 ▆▆▅▆▆█▄▃▁▃▃▁▁▂▁▂▂▂▁▁▂▂▃▃▃▃▄▃▅▃▃▅▄▄▄▃▄▂▄▂
wandb:          test_precision0.5 ▇█▁▃▇▆█▄▃▃▃▃▃▃▄▃▄▄▄▄▅▃▅▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▆▅▃█▇▄▄▄▄▄▄▄▄▄▄▄▄▄▆▄▄▄▄▆▄▆▆▆▆▆▆▄▄
wandb:            test_recall0.25 ██▃▅▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂
wandb:             test_recall0.5 ▁█▇▇▆▄▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test_recall0.75 ▁▁▁▁▁▁█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▃▃▆▃▆▃▆▆▆▆▆▆▆▆▃
wandb:                train_auroc ▁▂▄▆▆▆▇▇▇███████████████████████████████
wandb:                 train_loss █▇█▇▇▅▄▂▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▃▃▄▄▄▇▅███████████████████▇██▇▇▇▇██▇▇
wandb:            val_accuracy0.5 ██▁▃▃▁▁▃▃▅▆▆▆▆▆▆▆▆▆▅▅▆▅▅▆▆▆▆▅▆▆▅▆▆▆▅▅▅▅▅
wandb:           val_accuracy0.75 ██▃▇▇▄▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▂▃▂▂▂▂▂▃▃
wandb:                  val_auroc ▁▇▆█▆▆▆▆▆▅▅▅▅▆▆▆▆▆▆▆▅▅▆▆▆▅▅▅▅▅▆▆▆▆▆▅▅▅▅▅
wandb:  val_balanced_accuracy0.25 ▅▁▅█▂▄█▃▅▂▅▅▅▅▅▅▅▅▄▄▄▅▅▅▄▄▄▅▅▄▅▄▅▄▄▅▄▄▅▄
wandb:   val_balanced_accuracy0.5 ▃▃▄▆█▆▃▁▃▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▄▄▃▃▃▄▄▄▄▄▄▄▃
wandb:  val_balanced_accuracy0.75 ▇▄▇▆█▅▅▁▇▇▇▇█▇█▇██▇▇▇▇▇█▇██▇▇▇▇████▇▇▇▇▆
wandb:          val_precision0.25 ▅▅▆▇█▄▅▇▁▁▇▅▅▅▅▅▅▅▄▄▄▄▅▅▄▄▃▇▄▄█▆▃▄▄██▇▃▆
wandb:           val_precision0.5 ▁▇██▆▆▄▇████████████████▇██▇▇██▇█▇█▇▇▇▇▇
wandb:          val_precision0.75 ▁▁▁▁▁▁▇▄▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:             val_recall0.25 ████▄▅▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 █▆▆▄▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁█▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.62025
wandb:           test_accuracy0.5 0.63291
wandb:          test_accuracy0.75 0.63291
wandb:                 test_auroc 0.49322
wandb: test_balanced_accuracy0.25 0.48136
wandb:  test_balanced_accuracy0.5 0.45678
wandb: test_balanced_accuracy0.75 0.44025
wandb:         test_precision0.25 0.22222
wandb:          test_precision0.5 0.15385
wandb:         test_precision0.75 0.09091
wandb:            test_recall0.25 0.2
wandb:             test_recall0.5 0.1
wandb:            test_recall0.75 0.05
wandb:                train_auroc 0.99973
wandb:                 train_loss 0.03434
wandb:           val_accuracy0.25 0.61905
wandb:            val_accuracy0.5 0.6381
wandb:           val_accuracy0.75 0.64762
wandb:                  val_auroc 0.47493
wandb:  val_balanced_accuracy0.25 0.4888
wandb:   val_balanced_accuracy0.5 0.50146
wandb:  val_balanced_accuracy0.75 0.50779
wandb:          val_precision0.25 0.23077
wandb:           val_precision0.5 0.25
wandb:          val_precision0.75 0.26087
wandb:             val_recall0.25 0.23077
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.23077
wandb: 
wandb: 🚀 View run vgg16_2d_78_6_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/n8g0apz3
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_161036-n8g0apz3/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_163840-67lminf8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_6_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/67lminf8
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▆█▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           test_accuracy0.5 ▁▇▇▅▇█▆▅▆▆▆▅▅▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:          test_accuracy0.75 ███▅▅▁▄▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:                 test_auroc ▁▂▁█▇▃▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅
wandb: test_balanced_accuracy0.25 ▇▇▇▇█▃▆▄▅▆▆▁▃▃▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:  test_balanced_accuracy0.5 ▇▆▂█▄▃▂▄▄▃▃▃▂▂▂▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb: test_balanced_accuracy0.75 ▅▅█▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▅▅▆█▅▃▅▂▄▄▄▄▄▄▄▃▁▃▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:          test_precision0.5 ▄▅█▄█▅▅▅▄▇▄▃▃▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.75 ▁▇█▁▇▆▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test_recall0.25 █████▅▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 █▂▂▂▅▄▄▂▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.75 ▁█▁▁▅▇▂▅█▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:                train_auroc ▁▂▄▆▇███████████████████████████████████
wandb:                 train_loss ██▆▅▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▆▅▇▇▇███▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            val_accuracy0.5 ██▁▂▄▅▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:           val_accuracy0.75 ▇▇▇▇▇▁██▄▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:                  val_auroc ▁▃▁▄▅▆▅▆█▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:  val_balanced_accuracy0.25 ▁▁▃▂▅▅▅▄▄█▇▄▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:   val_balanced_accuracy0.5 ▃▃▃█▅▄▃▄▄▄▄▄▄▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▂▄▂█▄▅▅▄▄▄▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:          val_precision0.25 ▁▁▁▁▂▅▅█▅▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:           val_precision0.5 ▁▆▅▇▇▇███▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇
wandb:          val_precision0.75 ▁▁▁▅▇▇▇▇█▇▇▇▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:             val_recall0.25 ████▃▄▂▂▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁█▇▇█▄▃▃▇▅▄▃▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:             val_recall0.75 ▁▁▁▁▁█▇▇▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.58228
wandb:           test_accuracy0.5 0.58228
wandb:          test_accuracy0.75 0.59494
wandb:                 test_auroc 0.54068
wandb: test_balanced_accuracy0.25 0.45593
wandb:  test_balanced_accuracy0.5 0.43941
wandb: test_balanced_accuracy0.75 0.44788
wandb:         test_precision0.25 0.19048
wandb:          test_precision0.5 0.15789
wandb:         test_precision0.75 0.16667
wandb:            test_recall0.25 0.2
wandb:             test_recall0.5 0.15
wandb:            test_recall0.75 0.15
wandb:                train_auroc 1.0
wandb:                 train_loss 1e-05
wandb:           val_accuracy0.25 0.67619
wandb:            val_accuracy0.5 0.66667
wandb:           val_accuracy0.75 0.66667
wandb:                  val_auroc 0.62634
wandb:  val_balanced_accuracy0.25 0.56548
wandb:   val_balanced_accuracy0.5 0.54625
wandb:  val_balanced_accuracy0.75 0.53335
wandb:          val_precision0.25 0.34615
wandb:           val_precision0.5 0.32
wandb:          val_precision0.75 0.30435
wandb:             val_recall0.25 0.34615
wandb:              val_recall0.5 0.30769
wandb:             val_recall0.75 0.26923
wandb: 
wandb: 🚀 View run vgg16_2d_78_6_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/67lminf8
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/wandb/run-20250701_163840-67lminf8/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_6/execution_datetimes.json

**************************************************  Experiment 78 | Version 7 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

✅ Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 12, 1.0: 20}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 11, 1.0: 7}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 12, 1.0: 20}
    Batch label distribution: {0.0: 20, 1.0: 12}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 10, 1.0: 8}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 6, 1.0: 26}
    Batch label distribution: {0.0: 12, 1.0: 20}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 8, 1.0: 10}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_165921-4ayj65le
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_7_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4ayj65le
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▅▅▂▄▆█▇▇███████████████████████████
wandb:           test_accuracy0.5 ▂▄▂▁█▃▂▄▄▄▅▅▄▃▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:          test_accuracy0.75 █████▂▃▅▁▃▄▄▄▄▄▄▄▃▃▃▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄
wandb:                 test_auroc ▅▆▇▆▁▅█▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: test_balanced_accuracy0.25 ▅▅▅▅▅▅▅▁▂▁▇████▇▇▇▆▆▆▆▇▇▆▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇
wandb:  test_balanced_accuracy0.5 ▇▆▆▄▅▄▆▃▁▆▅▆███▇▇███▇▇▇▇▇▇▇▇██▇▇▇▇▇█████
wandb: test_balanced_accuracy0.75 ▆▆▆▃▁▂▆█▅▆▅▅▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆
wandb:         test_precision0.25 ▃▃▃▄▂▂▃▄▁█▇███▇▇▇▇▇▇▇▇▆▆▇▆▆▆▇▇▇▆▆▆▆▇▇▇▇▇
wandb:          test_precision0.5 ▁▁▁▆▄▅▄▇▅▅▆▇██▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇████████
wandb:         test_precision0.75 ▁▁▁▁▁▆█▆▃▄▇▆▆▅▇▇▇▇▇▇▅▅▆▅▅▅▅▅▅▅▅▅▅▅▇▅▅▅▅▇
wandb:            test_recall0.25 █▇▇▄▄▂▂▂▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 █▁▁▁▁▁▁▇▇▆▅▃▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test_recall0.75 ▁▁▁▁▁▅█▇▇▅▇▇▇▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇
wandb:                train_auroc ▁▂▂▃▂▃▅█████████████████████████████████
wandb:                 train_loss ████████▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▂▄▃▄▆▇▇███████████████████▇▇▇▇▇▇▇▇
wandb:            val_accuracy0.5 ██▁▃▄▆▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           val_accuracy0.75 ███▆▇▁▄▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:                  val_auroc ▄▂▅▅▆▇▄▅▅█▁▂▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:  val_balanced_accuracy0.25 ▂▂▂▆▂▆▅▆██▁▆▆▅▇▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:   val_balanced_accuracy0.5 ▅▅▇▆▁█▄▇▄██▆▆▇▆▇▇▇▇▆▆▆▇▇▇▇▇▇▆▆▆▇▇▆▆▆▆▆▆▆
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁█▂▅▂█▇▆▂▇▄▄▄▆▆▆▆▆▆▆▆▄▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:          val_precision0.25 ▁▁▁▁▁▄▃▅█▆▇▆▇▆▆▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▃▃▃
wandb:           val_precision0.5 ▅▁▁▁▁▆▁▆▅▇█▇▆█▅█████████████████████████
wandb:          val_precision0.75 ▁▁▁▁▁▁▇█▆█▅▇▇▇▇████▇▇▇▇████▇▇███████████
wandb:             val_recall0.25 ███▆▆▃▄▃▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 █▁▁▁▁█▇▇▆▆▅▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:             val_recall0.75 ▁▁▁▇▆▅▃▅▄█▄▄▄▅▅▅▅▅▄▄▅▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.64557
wandb:           test_accuracy0.5 0.67089
wandb:          test_accuracy0.75 0.65823
wandb:                 test_auroc 0.51737
wandb: test_balanced_accuracy0.25 0.54788
wandb:  test_balanced_accuracy0.5 0.53178
wandb: test_balanced_accuracy0.75 0.50678
wandb:         test_precision0.25 0.31818
wandb:          test_precision0.5 0.3125
wandb:         test_precision0.75 0.26667
wandb:            test_recall0.25 0.35
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.2
wandb:                train_auroc 0.99936
wandb:                 train_loss 0.06128
wandb:           val_accuracy0.25 0.65714
wandb:            val_accuracy0.5 0.71429
wandb:           val_accuracy0.75 0.72381
wandb:                  val_auroc 0.60419
wandb:  val_balanced_accuracy0.25 0.52702
wandb:   val_balanced_accuracy0.5 0.565
wandb:  val_balanced_accuracy0.75 0.57132
wandb:          val_precision0.25 0.29167
wandb:           val_precision0.5 0.38889
wandb:          val_precision0.75 0.41176
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.26923
wandb: 
wandb: 🚀 View run vgg16_2d_78_7_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4ayj65le
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_165921-4ayj65le/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_172806-mk8z6too
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_7_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/mk8z6too
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▆▅▆▅▆▅█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           test_accuracy0.5 ▃▄▄▂▁▅▅█▆▇▆█████████████████████████████
wandb:          test_accuracy0.75 ██▇▅▅▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃
wandb:                 test_auroc █▅▇▄▁▆▄▃▄▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: test_balanced_accuracy0.25 ▅▅▆█▇▃▆▁▄▂▆▄▆▆▆▄▄▄▆▆▄▄▄▄▄▄▄▅▄▄▄▁▄▆▄▄▄▄▅▄
wandb:  test_balanced_accuracy0.5 ▅▇▅▁█▇▄▆▇▇▆▆▇▅▇▅▅▇▇▅▇▇▇▅▅▅▅▅▅▅▅▆▆▆▇▅▅▅▅▅
wandb: test_balanced_accuracy0.75 ██▁▃▄▃▂█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁
wandb:         test_precision0.25 ▆▆▇█▂▁▄▅▆▆▅███▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▅▅▅▅▅█▅
wandb:          test_precision0.5 █▇▃▇▂▅▄▃▇▆▅▃▃▃▄▄▄▄▄▃▄▄▄▁▄▁▁▄▁▁▁▁▂▂▃▁▁▁▁▁
wandb:         test_precision0.75 ▁▁▁▄▅▆▇▅▆█▆█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test_recall0.25 ███▅▄▁▁▂▂▂▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▄▇▅█▂▂▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb:            test_recall0.75 ▁▁▅▂█▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄
wandb:                train_auroc ▁▁▂▆▆███████████████████████████████████
wandb:                 train_loss ██▅▆▅▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▂▂▄▃█▅▆▇█▇▇▇██████████████▇█▇▇██▇▇▇▇▇
wandb:            val_accuracy0.5 ▂█▂▁▃▅▅▆▅▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▆▆▆▆▆▆▆▆
wandb:           val_accuracy0.75 ███▃▃▂▁▃▃▃▃▃▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▂▂▂▂▂▂
wandb:                  val_auroc ▅▄▇▇▁▃▄▄▄▃█▅▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:  val_balanced_accuracy0.25 ▆▁▆▇▃▆▇▆█▅▆▆▇▇▇▆▇▇▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▆▆
wandb:   val_balanced_accuracy0.5 ▁▇▂▄▁▂▃▃▂▃▇▄█▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▃▁
wandb:  val_balanced_accuracy0.75 ▃▃▃▃▄▁▁▃▃▅▆█▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂
wandb:          val_precision0.25 ▅▅▃▆▅▁▆▅▂▆█▂▅▇▇▇▇▇▅▇▅▇▇▅▅▄▅▄▄▅▄▄▄▄▄▅▄▄▄▄
wandb:           val_precision0.5 ▆▄▁▆▇▄▅▄▆█▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▅▅▅▅▄
wandb:          val_precision0.75 ▁▁▃▇█▄▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:             val_recall0.25 █▄█▄▅▅▃▃▄▃▁▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▇█▇▁▄▆▄▅▃▂▄▆▆▄▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃▂▃▂▂▂▃▃▃▃▂
wandb:             val_recall0.75 ▁▂▁▁▂█▇▂▄▇▇▆▇█▄█▄▅▅▅▅▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.60759
wandb:           test_accuracy0.5 0.60759
wandb:          test_accuracy0.75 0.62025
wandb:                 test_auroc 0.49873
wandb: test_balanced_accuracy0.25 0.48941
wandb:  test_balanced_accuracy0.5 0.43983
wandb: test_balanced_accuracy0.75 0.44831
wandb:         test_precision0.25 0.2381
wandb:          test_precision0.5 0.13333
wandb:         test_precision0.75 0.14286
wandb:            test_recall0.25 0.25
wandb:             test_recall0.5 0.1
wandb:            test_recall0.75 0.1
wandb:                train_auroc 0.99973
wandb:                 train_loss 0.0337
wandb:           val_accuracy0.25 0.61905
wandb:            val_accuracy0.5 0.6381
wandb:           val_accuracy0.75 0.6381
wandb:                  val_auroc 0.5129
wandb:  val_balanced_accuracy0.25 0.4888
wandb:   val_balanced_accuracy0.5 0.48856
wandb:  val_balanced_accuracy0.75 0.48856
wandb:          val_precision0.25 0.23077
wandb:           val_precision0.5 0.22727
wandb:          val_precision0.75 0.22727
wandb:             val_recall0.25 0.23077
wandb:              val_recall0.5 0.19231
wandb:             val_recall0.75 0.19231
wandb: 
wandb: 🚀 View run vgg16_2d_78_7_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/mk8z6too
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_172806-mk8z6too/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_175407-4fttunxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_7_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4fttunxw
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▆▆▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           test_accuracy0.5 ▃▆▅▁▅▇▇▆▇██▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:          test_accuracy0.75 ████▇▃▃▃▂▁▄▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▂▂▃▃▃
wandb:                 test_auroc ▂▁▁▆▆▅▄▅▄▅▅▅▄▃▄▇▇▇███▇██████████████████
wandb: test_balanced_accuracy0.25 ▅▅▅▅▅▆▇█▄▃▂▅▂▄▂▂▃▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂
wandb:  test_balanced_accuracy0.5 ▇▄██▄▇▆▃▁▃▃▆▄▅▅▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ██▅██▄▅▃▄▅▄▆▇▃▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂
wandb:         test_precision0.25 ▆▆▆▇█▄▃▆▁▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃
wandb:          test_precision0.5 ▇▇█▅▄█▃▄▆▄▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▇█▆█▇▆▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test_recall0.25 █▅▅▅▄▃▁▂▃▃▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 █▁▁▆▇▃▅▃▃▃▅▃▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test_recall0.75 ▁▁▁▁█▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:                train_auroc ▃▃▂▁▄▆▇▇▇███████████████████████████████
wandb:                 train_loss █▇▅▅▃▃▁▁▁▁▁▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▂▅▇▆▇█▇█▇▇▇▇████████████████████████
wandb:            val_accuracy0.5 ▁██▅▅▆▇▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           val_accuracy0.75 ██▁▇▃█▃▄▄▃▄▄▅▄▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:                  val_auroc ▂▁▃▅▂▃▅▅▅▆█▇▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:  val_balanced_accuracy0.25 ▁▁▃▃█▃▅▄▂▂▅▆▇▆█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:   val_balanced_accuracy0.5 ▅▁▄█▅▇▂▃▄▆█▅█▅▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:  val_balanced_accuracy0.75 ▁▁▃▃▅▃▃▇▄▇▅█▅▃▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:          val_precision0.25 ▁▁▂▃▅▂█▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           val_precision0.5 ▁▇▆▇▆▇▇▆█▇▆█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:          val_precision0.75 ▁▁▁▁▁▇▇▆▇▆▇█▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:             val_recall0.25 ████▄▃▂▃▃▂▁▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:              val_recall0.5 ▁▁▇▆█▆▄▄▃▄▄▅▅▃▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:             val_recall0.75 ▁▁▁▁▃▂▅▅▄▅█▆▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.55696
wandb:           test_accuracy0.5 0.55696
wandb:          test_accuracy0.75 0.58228
wandb:                 test_auroc 0.56186
wandb: test_balanced_accuracy0.25 0.40593
wandb:  test_balanced_accuracy0.5 0.40593
wandb: test_balanced_accuracy0.75 0.42288
wandb:         test_precision0.25 0.10526
wandb:          test_precision0.5 0.10526
wandb:         test_precision0.75 0.11765
wandb:            test_recall0.25 0.1
wandb:             test_recall0.5 0.1
wandb:            test_recall0.75 0.1
wandb:                train_auroc 1
wandb:                 train_loss 0.0
wandb:           val_accuracy0.25 0.65714
wandb:            val_accuracy0.5 0.65714
wandb:           val_accuracy0.75 0.65714
wandb:                  val_auroc 0.56767
wandb:  val_balanced_accuracy0.25 0.55282
wandb:   val_balanced_accuracy0.5 0.55282
wandb:  val_balanced_accuracy0.75 0.55282
wandb:          val_precision0.25 0.32143
wandb:           val_precision0.5 0.32143
wandb:          val_precision0.75 0.32143
wandb:             val_recall0.25 0.34615
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.34615
wandb: 
wandb: 🚀 View run vgg16_2d_78_7_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/4fttunxw
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/wandb/run-20250701_175407-4fttunxw/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_7/execution_datetimes.json

**************************************************  Experiment 78 | Version 9 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

✅ Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 37, 1.0: 27}
    Batch label distribution: {0.0: 34, 1.0: 30}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 11, 1.0: 7}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 38, 1.0: 26}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 28, 1.0: 36}
    Batch label distribution: {0.0: 8, 1.0: 10}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 30, 1.0: 34}
    Batch label distribution: {0.0: 28, 1.0: 36}
    Batch label distribution: {0.0: 8, 1.0: 10}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_181320-caqwg6zj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_9_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/caqwg6zj
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▃▁▁▃▆▃▅▅▅▇▇█▇▇▇██████████████████▇▇
wandb:           test_accuracy0.5 ▁▄█▁█▂▄▄▅▄▄▆▆▅▇▇▅▆▆▅▆█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:          test_accuracy0.75 █████▄▁▇▆▆▇▅▂▅█▆▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:                 test_auroc ▅▄▅▄▂▃▄▃▁▆▇▆▄██▅▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: test_balanced_accuracy0.25 ▄▄▄▄▄▅▄▁▄▆▂▃▁▃▇▅█▅▄▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▆
wandb:  test_balanced_accuracy0.5 ▇▄▁▁▅▂▅▇▃▄▅▆▇▅▇▆▇▃▇▄▇▇▆▆▆███▆████████▇▆█
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▂▇▂█▂▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:         test_precision0.25 ▂▂▂▂▃▁▂▁▂▁▄▃▇▄▂▃▅▄▃▄█▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:          test_precision0.5 ▅▄▄▄▁▄▄▄▄▃▄▃▅▄▄▃▄▅█▄▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▄▅
wandb:         test_precision0.75 ▁▁▁▁▁▂▂▃▃▂▃▄▂▄▃▃▂▂█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test_recall0.25 ██▆██▅▅▅▂█▄▃▂▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 █▇▅█▅▁▃▄▃▂▁▂▁▂▂▂▂▁▁▁▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂
wandb:            test_recall0.75 ▁▁▁▁▁▁▅▃▇▆▆▆▂▆█▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:                train_auroc ▁▄▄▃▄▅▄▆▇▇██████████████████████████████
wandb:                 train_loss ███▇▇▆▇▆▄▂▂▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▃▁▆▄▃▃▅▅██▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            val_accuracy0.5 █▆█▁▃▃▅▇▃▆▅▅▇▆▆▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           val_accuracy0.75 ██████████▇▁▄▇▆▅▆█▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:                  val_auroc ▄▇▇▁▃▅▇▅▅▆█▇▆▇▆▆▇█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▄▆▁█▄▃▄▆▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:   val_balanced_accuracy0.5 ▇▅▇▆▁▃▄▅██▆▇▅▅▅▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅
wandb:  val_balanced_accuracy0.75 ▁▁▁▁█▃▅▄▁▂▃▅▃▅▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅▆▆▆
wandb:          val_precision0.25 ▁▁▁▁▁▂▂▃▂▁▇▆▄▆▅▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:           val_precision0.5 ▆▅▆▁▅▆▆▄▄▇▇▆▇█▆▇▆▆▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆
wandb:          val_precision0.75 ▁▁▁▁▅▇▁▇▄▇▄▅▆▇▆█▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇
wandb:             val_recall0.25 █▆█████▆▇▇▄▂▁▅▃▂▅▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▆▁▃▁▅▁▆█▇▅▆▆▆▃▄▅▄▃▆▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:             val_recall0.75 ▁▁▁▁▂▄▂▃▆▃▄▂█▅█▃▃▃▅▅▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▄▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.63291
wandb:           test_accuracy0.5 0.68354
wandb:          test_accuracy0.75 0.6962
wandb:                 test_auroc 0.50254
wandb: test_balanced_accuracy0.25 0.53941
wandb:  test_balanced_accuracy0.5 0.54025
wandb: test_balanced_accuracy0.75 0.51568
wandb:         test_precision0.25 0.30435
wandb:          test_precision0.5 0.33333
wandb:         test_precision0.75 0.3
wandb:            test_recall0.25 0.35
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.15
wandb:                train_auroc 1
wandb:                 train_loss 0.03415
wandb:           val_accuracy0.25 0.64762
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.72381
wandb:                  val_auroc 0.58569
wandb:  val_balanced_accuracy0.25 0.52069
wandb:   val_balanced_accuracy0.5 0.54601
wandb:  val_balanced_accuracy0.75 0.57132
wandb:          val_precision0.25 0.28
wandb:           val_precision0.5 0.33333
wandb:          val_precision0.75 0.41176
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.26923
wandb: 
wandb: 🚀 View run vgg16_2d_78_9_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/caqwg6zj
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_181320-caqwg6zj/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_184013-yc223myu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_9_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/yc223myu
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▅▁▃█▅▆▇▅█▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           test_accuracy0.5 ▂▆▁▂▄█▃▅▅▃▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▃▄▃
wandb:          test_accuracy0.75 ▄█▃▁▂▄▇▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:                 test_auroc ▃▃▅▅█▃▄▅▁▃▃▃▂▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb: test_balanced_accuracy0.25 ▆▅▆▇▅▇█▄▅▄▅▆█▇▂▃▃▄▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:  test_balanced_accuracy0.5 ▇███▄▅▁▄▅▆▃▃▄▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb: test_balanced_accuracy0.75 ██▃▅▅▅▅▄▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         test_precision0.25 █▇█▇▇▅▇▇▆▅▄▄▆▃▅▄▃▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄
wandb:          test_precision0.5 ▁▁█▇▇▆▃▄▄▄▂▄▃▂▃▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         test_precision0.75 ▁▁▁▁▄▃▃▂█▄▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test_recall0.25 ███▂▃▃▂▂▄▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂
wandb:             test_recall0.5 ▅▇█▄▅▄▂▂▂▂▃▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test_recall0.75 ▁▃▁▁▆▃▆█▆▃▃▃▆▃█▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:                train_auroc ▁▁▁▅▅█▇▇████████████████████████████████
wandb:                 train_loss ████▇▆▅▄▄▃▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▂▂▄▅▄▃▆█▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇
wandb:            val_accuracy0.5 ▁█▃▅▃▃▆▄▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:           val_accuracy0.75 ███▆▁▅▃▅▆▃▅▅▅▅▆▆▆▆▆▆▅▅▅▅▅▅▆▅▆▅▆▅▆▆▆▆▆▆▅▅
wandb:                  val_auroc ▃█▇▅▆▄▆▁▇▄▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▃▄▄▄▄▄▄▄
wandb:  val_balanced_accuracy0.25 ▅▇▃█▅▅▅▆▁▇▄▄▃▅▅▅▅▅▅▅▅▅▄▅▅▄▅▅▅▅▆▆▅▅▅▅▅▅▅▅
wandb:   val_balanced_accuracy0.5 ▅█▃▁▂▆▁▃▂▃▁▂▁▄▃▃▃▄▄▄▄▄▄▄▃▃▄▄▄▄▃▄▄▄▄▄▄▄▄▄
wandb:  val_balanced_accuracy0.75 ▆▄▆▇▆▆▆█▇▅▁▂▇▂▂▅▅▅▅▅▅▄▂▁▁▁▁▁▂▂▅▅▅▂▂▅▇▇▇▅
wandb:          val_precision0.25 ▆▆▇█▆▂▃▄▆▃▇▁▃▂▃▃▃▂▂▂▂▂▂▂▃▄▄▄▄▄▅▄▄▅▄▄▄▄▄▄
wandb:           val_precision0.5 █▅▆▃▆▆▄▁▅▅▅▅▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅▆▅▅▅▅▅▅▅
wandb:          val_precision0.75 ▁█▁▁▃▃▅▅▄▁▅▅▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▄
wandb:             val_recall0.25 ▇██▆▅▃▃▂▃▂▃▄▂▃▃▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▃▆▆▇█▆▃▅▃▃▄▃▄▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:             val_recall0.75 ▃▁▁▆▁▂▅▂█▅▆▅▇▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▆▆████████
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.55696
wandb:           test_accuracy0.5 0.55696
wandb:          test_accuracy0.75 0.56962
wandb:                 test_auroc 0.43729
wandb: test_balanced_accuracy0.25 0.42246
wandb:  test_balanced_accuracy0.5 0.38941
wandb: test_balanced_accuracy0.75 0.39788
wandb:         test_precision0.25 0.14286
wandb:          test_precision0.5 0.05882
wandb:         test_precision0.75 0.0625
wandb:            test_recall0.25 0.15
wandb:             test_recall0.5 0.05
wandb:            test_recall0.75 0.05
wandb:                train_auroc 0.99955
wandb:                 train_loss 0.06291
wandb:           val_accuracy0.25 0.6
wandb:            val_accuracy0.5 0.62857
wandb:           val_accuracy0.75 0.6381
wandb:                  val_auroc 0.44133
wandb:  val_balanced_accuracy0.25 0.47614
wandb:   val_balanced_accuracy0.5 0.49513
wandb:  val_balanced_accuracy0.75 0.50146
wandb:          val_precision0.25 0.21429
wandb:           val_precision0.5 0.24
wandb:          val_precision0.75 0.25
wandb:             val_recall0.25 0.23077
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.23077
wandb: 
wandb: 🚀 View run vgg16_2d_78_9_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/yc223myu
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_184013-yc223myu/logs
wandb: creating run
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_191001-m0jn6pyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_9_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/m0jn6pyy
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▅▅▃▇█▇▇█▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           test_accuracy0.5 ▅▁▅▁▂▅█▇▅▆▆▇▇▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:          test_accuracy0.75 ██████▃▆▄▁▃▃▄▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:                 test_auroc ▇▆▅▅█▄▄▁▃▂▅▆▂▅▅▄▅▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄
wandb: test_balanced_accuracy0.25 ██▆█▇█▁▁▄▆▃▆▅▁▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:  test_balanced_accuracy0.5 ▆█▇▄▄▁▃▄▅▆▅█▆▆▆▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: test_balanced_accuracy0.75 ▇▇█▇▇▂▁▇▂▃▇▇▇▇▇▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         test_precision0.25 ████▇█▆▅▇▁█▆▆▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅
wandb:          test_precision0.5 ▁▁█▇█▇█▆▄▅▅▅▄▅▆▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:         test_precision0.75 ▁▁▁▁▁▁▃█▄▅▄▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test_recall0.25 █████▃▄▇▃▅▂▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▆██▄▂▅▄▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test_recall0.75 ▁▃▁▁▁▃▃▆▆▅▆▅▃▅██████████████████████████
wandb:                train_auroc ▁▂▁▄▅▇▇▇████████████████████████████████
wandb:                 train_loss ████▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▄▁▃▄▆▇██████▇▇▇▇▇▇▇▇▇▇████████████████
wandb:            val_accuracy0.5 ██▂▁▅▆▆▄▄▆▆▇▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆
wandb:           val_accuracy0.75 ██████▁▅▄▆▅█▄▅▆▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:                  val_auroc ▆▁█▆█▅█▅▃▃▆▅▇▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:  val_balanced_accuracy0.25 ▂▂▇▆▇▁▄▁▄▆█▅▅▆▆▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:   val_balanced_accuracy0.5 ▁▆▇▅▂▁▃▄▂▇▇▇▇▇▇█████████████████████████
wandb:  val_balanced_accuracy0.75 ▂▂▂▂▂▁▁▂▃▅▅▄▅▆█▆████████████████████████
wandb:          val_precision0.25 ▂▂▃▂▃▁▂▃▁▃▇▆▇▅█▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:           val_precision0.5 ▅▁▁▆▁▅▅▅▆▆▅█▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:          val_precision0.75 ▄▁▁▁▁▁█▁▇▅▄▅▄▆▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:             val_recall0.25 ██▇█▆▅▇▃▄▅▄▄▃▂▃▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:              val_recall0.5 █▇▁▇█▁▄▂▃▃▄▂▄▃▃▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:             val_recall0.75 ▁▁▁▁▁▃▂▇▅▆▆▇████████████████████████████
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.59494
wandb:           test_accuracy0.5 0.60759
wandb:          test_accuracy0.75 0.64557
wandb:                 test_auroc 0.45424
wandb: test_balanced_accuracy0.25 0.46441
wandb:  test_balanced_accuracy0.5 0.47288
wandb: test_balanced_accuracy0.75 0.49831
wandb:         test_precision0.25 0.2
wandb:          test_precision0.5 0.21053
wandb:         test_precision0.75 0.25
wandb:            test_recall0.25 0.2
wandb:             test_recall0.5 0.2
wandb:            test_recall0.75 0.2
wandb:                train_auroc 1
wandb:                 train_loss 1e-05
wandb:           val_accuracy0.25 0.67619
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.72381
wandb:                  val_auroc 0.55501
wandb:  val_balanced_accuracy0.25 0.56548
wandb:   val_balanced_accuracy0.5 0.57181
wandb:  val_balanced_accuracy0.75 0.59713
wandb:          val_precision0.25 0.34615
wandb:           val_precision0.5 0.36
wandb:          val_precision0.75 0.42857
wandb:             val_recall0.25 0.34615
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.34615
wandb: 
wandb: 🚀 View run vgg16_2d_78_9_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/m0jn6pyy
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/wandb/run-20250701_191001-m0jn6pyy/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_9/execution_datetimes.json

**************************************************  Experiment 78 | Version 11 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

✅ Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 3, 1.0: 13}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 1, 1.0: 1}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 3, 1.0: 13}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 2}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {1.0: 2}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_194151-lc0p70m1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_11_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/lc0p70m1
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▃▅▅▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇█▇
wandb:           test_accuracy0.5 ▆▃█▁▁▅▇▆▇▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▇▆▆▇▇▆▆▆▆▆▆▆
wandb:          test_accuracy0.75 █████▆▃▃▂▅▄▅▄▅▄▄▄▃▄▃▄▄▄▄▄▃▄▃▃▃▁▁▁▄▃▃▄▃▃▄
wandb:                 test_auroc ▄▄▄▃▄▁▃▅▇▆▇███▇▇██████████▇▇█▇██▇███████
wandb: test_balanced_accuracy0.25 ▂▃▂▂▂▁▂█▂▃▄▄▄▅▅▅▄▄▄▄▅▅▅▅▅▄▄▅▅▆▅▅▅▅▄▄▅▅▄▅
wandb:  test_balanced_accuracy0.5 ▂▁▃▄▄▆█▅▆▅▅▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▅▆▅▆▆
wandb: test_balanced_accuracy0.75 ▃▃▃▃▃▃▃▁▃█▁▄▃▄▄▃▄▃▄▄▅▆▄▄▄▄▄▅▅▄▄▄▄▂▄▂▂▄▄▅
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▃▂▄▄▄▅▄▄▅▄▅▆▄▄▆▇▅▆▅▅▄▄▅▅▆▄▄▄█▆
wandb:          test_precision0.5 ▃▂▂▂▁▃▄▄▆▆▄█▆▄▄█▆▄▅▅▄▄▅▅▄▅▆▆▆▅▅▅▆▄▄▃▅▄▄▄
wandb:         test_precision0.75 ▁▁▁▁▁█▆▆█▅▆▃▅▆▅▆▅▆▅▆▅▅▅▅▅▅▅▅▅▅▆▅▅▅▄▄▅▅▅▅
wandb:            test_recall0.25 █████▆▆▅▄▅▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂
wandb:             test_recall0.5 ██▂▆█▄▇▁▁▆▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂
wandb:            test_recall0.75 ▁▁▁▁▂▄█▅▄▅▄▄▇▄▇▇▇▅▅▅▅▇▅▅▅▅▅▅▇▅▅▇▇▅▅▅▇▅▄▇
wandb:                train_auroc ▁▄▅█████████████████████████████████████
wandb:                 train_loss ████▇▇▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▅▅███▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇
wandb:            val_accuracy0.5 ▄▁█▁▂▄▆▆▆▆▅▇▅▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▆
wandb:           val_accuracy0.75 █████▇█▄▄▄▃▄▄▃▄▄▄▄▄▄▄▄▄▄▄▅▃▃▅▂▅▁▄▃▂▄▄▅▅▄
wandb:                  val_auroc ▇▇▆▅▇▆▁▃▆▆█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄
wandb:  val_balanced_accuracy0.25 ▅▅▅▅▅▅█▆▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▁▁▂▂▂
wandb:   val_balanced_accuracy0.5 ▆▄▅█▁█▃▃▄▄▄▂▃▃▃▃▃▃▄▃▃▃▃▃▃▄▃▃▃▃▄▁▂▂▁▃▃▃▄▂
wandb:  val_balanced_accuracy0.75 ▆▆▆▆▆▁▂▄█▇▃▆▅▄▅▅▄▄▅▅▄▄▅▅▄▄▄▆▆▄▄▄▄▂▂▃▄▆▅▂
wandb:          val_precision0.25 ▇▇▇▇▇▇▇██▅▂▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂
wandb:           val_precision0.5 █▂▇▅▄▇▇▆▅▅▃▂▂▂▃▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▃▃▂▂▂▂▃▄▁▂
wandb:          val_precision0.75 ▁▁▁▁▁▁▁█▆▁▆▄▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇█▆▇██▆▆
wandb:             val_recall0.25 █████▆▅▆▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▆█▃▅▆▄▁▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:             val_recall0.75 ▁▁▁▁▁▇▁█▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.67089
wandb:           test_accuracy0.5 0.6962
wandb:          test_accuracy0.75 0.6962
wandb:                 test_auroc 0.57034
wandb: test_balanced_accuracy0.25 0.54831
wandb:  test_balanced_accuracy0.5 0.5322
wandb: test_balanced_accuracy0.75 0.51568
wandb:         test_precision0.25 0.33333
wandb:          test_precision0.5 0.33333
wandb:         test_precision0.75 0.3
wandb:            test_recall0.25 0.3
wandb:             test_recall0.5 0.2
wandb:            test_recall0.75 0.15
wandb:                train_auroc 0.99964
wandb:                 train_loss 0.04064
wandb:           val_accuracy0.25 0.55238
wandb:            val_accuracy0.5 0.60952
wandb:           val_accuracy0.75 0.66667
wandb:                  val_auroc 0.4888
wandb:  val_balanced_accuracy0.25 0.4187
wandb:   val_balanced_accuracy0.5 0.45667
wandb:  val_balanced_accuracy0.75 0.49464
wandb:          val_precision0.25 0.13793
wandb:           val_precision0.5 0.17391
wandb:          val_precision0.75 0.23529
wandb:             val_recall0.25 0.15385
wandb:              val_recall0.5 0.15385
wandb:             val_recall0.75 0.15385
wandb: 
wandb: 🚀 View run vgg16_2d_78_11_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/lc0p70m1
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_194151-lc0p70m1/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_201321-lbmythpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_11_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/lbmythpo
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▅▅█████████████████████████████████████
wandb:           test_accuracy0.5 █▁▁▆▃▂▂▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:          test_accuracy0.75 ███▆▆▆▃▇▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb:                 test_auroc ▃▇▆█▇▇▄▁▂▂▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃
wandb: test_balanced_accuracy0.25 ▆█▆▆█▅▆▃▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:  test_balanced_accuracy0.5 ▇█▁▂▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁
wandb: test_balanced_accuracy0.75 █▇█▆██▇▂▄▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb:         test_precision0.25 ▇█▇██▇▅▅▅▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃
wandb:          test_precision0.5 ▇▇█▅▅▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.75 ▁█▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test_recall0.25 ██▇▆▆▁▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂
wandb:             test_recall0.5 ▆▆█▆▅▅▁▁▂▃▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.75 ▁▁▃▃▁█▃▃▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:                train_auroc ▁▂▂▃▃▆▇█████████████████████████████████
wandb:                 train_loss █▇▇▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▂▃▅▅▆▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇█▇█▇▇▇▇▇
wandb:            val_accuracy0.5 ▁▃▁▂▂██▇▅▆▆▆▆▆▆▆▆▇▆▆▇▆▆▆▆▆▆▇▆▆▆▆▆▆▇▆▆▆▆▆
wandb:           val_accuracy0.75 ███▇█▆▃▂▄▂▂▄▃▃▃▃▃▄▃▃▄▄▂▃▃▄▄▃▃▃▄▂▃▂▃▄▄▁▂▃
wandb:                  val_auroc █▅▃▆▁▄▄▄▄▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:  val_balanced_accuracy0.25 ▆▆██▆▇▃▃▂▂▂▂▂▂▂▂▃▂▃▂▃▃▅▃▃▄▁▂▃▃▃▃▃▃▅▆▆▃▃▃
wandb:   val_balanced_accuracy0.5 ▇▁▆█▇▅▇▃▃▅▅▅▅▃▄▅▅▄▄▅▄▄▅▅▆▄▅▃▅▅▅▄▆▄▄▄▅▇▅▅
wandb:  val_balanced_accuracy0.75 ▅▂▅▂█▁▆▄▆▅▅▅▆▅▅▅▅▆▆▆▅▆▅▅▅▅▅▅▆▆▆▅▆▆▆▂▅▅▅▅
wandb:          val_precision0.25 ▇█▇▇▁▅▁▃▁▁▁▁▁▁▂▁▁▄▁▂▄▁▁▁▁▂▂▂▄▁▂▂▂▂▇▆▃▃▃▄
wandb:           val_precision0.5 ▅▆▅▄▆▁▃▅▄█▄▂▂▂▃▃▂▂▂▂▂▂▂▂▄▃▃▂▂▄▃▃▄▂▃▂▄▄▄▃
wandb:          val_precision0.75 ▁▁▄▇▆▇██▇██▇██▇█▇▇██████▇▇██▇███▇▇▇▇▇▇▇▇
wandb:             val_recall0.25 ██▆▅▆▅▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁
wandb:              val_recall0.5 ▂█▃▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂
wandb:             val_recall0.75 ▁▁▁▁▁▂▇▇▁█▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.53165
wandb:           test_accuracy0.5 0.53165
wandb:          test_accuracy0.75 0.5443
wandb:                 test_auroc 0.46017
wandb: test_balanced_accuracy0.25 0.40551
wandb:  test_balanced_accuracy0.5 0.37246
wandb: test_balanced_accuracy0.75 0.38093
wandb:         test_precision0.25 0.13043
wandb:          test_precision0.5 0.05263
wandb:         test_precision0.75 0.05556
wandb:            test_recall0.25 0.15
wandb:             test_recall0.5 0.05
wandb:            test_recall0.75 0.05
wandb:                train_auroc 0.99973
wandb:                 train_loss 0.03442
wandb:           val_accuracy0.25 0.61905
wandb:            val_accuracy0.5 0.64762
wandb:           val_accuracy0.75 0.67619
wandb:                  val_auroc 0.48832
wandb:  val_balanced_accuracy0.25 0.463
wandb:   val_balanced_accuracy0.5 0.48199
wandb:  val_balanced_accuracy0.75 0.50097
wandb:          val_precision0.25 0.18182
wandb:           val_precision0.5 0.21053
wandb:          val_precision0.75 0.25
wandb:             val_recall0.25 0.15385
wandb:              val_recall0.5 0.15385
wandb:             val_recall0.75 0.15385
wandb: 
wandb: 🚀 View run vgg16_2d_78_11_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/lbmythpo
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_201321-lbmythpo/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_203505-8w98jt3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_11_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/8w98jt3d
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▂▃▄▆▄▆▆▇█▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:           test_accuracy0.5 ▁▃▅▄▄▅▆▂▇█▆▇▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:          test_accuracy0.75 ██████▁█▆▄▃▂▅▆▃▄▅▃▅▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:                 test_auroc ▄▅▇▄█▄▇▂▁▃▂▆▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb: test_balanced_accuracy0.25 ▇▇▅▇▅▁▂██▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:  test_balanced_accuracy0.5 ▅▇█▇▆▅▁▂▇▆▅▆█▇▄█▇▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: test_balanced_accuracy0.75 ▅▃▁▆▇▃▃▆▄█▇▆▇▃▇▄█▄█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         test_precision0.25 ▅▄▄▅▅▂▃▂▃▁█▅▅▂▅▄▂▄▄▄▃▄▄▃▄▃▄▄▃▃▃▃▄▃▃▃▃▄▃▃
wandb:          test_precision0.5 ▅▁█▃▅▆▃▃█▅▄▇▆▅▄▄▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         test_precision0.75 ▁▁▁▅▅▅▆▆█▅▇▇▇▆█▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:            test_recall0.25 ███▅▄▂▂▂▂▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 █▆▆▅▄▄▁▃▁▃▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test_recall0.75 ▁▁▅▂▅█▃▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:                train_auroc ▁▂▂▄▃▇██████████████████████████████████
wandb:                 train_loss ████▇▆▄▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▃▅▅▅▆▆▇▆▇█████████████████████████████
wandb:            val_accuracy0.5 ▁▃█▆▇▆▃▆▅▆██▇▇▆▇████████████████████████
wandb:           val_accuracy0.75 █████▂▇▁▄▆▆▇▅▅▄▅▅▅▆▆▆▆▆▆▆▆▆▅▅▅▅▆▅▅▅▅▆▅▅▆
wandb:                  val_auroc ▂▁▃▄▅▅▆█▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▆▆▆▆▆▇▇▆▆
wandb:  val_balanced_accuracy0.25 ▄▄▅▄▄▁▃█▄▇▂▃▄▅▆▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:   val_balanced_accuracy0.5 ▁▃▄▂█▃▅▃▆█▄▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇
wandb:  val_balanced_accuracy0.75 ▅▄█▄▁▅▆▆▅▃▄▅▅▄▄▆▆▆▆▆▆▆▆▆▆▅▅▅▆▆▆▅▅▅▅▆▆▆▆▅
wandb:          val_precision0.25 ▅▅▅▅▆▆▄▇▆▁█▆▇█▆█▅▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇
wandb:           val_precision0.5 ▂▃▃▁▅▂▄▆▄▃█▄▆▆▂▂▆▆▆▆▆▆▆▆▆▆▆▆▆▆██████████
wandb:          val_precision0.75 ▁█▁▁▄▄▃▄▄▄▄▃▅▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:             val_recall0.25 ▇█▇▁▃▅▂▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:              val_recall0.5 █▆█▅▆▁▅▃▂▂▄▃▃▃▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄
wandb:             val_recall0.75 ▁▁▁▄▇▄▄▂▄▅▅█▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.56962
wandb:           test_accuracy0.5 0.62025
wandb:          test_accuracy0.75 0.63291
wandb:                 test_auroc 0.45085
wandb: test_balanced_accuracy0.25 0.46398
wandb:  test_balanced_accuracy0.5 0.49788
wandb: test_balanced_accuracy0.75 0.50636
wandb:         test_precision0.25 0.20833
wandb:          test_precision0.5 0.25
wandb:         test_precision0.75 0.26316
wandb:            test_recall0.25 0.25
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.25
wandb:                train_auroc 1
wandb:                 train_loss 4e-05
wandb:           val_accuracy0.25 0.68571
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.68571
wandb:                  val_auroc 0.54649
wandb:  val_balanced_accuracy0.25 0.54601
wandb:   val_balanced_accuracy0.5 0.54601
wandb:  val_balanced_accuracy0.75 0.5202
wandb:          val_precision0.25 0.33333
wandb:           val_precision0.5 0.33333
wandb:          val_precision0.75 0.29412
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.19231
wandb: 
wandb: 🚀 View run vgg16_2d_78_11_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/8w98jt3d
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/wandb/run-20250701_203505-8w98jt3d/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_11/execution_datetimes.json

**************************************************  Experiment 78 | Version 12 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

Using WeightedRandomSampler for train subset

✅ Set train dataloaders with 3 folds
  - Fold 1: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 20, 1.0: 12}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 3, 1.0: 15}
  - Fold 2: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 5, 1.0: 13}
  - Fold 3: 210 samples
    Label distribution: {0: 158, 1: 52}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 12, 1.0: 6}

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

Using WeightedRandomSampler for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

Using WeightedRandomSampler for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_78/version_12/wandb/run-20250701_205522-7iemeeif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_78_12_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_lung_vgg_wrs/runs/7iemeeif
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
srun: got SIGCONT
slurmstepd-02.ctm-deep-05: error: *** JOB 13665 ON 02.ctm-deep-05 CANCELLED AT 2025-07-01T21:20:00 ***
slurmstepd-02.ctm-deep-05: error: *** STEP 13665.0 ON 02.ctm-deep-05 CANCELLED AT 2025-07-01T21:20:00 ***
srun: forcing job termination
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
Exception ignored in: <function _releaseLock at 0x7f9ec2711940>
Traceback (most recent call last):
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/logging/__init__.py", line 237, in _releaseLock
    def _releaseLock():
    
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3623617) is killed by signal: Terminated. 
Error executing job with overrides: []
Traceback (most recent call last):
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1132, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/multiprocessing/queues.py", line 114, in get
    raise Empty
_queue.Empty

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/nas-ctm01/homes/mipaiva/pipeline_template_pl/slurm_files/shell_script_files/../../src/scripts/run_experiment_pipeline.py", line 54, in run_hyperparameter_grid_based_execution_pipeline
    run_experiment_pipeline(config)
  File "/nas-ctm01/homes/mipaiva/pipeline_template_pl/slurm_files/shell_script_files/../../src/scripts/run_experiment_pipeline.py", line 167, in run_experiment_pipeline
    model_pipeline.train_model()
  File "/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/model/model_pipeline.py", line 68, in train_model
    self.pytorch_lightning_trainer.fit(
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 134, in run
    self.on_advance_end()
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 249, in on_advance_end
    self.val_loop.run()
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py", line 181, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 108, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
                                       ^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py", line 126, in __next__
    batch = super().__next__()
            ^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py", line 58, in __next__
    batch = next(self.iterator)
            ^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py", line 285, in __next__
    out = next(self._iterator)
          ^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py", line 123, in __next__
    out = next(self.iterators[0])
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1294, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1145, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 3624143, 3624206, 3624269) exited unexpectedly

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7f9ccb8fe200>
Traceback (most recent call last):
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 94, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 228, in teardown
    self._client.send_server_request(
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in send_server_request
    self._send_message(msg)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 151, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe
srun: error: 02.ctm-deep-05: task 0: Exited with exit code 1
