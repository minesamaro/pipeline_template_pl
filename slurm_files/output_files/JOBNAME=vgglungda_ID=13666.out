Initialization time: 2025-07-01 14:49:12
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)

**************************************************  Experiment 79 | Version 1 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 5}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 6}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 7}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Currently logged in as: maria-i-paiva (maria-i-paiva-inesc-tec) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_1/wandb/run-20250701_145251-pd8x8y6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_1_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/pd8x8y6u
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ▁█▁███████▁██▁█▁▁███▁██▁▁▁█▁▁▁██████████
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁███▁▁▁▁▁▁█▁█████▁█▁▁▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁█▁█▁▁▁▁█▁███▁▁▁█▁▁▁▁▁▁▁▁▁▁▁█▁██████▁▁▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▂▄▃▅▅▄▂▄▅▄▆▃▄▂▃▁▄▆▅▄▄▅█▃▂▂▂▄▄▃▄▂▅▆▂▄▄▄▄▄
wandb:                 train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 █▁█████▁██▁█▁█▁▁█▁▁██▁███▁█▁▁▁▁▁▁████▁██
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁██▁▁▁▁▁▁▁▁██▁▁▁▁█▁▁▁▁▁▁▁▁█▁██▁▁█▁▁▁█▁▁█
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▁▁▁▁▁▁▁██▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███▁▁▁▁▁▁█
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.48221
wandb:                 train_loss 2.09364
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_1_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/pd8x8y6u
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_1/wandb/run-20250701_145251-pd8x8y6u/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_1/wandb/run-20250701_150628-2qq24qnm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_1_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/2qq24qnm
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ███▁▁███▁███▁▁▁▁▁▁█▁▁█▁▁███▁███▁▁▁▁▁▁▁██
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc █▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ██▁█▁▁█▁▁▁███▁▁██▁██▁▁▁██▁█▁▁▁▁▁████▁▁▁█
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 █▁▁██▁████▁█▁█▁█▁███▁█▁▁█▁▁▁▁█▁▁██▁██▁▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▃▄▄▃▄▄▄▆▅▄▁▃▃▅▃█▄▄▄▅█▄▆▄▅▂▃▂▁▃▇▅▃▅▃▆▃▅▆▄
wandb:                 train_loss █▆▇▂▃▃▆▃▄▂▂▄▂▂▂▆▂▃▂▆▁▂▂▂▁▂▄▃▃▃▃▁▂▁▃▄▂▅▁▂
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁▁█▁███▁▁▁▁███▁▁▁▁█▁▁▁█▁▁▁▁█▁█▁█▁▁▁█▁█▁█
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ██▁█▁▁▁▁▁█▁▁▁▁████▁█▁▁███▁▁██▁▁██▁█▁▁██▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ██▁▁▁▁▁▁█▁▁█▁▁██▁█▁███████▁▁▁██▁████▁██▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.44985
wandb:                 train_loss 2.09368
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_1_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/2qq24qnm
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_1/wandb/run-20250701_150628-2qq24qnm/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_1/wandb/run-20250701_151716-o3s1gfh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_1_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/o3s1gfh7
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ███▁███▁█▁▁█▁▁▁██████▁▁███▁▁▁▁█▁▁▁██████
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁███████████████████████████████████████
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁█▁█▁▁▁▁▁▁█▁▁▁▁█▁▁▁▁█▁███▁▁████████▁█▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁███▁█▁▁█▁▁▁▁▁▁█▁▁▁██▁█▁█▁▁▁▁███▁██▁█▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▆▆▄▂▃▆▆▄▅▄▅▅▅▆▄▇▃▄▂▅▅▃▆▁▄▃▅▃█▅▄▅▅▄▆▃▆▆▄▆
wandb:                 train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ██▁▁▁█████▁▁██▁████▁███▁█▁▁▁▁▁▁█▁▁█▁████
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁██▁▁▁█▁▁▁▁▁▁▁▁▁██▁▁██████▁████████▁▁▁▁▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ██▁▁▁█▁▁█▁▁▁▁▁█▁▁▁██▁▁▁▁▁██▁█▁▁▁▁█████▁█
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.43374
wandb:                 train_loss 2.09385
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_1_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/o3s1gfh7
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_1/wandb/run-20250701_151716-o3s1gfh7/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_1/execution_datetimes.json

**************************************************  Experiment 79 | Version 2 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 19, 1.0: 9}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 16, 1.0: 12}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 21, 1.0: 11}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 11, 1.0: 17}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_2/wandb/run-20250701_153009-txrmu5mq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_2_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/txrmu5mq
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 █▁▁▁█████████▁██▁▁█▁███▁███████████▁██▁▁
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁█▁▁█▁▁▁▁▁▁▁▁▁██▁▁▁█▁▁▁█▁▁▁▁▁▁▁▁▁████▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁██▁▁▁▁▁▁▁▁▁▁▁██▁█
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▃▅█▆▄▅▆▅▅▅▆▄▄▇▅▄▁▆▅▆▃▆▅▃▅▅▄▅▅▄▄▆▃▆▄▇▅▆▅▃
wandb:                 train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ████████████▁███▁█████▁▁██▁████▁▁▁▁█████
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁█▁▁█▁▁█▁▁▁██▁▁▁▁█
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁█▁▁▁█▁█▁█
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.4142
wandb:                 train_loss 2.09364
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_2_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/txrmu5mq
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_2/wandb/run-20250701_153009-txrmu5mq/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_2/wandb/run-20250701_154058-en3m80i2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_2_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/en3m80i2
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ▁████▁███▁████▁████████▁██▁██▁█████████▁
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▃▁▃▄▄▅█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁▁▁▁▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁█▁▁█
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▁▁██▁▁▁▁▁▁▁▁▁▁█▁▁▁██▁▁▁▁▁▁▁█▁▁▁▁▁▁█
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▆▅▅▃▁▅▆▆█▅▃▅▃▄▁▃▃▂▃▁▃▅▄▃▅▅▃▃▆▄▃▅▂▄▃▅▃▄▂▃
wandb:                 train_loss ▆▁▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 █▁███████▁█████▁▁████████▁▁▁█▁█████████▁
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc █▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▅▁▁▁▁▁█▅▅▅▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁█▁▁▁▁▁▁██▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁██▁▁▁▁▁▁▁█▁▁▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.42589
wandb:                 train_loss 2.09366
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_2_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/en3m80i2
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_2/wandb/run-20250701_154058-en3m80i2/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_2/wandb/run-20250701_155406-hzwhgxl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_2_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/hzwhgxl4
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ▁██▁▁▁██▁▁▁█████▁▁██▁█▁▁▁█▁███▁██▁▁▁████
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ██▁▁▁▁████▁▁▁▁██▁▁▁█▁█▁█▁██████▁▁█████▁█
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ██▁▁▁█▁█▁▁▁▁▁██▁▁▁▁█▁██████▁▁▁▁▁▁█▁▁▁▁█▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▃▆▃▆▆▆▂▄▂▄▆▃▂▃▅▃▃▆▆▇▂▄▄▁▄▅▅▅█▂▃▂▄▄▃▄▂▄▃▂
wandb:                 train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁█▁▁▁█▁▁▁▁███▁█▁██████▁▁▁▁█▁███▁█▁▁█▁██▁
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁██▁▁█████████▁▁▁▁▁█▁▁▁█▁▁█▁▁█▁█▁██▁█▁█
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁██▁█▁▁██▁█▁▁▁█▁▁█▁██████▁██▁█▁▁███▁█▁██
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.25316
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.25316
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 1
wandb:            test_recall0.75 0
wandb:                train_auroc 0.42469
wandb:                 train_loss 2.09368
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.24762
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.24762
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 1
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_2_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/hzwhgxl4
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_2/wandb/run-20250701_155406-hzwhgxl4/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_2/execution_datetimes.json

**************************************************  Experiment 79 | Version 3 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 36, 1.0: 28}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 31, 1.0: 33}
    Batch label distribution: {0.0: 32, 1.0: 32}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 26, 1.0: 34}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_3/wandb/run-20250701_160823-ipd6wb3h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_3_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ipd6wb3h
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading history steps 173-174, summary, console lines 4-5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ▁█▁███▁▃██████████████████████▁█████████
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▅▅█▅▇▄▆▂▄▅▇▃▁▄▆▃▃▃▃▄▄▆▅▃▅▅▃▆▄▄▃▃▅▄▅▅▄▅▅▅
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁███▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▅▇▆▆▆██▆▃▅▄▆▄▃▃▄▃▆▃▄▄▃▄▄▂▅▃▅▃▃▂▁▅▄▄▄▄▄▄▂
wandb:                 train_loss ▇███████▁███████████████████████████████
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ▁██▁▁██▁▁█████████████████████▁█████████
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▆▆▅▇▆▆▆▆█▆▆▆▄▃▁▂▃▅▄▄▄▃▅▅▃▃▃▂▂▂▂▃▂▃▂▂▄▃▄▄
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 █▁█▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 █▁▁██▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.48771
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.47631
wandb:                 train_loss 2.0936
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.43525
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_3_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ipd6wb3h
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_3/wandb/run-20250701_160823-ipd6wb3h/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_3/wandb/run-20250701_162500-3rycch1o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_3_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/3rycch1o
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc █▁▄▄▄███████████████████████████████████
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▅▅▄▆█▅▄▁▄▅▃▄▄▃▂▅▃▄▄▃▁▂▂▅▄▄▄▄▃▂▄▄▃▅▃▄▃▄▃▄
wandb:                 train_loss ▁▁▁█▇▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 █████▁██████████████████████████████████
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▄▂▃▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.45962
wandb:                 train_loss 2.09359
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_3_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/3rycch1o
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_3/wandb/run-20250701_162500-3rycch1o/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_3/wandb/run-20250701_163746-1y5hj7ml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_3_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/1y5hj7ml
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: uploading history steps 161-162, summary, console lines 4-5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ███▁████████████████████████████▁▁██▁███
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▄▅█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁█▁▁▁
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▆█▅▃▇▁▃▁▃▄▄▄▃▄▅▂▄▄▃▄▄▃▅▃▄▂▄▅▂▃▃▄▃▂▄▃▂▃▄▅
wandb:                 train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 █████████████████████████████████▁██████
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁███▁
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████▁▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.74684
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.5
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.5
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0
wandb:            test_recall0.75 0
wandb:                train_auroc 0.49744
wandb:                 train_loss 2.09359
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.75238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.5
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.5
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_3_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/1y5hj7ml
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_3/wandb/run-20250701_163746-1y5hj7ml/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_3/execution_datetimes.json

**************************************************  Experiment 79 | Version 4 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 5}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 6}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 7}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_4/wandb/run-20250701_165225-ch7zgrzf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_4_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ch7zgrzf
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading history steps 332-332, summary, console lines 4-5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▅▅▄▄▆▅▆▅▆▄▅▄▆▄▅▅▅▄▇▅▆▅▇▆█▃▅▅▅▄▃▄▄▄▃▃▃▂▂
wandb:           test_accuracy0.5 ▇█▆█▆▅▅▅▇▇▄▄▄▇▆▆▅▅▅▄▆▆█▆▆█▇█▆▆▆▇▆▄▄▁▃▂▂▁
wandb:          test_accuracy0.75 █▇███▆▄▄▃▅▃▄▃▃▃▅▃▃▃▃▆▄▆▂▄▅▆▆▄▃▄▄▃▄▂▃▂▂▁▂
wandb:                 test_auroc ▅▄▆▁▃▅▄▄▄▄▃▅▆▄▄▄▅▄▅▅▅▂▅▅█▇▄▅▇▆▆▇▅▂▃▁▂▂▂▃
wandb: test_balanced_accuracy0.25 ▃▃▃▆▆▇▃▂▂▃▇▄▂▄▇▄▆▂▄▃▄▅▄▅▃▇▆▅▆█▇▃▄▄▃▃▁▂▂▂
wandb:  test_balanced_accuracy0.5 ▆▄▃▅▄▆▆▃▄▄▆▆▅▄▄▄▅▅▅▅▅▇▆▃▅▇▅▄▄▃▆█▁▃▃▃▁▃▂▂
wandb: test_balanced_accuracy0.75 ▇▇▅▄▅▄▄▁█▄▃▆▄▂▂▅▄▃▃▄▆▆▃█▆▅▄▄▅▄▄▃▂▁▁▁▃▃▂▂
wandb:         test_precision0.25 ▃▃▃▅▅▅▅▂▅▁▃█▅▆▆▃▆▅▃▃▅▄▃▅▆▇▇▅▇▅▅▄▅▆▇▃▆▄▃▃
wandb:          test_precision0.5 ▃█▂▂▃▂▁▃▂▁▂▃▂▁▂▄▂▂▂▁▃▂▂▃▃▃▄▄▄▃▃▃▂▂▂▁▂▂▂▃
wandb:         test_precision0.75 ▁▂▁▂█▂▂▃▄▄▄▃▄▃▃▄▃▄▄▃▅▅▄▇▅▄▅▅▃▄▄▄▄▃▄▃▄▃▃▃
wandb:            test_recall0.25 ███▄▆▃▁▃▅▃▂▅▃▂▄▅▃▁▁▄▄▃▃▂▃▂▂▃▃▅▃▂▇▄▅▇▄▄▂▃
wandb:             test_recall0.5 ▃▂▁▁▄▁▂▂▂▃▅▃▂▂▃▃▃▃▃▃▄▃▅▂▂▃▃▄▂▃▃▅▅█▂▄▃▄▄▄
wandb:            test_recall0.75 ▁▁▃▃▃▃▆▆█▆▆▆▃▄▃▆▆▅▃▆▆▄▅▅▅▄▆▆▇▆▅▅▄▆▆▄▄▄▆▆
wandb:                train_auroc ▁▂▅▅████████████████████████████████████
wandb:                 train_loss █▆▄▂▃▂▂▂▂▁▁▁▁▃▁▂▁▁▅▁▁▁▁▁▂▁▂▁▁▂▁▁▂▂▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▅▁▅█▇▆▇▆▇▅▇▆▅▆▆▆▆▆▆▇▆▆▄▇▅▆▆▆▆▆▅▆██▇▇▆▆▆
wandb:            val_accuracy0.5 ▁▃█▇▆▇▇▇▆▆▇▇▇▆▆▆▇▇▇▅█▇▇▆▆▇▄▆▆▇▅▅█▇█▇▇▆▆▆
wandb:           val_accuracy0.75 █▇▆▅▆▆▆▆▆▅▇▆▄▄▄▄▅▅▆▄▄▄▆▃▄▆▆▆▄▄▄▁▃▅▆▅▄▄▄▄
wandb:                  val_auroc ▁▄▃▆█▅▅▇▇▇█▆▃▄▆▅▃▄▄▄▄▄▄▅▄▄▄▃▆▁▃▄▆▅▆▅▅▄▅▄
wandb:  val_balanced_accuracy0.25 ▅▃▇██▆▅▆▂▆▃▄▆▅▅▆▄▅▆▇▄▄▄▁▆▄▃▃▃▆▅▇█▆▅▅▅▆▅▅
wandb:   val_balanced_accuracy0.5 ▂▂▂▁▄▅▅▄▄▅▆▄▅▆▅▆▆▄▅▂▆▄█▃▅▄▃▁▅▅▅▅▅▅▄▅▄▄▄▄
wandb:  val_balanced_accuracy0.75 ▄▄▂▄▅▅▇▃▅▄▇▄▇▃▆▆▆▅█▄█▆▆▅█▄▂▂▂▂▁▆▆▇▇▇▇▇▇▆
wandb:          val_precision0.25 ▄▃▂▇▅▅▄▃▄▅▇▇▆▅▃▄▅▅▆▄▆▇▃▃▄▄▁▆▄█▇▆▃▅▆▄▅▅▅▅
wandb:           val_precision0.5 ▃▂▁▁▄▅▄▄▅▄▄▅▇▄▄▅▅▅▄▅▇▃▃▅▄▅▅▆▂▃█▅▆▅▅▄▄▆▅▅
wandb:          val_precision0.75 ▁▅▅▇█▇▅▆▅▆▆▇█▅▅▆▆▇▆▆▅▆▇▆▆▅▆▅▆█▇▇▅▆▆▆▆▆▆▆
wandb:             val_recall0.25 █▆▄▄▂▁▃▂▃▃▂▃▂▃▂▅▃▂▂▁▃▃▂▂▃▄▂▃▃▂▂▄▂▂▂▃▃▃▃▃
wandb:              val_recall0.5 ██▄▄▃▅▇▅▅▄▇▄▅▅▅▅▅▅▇▄▆▆▆▄▃▅▅▄▁▅▄▄▄▅▅▅▅▅▆▆
wandb:             val_recall0.75 ▁▁▅▁▃▅▃▅▃▅▅▆▇▅▅▅▆▅▆▅▅▅▃▆▄▅▆█▄▄▆▅█▆▆▅▅▆▆▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.49367
wandb:           test_accuracy0.5 0.46835
wandb:          test_accuracy0.75 0.49367
wandb:                 test_auroc 0.52712
wandb: test_balanced_accuracy0.25 0.51229
wandb:  test_balanced_accuracy0.5 0.42924
wandb: test_balanced_accuracy0.75 0.44619
wandb:         test_precision0.25 0.2619
wandb:          test_precision0.5 0.19444
wandb:         test_precision0.75 0.20588
wandb:            test_recall0.25 0.55
wandb:             test_recall0.5 0.35
wandb:            test_recall0.75 0.35
wandb:                train_auroc 0.99968
wandb:                 train_loss 0.04029
wandb:           val_accuracy0.25 0.5619
wandb:            val_accuracy0.5 0.6
wandb:           val_accuracy0.75 0.61905
wandb:                  val_auroc 0.53408
wandb:  val_balanced_accuracy0.25 0.51534
wandb:   val_balanced_accuracy0.5 0.52775
wandb:  val_balanced_accuracy0.75 0.54041
wandb:          val_precision0.25 0.2619
wandb:           val_precision0.5 0.27778
wandb:          val_precision0.75 0.29412
wandb:             val_recall0.25 0.42308
wandb:              val_recall0.5 0.38462
wandb:             val_recall0.75 0.38462
wandb: 
wandb: 🚀 View run vgg16_2d_79_4_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ch7zgrzf
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_4/wandb/run-20250701_165225-ch7zgrzf/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_4/wandb/run-20250701_172326-mytziulm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_4_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/mytziulm
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▄▃▂▁▄▃▄▆▅▅▇▆▅▆▃▄▅▃▃▅▄▆▆▆▆▆▅█▃▃▃▅▆▅▂▃▅▅▅▅
wandb:           test_accuracy0.5 █▂▇▄▇▁▅▇▄▅▃▄▃▄▅▄▄▂▃▃▂▄▃▁▂▂▅▆▅▄▅▂▄▁▂▃▂▃▂▃
wandb:          test_accuracy0.75 ███▇▇▅▄▇▅▃█▁▅▂▆▄▂▅▃▄▃▂▄▇▃▅▅▅▆▆▅▄▅▂▃▂▁▄▃▅
wandb:                 test_auroc ▇█▇█▇▄▇▅▄▆▄▃▃▄▃▄▃▃▄▅▃▁▃▆▇▅▆▅▃▃▃▃▂▃▄▃▅▃▄▅
wandb: test_balanced_accuracy0.25 ▆▅▆▆▅▅▄▄▂▃▁▄▃▄▆▂▃▇▆▁▄▅▇▄▄▇█▆▇▂▂▅▂▅▅▃▄▄▅▁
wandb:  test_balanced_accuracy0.5 ▆█▆▅▆▄▄▂▃▄▃▁▄▂▃▃▅▂▃▂▅▂▄▄▂▅▅▂▃▃▄▆▁▃▂▃▃▄▃▃
wandb: test_balanced_accuracy0.75 ▆▆▆▆▆▆▆▆▆▆▅▅▄▅▅▅▄▆▆▅▁▅▇▇█▆▆▆▄▄▅▆▆▅▆▃▆▅▄▄
wandb:         test_precision0.25 ▅▅▄▅▃▄▂▃▂▂▁▃▃▂▃▁▁▁▃▂▄▂▆▄▃▆█▇▆▃▃▄▂▂▁▁▃▃▅▂
wandb:          test_precision0.5 ▅▃▅█▅▁▅▅▆▄▅▃▅▄▅▅▄▄▅▄▅▄▅▄▄▆▆▅▃▅▄▅▄▄▄▄▄▅▅▄
wandb:         test_precision0.75 ▆▁▇▁▁▁▇▅▅█▅▅▄▃▅▇▆▅▅▅▆▅▇▅▆▅▅▇▆▄▄▅▆▅▆▅▅▆▆▅
wandb:            test_recall0.25 ███▅▂██▄▃▄▂▂▁▂▂▂▂▅▂▂▂▃▄▃▂▂▄▄▁▁▂▃▂▂▂▂▂▂▂▂
wandb:             test_recall0.5 ▂█▆█▁▅▂▃▄▃▃▄▃▃▄▃▃▆▂▄▂▃▃▃▃▅▃▄▃▃▅▃▃▃▃▃▃▄▃▃
wandb:            test_recall0.75 ▁▁▃▁▁▁▃▃▂▃▃▅▄▄▄▄█▇▅▃▄▆▅▅▄▃▄▃▅▄▅▅▅▅▅▄▅▅▄▃
wandb:                train_auroc ▁▃▆▇▇███████████████████████████████████
wandb:                 train_loss █▇▇▅▅▄▄▃▃▃▂▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▃▁▃▂▄▆▆▄▅▇▇▆▆▆▇█▇▇▇▇▆▆▇▄▆▇▆▆▇▆▇▆▆▆▆▆▅▆▆▅
wandb:            val_accuracy0.5 █▇▆▄█▅▄▅▅▄▅▆▇▇▅▄▅▅▅▂▅▅▆▄▁▄▅▆▄▅▃▆▃▄▃▃▅▄▅▃
wandb:           val_accuracy0.75 ███▇▆█▇▇▅▅▃▅▂▅▆▅▅▅▅▅▄▁▆▂▇▅▅▅▅▄▄▅▃▄▃▄▅▂▂▃
wandb:                  val_auroc ▅▂▂▄▇██▄▇▅▆▆▅▆▄▅▇▅▇▆▆▆▅▆▅█▇▅▄▆▅▄▅▅▅▃▂▂▁▄
wandb:  val_balanced_accuracy0.25 ▄▄▂▃▅▅▅▁▂▆▄▆▃▂▂▁▆▅█▇▅▃▆▃▇▅▅▄▂▃▃▂▂▃▃▄▂▃▁▃
wandb:   val_balanced_accuracy0.5 ▆▂▁▃▆▃▄▄▇█▄▂▆▅▅▅▆▃█▅▅▆▄▃▅▃▅▅▄▂▂▆▃▅▆▃▂▄▄▃
wandb:  val_balanced_accuracy0.75 ▄▄▄▄▄▃▅▅▃▅▆▄▅█▃▄█▃▆▅▇▆▆▄▆▅▃▃▇▄▃▅▄▅▅▂▃▁▂▂
wandb:          val_precision0.25 ▂▇▇▅▆▅▆▆██▇▆▇▆▇▆▇▇█▆███▇██▆▇▆█▆▇▆▄▇▇▄▁▆▆
wandb:           val_precision0.5 ▁▄▅▁▄▆█▅█▃▃▅▅▅█▇█▆▆▆█▅▇██▇▅▆▆▅▆▅▅▇▇▇▆▆▅▄
wandb:          val_precision0.75 ▁▁▁▁▁▁▄█▁▅▄▅▃▅▄▃▅▅▅▄▅▅▄▃▅▅▅▄▄▅▄▃▅▅▄▅▅▅▂▄
wandb:             val_recall0.25 █▇▃▂▅▇▃▅▄▄▅▂▁▃▂▃▃▅▂▄▃▂▃▂▄▃▄▃▃▁▂▂▃▃▂▁▃▃▃▃
wandb:              val_recall0.5 █▂▁▄▃▂▄▅▁▅▃▂▃▄▅▃▅▂▆▃▂▃▄▄▂▄▅▄▄▄▃▃▂▆▃▂▅▄▄▂
wandb:             val_recall0.75 ▁▂▂▁▃▂▇▄▆▆▁▃▆▅▄▅▄█▆▄▇▅▆█▅▇▅▅▆▄▃▄▅▄█▆▆▆▅▃
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.50633
wandb:           test_accuracy0.5 0.5443
wandb:          test_accuracy0.75 0.53165
wandb:                 test_auroc 0.41695
wandb: test_balanced_accuracy0.25 0.42161
wandb:  test_balanced_accuracy0.5 0.44703
wandb: test_balanced_accuracy0.75 0.42203
wandb:         test_precision0.25 0.17241
wandb:          test_precision0.5 0.19231
wandb:         test_precision0.75 0.16
wandb:            test_recall0.25 0.25
wandb:             test_recall0.5 0.25
wandb:            test_recall0.75 0.2
wandb:                train_auroc 0.99944
wandb:                 train_loss 0.04656
wandb:           val_accuracy0.25 0.54286
wandb:            val_accuracy0.5 0.54286
wandb:           val_accuracy0.75 0.55238
wandb:                  val_auroc 0.47371
wandb:  val_balanced_accuracy0.25 0.45107
wandb:   val_balanced_accuracy0.5 0.42527
wandb:  val_balanced_accuracy0.75 0.4316
wandb:          val_precision0.25 0.19444
wandb:           val_precision0.5 0.15625
wandb:          val_precision0.75 0.16129
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.19231
wandb:             val_recall0.75 0.19231
wandb: 
wandb: 🚀 View run vgg16_2d_79_4_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/mytziulm
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_4/wandb/run-20250701_172326-mytziulm/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_4/wandb/run-20250701_174041-s9ymu1ip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_4_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/s9ymu1ip
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▆▇▄▅▇▅▅▇▅█▅▆▃▇▄▆▄▆▆▆▆▆▇█▅▇▇▅▆▆▆▆▅▅▇▆▆▆
wandb:           test_accuracy0.5 █▇▂▇▆▆▂▆▆▂▁▅▅▃▆▅▃▃▂▁▄▄▂▅▆▄▄▄▂▃▄▅▅▄▃▆▃▃▃▃
wandb:          test_accuracy0.75 ▇█▇▇▆█▅▆▄▅▄▅▃▁▄▃▂▃▄▃▄▃▆▃▄▃▇▄▃▁▂▃▂▃▃▁▅▃▂▁
wandb:                 test_auroc ▄▅▆▆▁▅▅▃▅▇▆▅▅▅▇▆▆▅▅▆▆██▇█▇█▇▇▇▇▆▆▇█▇▆▇▆▅
wandb: test_balanced_accuracy0.25 ▃▂▃▄▃▂▃▃▄▄▄▄▄▄▃▅▂▄▁▁▄▃▃▂▅▂█▅▄▆▅▅▂▁▂▃▄▅▃▃
wandb:  test_balanced_accuracy0.5 ▄▃▂▂▃▁▃▂▃▁▃▂▅▂▅▃▂▂▅▅▃▆▄█▅▃▄▆▃▂▄▂▅▄▃▃▃▅▄▂
wandb: test_balanced_accuracy0.75 ▂▂▂▂▂▄▄▂▃▁▂▄▆▆▅▂▂▅▂▃▇▅▅▅▃▃▄▄█▅▄▄▄▄▇▂▄▅▃▂
wandb:         test_precision0.25 ▃▃▃▅▃▂▃▃▃▄▁▅▄▂█▇▃▂▄▁▄▃▅▅▅▃▄▆▅▄▄▆▃▃▅▁▁▆▄▃
wandb:          test_precision0.5 ▄▃▆██▁▅▃▅▅▆▃▅▅▆▇▆▆▄▅▅▅▄▃▅▇▅▇▆▅▄▄▄▅▄▄▄▃▃▄
wandb:         test_precision0.75 ▁▁▁▁▁█▁▁▄▆▇▆▆▆▆▇▅▃▅▆▆▆▅▆▆▇▆▆▅▅▇▆▅▅▅▆▇▅▅▅
wandb:            test_recall0.25 ██████▂▂▄▃▂▃▅▂▃▂▁▂▃▂▄▂▂▃▂▅▁▄▄▄▄▃▂▃▃▂▂▂▁▂
wandb:             test_recall0.5 ▁▁▇▄▂▂▆▄▄▄▆▆▄▅▅▅▇▄▅█▄▄▃▇▄▂▄▅▆▆▄▆▄▄▄▄█▄▃▄
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▂▃▁▂▅▃▄▂▅▄▄▅▅▅▄█▅▅▆▂▅▅▅▅▅▅▃▄▄▄▄▅
wandb:                train_auroc ▁▃▅▇▆█████████▇████████▇▇███████████████
wandb:                 train_loss █▇▆▆▇▄▄▁▁▁▂▁▁▁▂▁▁▁▁▁▁▂▅▂▂▁▁▂▁▁▃▁▂▁▁▂▁▁▁▁
wandb:           val_accuracy0.25 ▁▄▁▇▅▇▆▅▇█▇▆█▆▇▆▇▆▆▆▆▇▇▇▆▇▇▅▆▅▆▇▆▆▅▆▇▆▆▇
wandb:            val_accuracy0.5 █▇▃▇▃▇▄▇▃▅▆▆▃▂▂▃▄▂▃▅▃▄▄▄▅▇▃▄▁▃▄▂▃▃▂▂▂▁▅▃
wandb:           val_accuracy0.75 █▇██▄▇▄▅▃▄▁▁▆▄▅▄▆▁▃▂▄▂▂▄▄▆▂▅▄▂▃▃▁▁▅▂▂▃▄▃
wandb:                  val_auroc ▅▇▁█▅▄▅▆▄▆▆▇▇▆▇▆▆▅▂▅▄▇▄▆▄▅▃▄▃█▅▅▆▆▇▇▇▇▆█
wandb:  val_balanced_accuracy0.25 ▆▄▆▅▇█▇▆█▇▄▃▄▅▇█▆▇▄▃▄▁▃▂▇▄▁▂▇▄▆▃▃▃▆▆▄▃▃▆
wandb:   val_balanced_accuracy0.5 █▄▄▄▆▆▆▅▅▃▄▁▅▁▅▇▅█▃▄▅▄▂▆▄▃▂▄▃▂▂▄▅▃▂▃▂▄▃▇
wandb:  val_balanced_accuracy0.75 ▄▄▄▄▅▃▆▆▄▄▂▁▆▅▄▄▃▁▃▄▅▃▂▁▅▃▅▂▃▂▃▂▁▂▁█▆▇▃█
wandb:          val_precision0.25 ▄▅▄▂▄█▅▅▇▅▄▁▂▅▄▄▄▃▃▄▄▄▅▂▄▄▁▄▂▄▃▅▃▄▄▂▅▄▃▂
wandb:           val_precision0.5 ▅▅▇▅▅▃█▅▅▅▃▅▃▃▆▆▁▄▆▄▄▄▅█▃▄▅▃▅▄▅▄▅▃▅▇▄▅▅█
wandb:          val_precision0.75 ▁▁▁▁██▆▅▆▆▆▆▅▇▅▅▄▅▄▅▆▅▄▅▅▅▅▅▅▅▅▅▆▄▆▅▅▅▅▆
wandb:             val_recall0.25 ███▂▇█▅▂▂▃▂▃▃▂▂▂▂▂▂▃▃▃▄▁▃▃▁▄▂▂▄▃▃▃▁▃▂▃▄▄
wandb:              val_recall0.5 ▇█▅▁▁▂▃▄▂▃▅▃▅▅▄▃▃▅▅▅▆▅▅▃▃▅▅▅▃▅▅▆▅▃▅█▆▅▅▇
wandb:             val_recall0.75 ▁▁▁▁▂▃▂▄▂▃▄▃▄▃▃▄▃▄▄▄▅▄▃▄▃▃▃▂▄▄▅▅▅▅▅█▅▄▄▆
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.56962
wandb:           test_accuracy0.5 0.58228
wandb:          test_accuracy0.75 0.59494
wandb:                 test_auroc 0.54237
wandb: test_balanced_accuracy0.25 0.49703
wandb:  test_balanced_accuracy0.5 0.50551
wandb: test_balanced_accuracy0.75 0.51398
wandb:         test_precision0.25 0.25
wandb:          test_precision0.5 0.25926
wandb:         test_precision0.75 0.26923
wandb:            test_recall0.25 0.35
wandb:             test_recall0.5 0.35
wandb:            test_recall0.75 0.35
wandb:                train_auroc 1
wandb:                 train_loss 8e-05
wandb:           val_accuracy0.25 0.60952
wandb:            val_accuracy0.5 0.6
wandb:           val_accuracy0.75 0.5619
wandb:                  val_auroc 0.55721
wandb:  val_balanced_accuracy0.25 0.57278
wandb:   val_balanced_accuracy0.5 0.55355
wandb:  val_balanced_accuracy0.75 0.47663
wandb:          val_precision0.25 0.31707
wandb:           val_precision0.5 0.3
wandb:          val_precision0.75 0.22222
wandb:             val_recall0.25 0.5
wandb:              val_recall0.5 0.46154
wandb:             val_recall0.75 0.30769
wandb: 
wandb: 🚀 View run vgg16_2d_79_4_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/s9ymu1ip
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_4/wandb/run-20250701_174041-s9ymu1ip/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_4/execution_datetimes.json

**************************************************  Experiment 79 | Version 5 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 19, 1.0: 9}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 16, 1.0: 12}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 21, 1.0: 11}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 11, 1.0: 17}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_5/wandb/run-20250701_175718-mnuggbvm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_5_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/mnuggbvm
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▄█▁▂▆▃▇▇▆▅▃▅▅▅▄▅▅▅▄▄▄▅▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:           test_accuracy0.5 ███▇▅▆▆▃▁▆▁▃▆▂▃▃▄▃▃▃▂▂▅▃▁▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁
wandb:          test_accuracy0.75 ██▇▆▆▆▆▆▅▆▄▄▃▃▄▃▃▃▅▅▁▃▄▄▁▃▃▃▂▂▁▁▂▂▂▁▁▁▁▁
wandb:                 test_auroc ▄▄▄▄▃█▁▃▄▂▃▃▃▃▂▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▃▄▄▄▄▃▃▃▃▃
wandb: test_balanced_accuracy0.25 ▆▅▂▄▆█▅▆▅▆▃▇█▅▃▆▄▄▆▅▄▄▃▃▂▁▂▂▃▃▃▃▃▃▃▃▃▃▃▃
wandb:  test_balanced_accuracy0.5 ▆▆▅██▇▆▅▃▂▅▃▃▂▁▄▃▄▂▄▄▄▃▄▅▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂
wandb: test_balanced_accuracy0.75 ███▇▄▇▇▁▇▄▇█▅▄▄▅▃▃▅▆▂▅▄▄▃▃▃▃▄▄▃▃▃▃▃▃▃▃▃▃
wandb:         test_precision0.25 ▅▅▄▅▅▆▅▄▅▃▄▇▃▃█▄▄▄▅▅▂▂▃▁▃▃▃▃▃▃▃▄▃▃▃▃▃▃▃▃
wandb:          test_precision0.5 ▁▅▅██▄▆▄▄█▃▅▄▄▄▄▅▆▆▄▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         test_precision0.75 ▁█▁▄▃▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test_recall0.25 █▅█▃▁▃▃▃▄▂▃▂▄▄▂▁▄▃▄▃▃▃▃▃▂▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄
wandb:             test_recall0.5 ▃▂▅▂▅▂▄▃▃▅▅█▁▅▂▆▅▅▅▅▅▅▅▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test_recall0.75 ▄▃▁▃▃▂▂▄▅▅▇▅▆▂▅▆▆▆▆▃▇▇▇▇▇▇▇▇▇▇██▇███████
wandb:                train_auroc ▁▄▅███████████████▇█████████████████████
wandb:                 train_loss █▆▅▅▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▅▄▆▆▃▆▆▇▆▅▆█▇█▇▆▇█▆▇▆▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆
wandb:            val_accuracy0.5 ▆█▆▆▁▅▆▆▆▅▄█▆▇▆▅▅▅▅▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄
wandb:           val_accuracy0.75 ███▇█▆▂▆▅▃▂▁▃▂▄▅▄▄▄▆▂▅▃▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▄▃▂▇▅▃█▄▂▅▆▁▂▄▄▆▄▅▆▅▇▅▂▁▁▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁
wandb:  val_balanced_accuracy0.25 ▄▄▄▅▆▄▄█▆▅▃▁▅▆▆▄▄▃▃▃▃▃▂▅▆▂▁▄▃▃▃▂▃▂▄▃▃▄▃▅
wandb:   val_balanced_accuracy0.5 ▂▁▂▁▄▆▃▅▁▃▃▃█▅▄▅▄▃▃▂▅▄▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:  val_balanced_accuracy0.75 ▅▄▄▄▄▁▁▅▄▅▄▅▆█▅▆▅▇▆▆▅▆▅▅▂▄▃▄▄▄▅▅▆▆▅▆▆▆▅▅
wandb:          val_precision0.25 ▅▅▅▅▆▄▄▆▄█▄▅█▇▆▆▄▄▄▃▃▁▄▃▃▃▃▄▄▅▄▄▄▅▅▅▅▅▅▅
wandb:           val_precision0.5 ▅▆▅▁▃▅▆▆▆▆▅▆▇▇▇█▆▆▆▆▅▆▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:          val_precision0.75 ▁▁▁▁▇▁▅▆▇▇▇▆▇▅█▇█▇▇█████▇▆▇▇▇▇▇████▇▇▇▇▇
wandb:             val_recall0.25 ████▂▄▅▃▅▁▃▂▃▄▃▂▃▃▃▃▃▃▃▄▃▃▃▃▄▄▃▃▄▄▄▄▄▄▄▄
wandb:              val_recall0.5 ▁▃▆▇▄▆█▇▅▇▅▅█▅▆▄▄▆▆▆▆▄██▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:             val_recall0.75 ▁▁▂▃▃▆▅▃▇▅▅▆▅▆█▃▄▅▆▆▆█▅▆▇▆▆▆▆▆▇▇▇▇▇██▇▇▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.41772
wandb:           test_accuracy0.5 0.43038
wandb:          test_accuracy0.75 0.43038
wandb:                 test_auroc 0.50339
wandb: test_balanced_accuracy0.25 0.42839
wandb:  test_balanced_accuracy0.5 0.40381
wandb: test_balanced_accuracy0.75 0.40381
wandb:         test_precision0.25 0.20455
wandb:          test_precision0.5 0.17949
wandb:         test_precision0.75 0.17949
wandb:            test_recall0.25 0.45
wandb:             test_recall0.5 0.35
wandb:            test_recall0.75 0.35
wandb:                train_auroc 0.9998
wandb:                 train_loss 0.02963
wandb:           val_accuracy0.25 0.53333
wandb:            val_accuracy0.5 0.5619
wandb:           val_accuracy0.75 0.55238
wandb:                  val_auroc 0.48296
wandb:  val_balanced_accuracy0.25 0.52215
wandb:   val_balanced_accuracy0.5 0.52824
wandb:  val_balanced_accuracy0.75 0.50901
wandb:          val_precision0.25 0.26531
wandb:           val_precision0.5 0.27273
wandb:          val_precision0.75 0.25581
wandb:             val_recall0.25 0.5
wandb:              val_recall0.5 0.46154
wandb:             val_recall0.75 0.42308
wandb: 
wandb: 🚀 View run vgg16_2d_79_5_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/mnuggbvm
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_5/wandb/run-20250701_175718-mnuggbvm/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_5/wandb/run-20250701_181848-2jp07l6t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_5_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/2jp07l6t
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▄▄▆▆▅▄▆▇▆▆▆▆▅▅▆▆▆█▇▇▆▇▆▆▆▆▆▆▇▇▅▇▇▆▄▇▇
wandb:           test_accuracy0.5 ▁█▇█▇▇▆▆▆▅▅▇▅▅▆▆▅▆▅▅▅█▇▆▆▆▆▆▆▆▅▅▅▄▅▆▆▆▆▆
wandb:          test_accuracy0.75 █▇▇▅▆▆▄▅▅▄▄▅▅▅▆▅▆▆▆▅▄▃▄▄▄▅▇▆▆▅▄▅▅▅▅▅▁▅▆▅
wandb:                 test_auroc ▃▅▃▄▇▅▅▅▃▃▃▃▃▄▃▃▄▄▄▄▁▂▃▂▃▇▄▅▄▄▄▄▄▃▅███▄▅
wandb: test_balanced_accuracy0.25 ▂▂▂▁▆▆▇▂▅▂▁▆▄▄▅▄▄▂▄▂▄▄▅▅▄▃▄▂▄▂▂▂▄▂▃▄▆█▄▅
wandb:  test_balanced_accuracy0.5 ▅▅▅▄▅▄▄▅▃▃▄▃▆▆▄▅▁▃▃▂▂▆▃█▅▃▃▂▆▃▃▂▆▁▆▇▇▇▅▆
wandb: test_balanced_accuracy0.75 ▅▄▅▃▂▂▃▅▆▆▃▃▅▆▆▄▃▃▃██▆▅▇▅▅▅▄▄▄▃▆▄▅▇█▃▆▁▅
wandb:         test_precision0.25 ▃▁▃▄▄▄▅▃▃▁▅▅▄▄▅▅▄▇▆▃▂▃▃▄▅█▃▄▄▃▃▆▅▄▇▆▅▆▇▆
wandb:          test_precision0.5 ▁▅█▅▅▅▃▄▄▅▄▄▄▄▅▅▅▄▄▄▄▄▄▅▃▆▅▅▅▄▅▄▅▅▄▄▄▅▄▅
wandb:         test_precision0.75 ▁▁▁▅▇▇▆▅▃▆▆▆▇▇▆▅▅▅▅▅▅▇▆▅▅▆▆▆▅▅▆▅▆███▇▆▂▆
wandb:            test_recall0.25 █▃█▁▂▆▁▂▃▂▃▂▂▂▂▃▂▂▂▂▃▃▃▂▂▁▃▂▂▂▁▂▄▁▁▁▃▃▃▅
wandb:             test_recall0.5 █▂▁▃▂▄▃▂▃▃▃▄▃▂▃▁▄▂▄▄▃▄▂▄▄▂▂▁▃▃▃▃▃▂▄▄▄▃▁▄
wandb:            test_recall0.75 ▁▁▂▅▂▅▃▃▅▄▄▅▅▄▃▄▅▄▄▄▄▄▄▄▄▄▄▃▅▅▄▆▄▄▄█▃▅▄▃
wandb:                train_auroc ▁▅▆▆▇███████████████████████████████████
wandb:                 train_loss █▇▆▆▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁█▆▇▆▃▅█▆▇▇▇▆█▆▇▇▇▇▇▇▇▇▅▇▆▆▇█▇▇▇▆█▇▇▇▆▆
wandb:            val_accuracy0.5 ▁██▆▇▅▇▇▆▇▅▆▇▆▆▆▆▆▆▅▆▆▅▅▆█▃▇▅▅▅▇▆▇▇▇▆▆▇▄
wandb:           val_accuracy0.75 ███▇▇▅▇▅▁▆▃▂▄▂▅▂▄▄▄▅▄▅▅▅▅▅▅▅▅▅▄▅▅▅▅▇▅▄▄▁
wandb:                  val_auroc ▂█▁▁▁▅▂▅▂▄▃▄▄▄▄▅▄▆▅▅▅▅▅▅▃▃▃▃▂▅▄▅▅▄▄▅▆▃▁▃
wandb:  val_balanced_accuracy0.25 ▄▄▁▃▅▅▄▁▃▆▇▆▃▆▄▅▄▃▆▇▆▆▇▇▇▆▆▆▅▄▅▅▃█▃▆▇▆▄▅
wandb:   val_balanced_accuracy0.5 ▃▂▃▂▂▃▃▂▄▃▅█▅▃▅▄▅▅▃▁▄▃▅▃▃▄▂▃▃▃▄▅▄▃▅▃▄▄▁▂
wandb:  val_balanced_accuracy0.75 ▄▄▄▄▄▅▄▅▃▅▃▆▆▅▃▁▄▇▄█▃▄▆▅▆▆▄▄▄▃▅█▄▆▆▆▅▅▆▁
wandb:          val_precision0.25 ▆▅▄▆▅▃▁▅▆▆▇▇▆▅▇▇▆▇▇▅██▇▆▇▇▇▇█▇█▅▇▇▆▅▇█▆█
wandb:           val_precision0.5 ▇▁▁▅▇█▆▇▆▆▇▇▆███▆▇███▇▆██▇▆▆▅▇▇▇█▇█▆█▇█▆
wandb:          val_precision0.75 ▁▁██▄▃▄▅▄▅▅▆▄▆▅▅▄▄▅▅▅▅▄▅▄▅▄▄▅▆▅▅▆▅▆▅▅▅▅▄
wandb:             val_recall0.25 █▅▃▂▁▂▂▂▃▂▃▄▄▂▃▄▄▃▂▃▃▄▂▃▃▃▂▂▂▂▄▃▃▃▂▄▄▃▃▃
wandb:              val_recall0.5 █▂▂▃▁▂▂▂▃▂▂▃▂▂▂▃▂▃▃▄▄▃▂▃▂▃▃▃▃▃▄▅▂▂▃▄▃▂▂▃
wandb:             val_recall0.75 ▁▁▁▁▁▂▁▂▄▂▃▃▃▅▅▆▃▃▄▄▃▃▄▄▄▃▄▄▃▂▆█▃▃▆▆▆▆▃▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.58228
wandb:           test_accuracy0.5 0.56962
wandb:          test_accuracy0.75 0.59494
wandb:                 test_auroc 0.51271
wandb: test_balanced_accuracy0.25 0.53856
wandb:  test_balanced_accuracy0.5 0.48051
wandb: test_balanced_accuracy0.75 0.49746
wandb:         test_precision0.25 0.29032
wandb:          test_precision0.5 0.23077
wandb:         test_precision0.75 0.25
wandb:            test_recall0.25 0.45
wandb:             test_recall0.5 0.3
wandb:            test_recall0.75 0.3
wandb:                train_auroc 0.99952
wandb:                 train_loss 0.07017
wandb:           val_accuracy0.25 0.59048
wandb:            val_accuracy0.5 0.60952
wandb:           val_accuracy0.75 0.60952
wandb:                  val_auroc 0.51607
wandb:  val_balanced_accuracy0.25 0.52142
wandb:   val_balanced_accuracy0.5 0.49537
wandb:  val_balanced_accuracy0.75 0.48247
wandb:          val_precision0.25 0.27027
wandb:           val_precision0.5 0.24138
wandb:          val_precision0.75 0.22222
wandb:             val_recall0.25 0.38462
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.23077
wandb: 
wandb: 🚀 View run vgg16_2d_79_5_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/2jp07l6t
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_5/wandb/run-20250701_181848-2jp07l6t/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_5/wandb/run-20250701_184023-qbwvlipe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_5_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/qbwvlipe
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▆▁▆▅▅█▆▅▆▅▄▇▅▅▅▄▅▆▆▅▆▅▄▄▅▅▆▅▆▆▅▄▄▄▅▅▄▃▅
wandb:           test_accuracy0.5 █▁▄▄██▄▇▆▇▅▁▅▄▄▄▅▅▅▄▄▆▃▇▄▆▇▄▅▅▅▄▄▄▃▃▃▃▃▃
wandb:          test_accuracy0.75 █████▆▄▅▄▆▃▅▅▄▄▅▄▅▃▂▄▅▄▄▃▅▅▄▄▂▃▂▁▁▂▄▁▂▃▁
wandb:                 test_auroc ▆▄▂▁▂▅▅▇▇▆▇▆▆▇▇▃▅▇▆▆▇█▇▇▅▃▆▇▄▆▅▇▇▅▅▃▄▂▄▅
wandb: test_balanced_accuracy0.25 ▆▆▁▂▂█▄▃▅▇▄▅▄▇▃▄▄▆▄▅▇▄▁▅▇▆█▄▅▄▆▇▆▄▄▁▁▂▂▄
wandb:  test_balanced_accuracy0.5 ▆█▇▅▅▆▆▅▅▆▆▅▄▅█▆▄▅▅▅▄▅▂▆▇▅▆▆▆▅▆▁▃▃▅▄▅█▅▆
wandb: test_balanced_accuracy0.75 ▅▅▅▆▇▄▄▆▄▄▆▆▄█▅▅▃▂▃▅▅▄▃▄▃▇▇▃▄▆▅▄▂▃▂▁▃▅▄▃
wandb:         test_precision0.25 ▆▆▄▅▄▄▁▃▂▅▄█▃▇▅▄▃▃▅▄▃▂▄▃▁▄▃▂▆▆▆▆▅▄▂▁▄▃▂▄
wandb:          test_precision0.5 ▃▃▆▅██▆▆▅▃▅▃▄▅▅▅▃█▄▅▅▃█▄▃▄▄▁▂▃▃▄▃▅▃▄▆▄▅▃
wandb:         test_precision0.75 ▁█▁▁▁▇▆▁█▆▃▅▅▁▅▆▄▄▄▅▄▄▄▅▅▆▅▅▆▄▄▅▄▄▄▄▅▄▅▄
wandb:            test_recall0.25 ██▆▄▃▃▁▃▃▅▃▃▃▃▂▃▃▄▄▃▃▅▃▃▃▃▃▂▃▃▂▃▃▄▄▃▄▄▃▄
wandb:             test_recall0.5 █▇▁▅▂▅▅▇▅▄▄▅▅▅▅▅▆▅▆▅▅▆▅▇▅▅▅▅▅▅▅▆▄▅▇▆▅▆▇▇
wandb:            test_recall0.75 ▁▁▁▁▃▂▅▅▆▃▅▆▇▄▆▆▆▆▅▅▅▆▆▆▅▄▆▅▅▇▅▆▆▆▇▆██▇█
wandb:                train_auroc ▂▄▇▇▇▁▃▅█▇██████████████████████████████
wandb:                 train_loss ▇▅▆▅▃▄▃█▄▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▅▅▂▅▇█▇▅▇█▇▇▆▇▇▆▇▇▇▇▇█▇▇▇▇█▇█▇█▇▇▇▇▇▇▇
wandb:            val_accuracy0.5 ▇██▃█▃▄▄▆▄▂▄▅▆▃▄▄▄▃▃▅▂▁▅▄▄▃▄▄▄▃▃▃▃▃▃▃▃▃▃
wandb:           val_accuracy0.75 ██▇██▇██▇▇▆▅▁▅▅▅▆▅▅▅▅▄▅▅▆▅▆▅▆▅▅▆▅▆▄▆▅▄▄▄
wandb:                  val_auroc ▁▇▃▄▆▃▅▇█▇▄▆▆▆▆▆▆▇▅▆▆▅▅▄▄▄▃▆▆▆▆▆▄▄▅▅▅▄▅▅
wandb:  val_balanced_accuracy0.25 ▅▃▄██▇█▄▆▇▆▆▃▃▄▄▄▃▃▁▅▆▆▄▂▆▃▃▁▆▅▄▃▅█▆▅▂▆█
wandb:   val_balanced_accuracy0.5 █▅▅▃▅▅▂▄▃▁▃▂▄▇▄▃▆▃▃▁▄▃▁█▅▆▇▄▃▆▄▅▃▅▃▄▅▄▅▇
wandb:  val_balanced_accuracy0.75 ▆▆▄▆▁▆▆▆▇▆▃▄▆▇▅█▆▅▅▅▆▅▄▃██▇▆█▅▅▆▃█▄▄▄▆▆▄
wandb:          val_precision0.25 ▅▅▄▅▅▅▄▂▆▄▂▇▅▄▃▃▃▆▄▃▄▆▆▅▃▅▇▅▇▄▅▆▇▆▃▃▅▁▇█
wandb:           val_precision0.5 ▇▁▁▇▇▇▇▆▆▆▇█▇▄▅▇▇▇█▆▇██▇▇▇▇▇▇█▇▆▆▇▆▆▇▇▇█
wandb:          val_precision0.75 ▁▁▁▁█▁▅▃▃▃▃▅▅▄▅▅▄▄▅▄▄▄▄▅▄▄▅▄▅▅▅▅▅▄▃▄▄▄▄▄
wandb:             val_recall0.25 █▆██▃▃▄▁▃▃▁▃▃▄▂▂▂▅▂▃▃▁▂▂▄▄▂▂▃▃▁▂▂▂▃▄▃▃▁▄
wandb:              val_recall0.5 ▁▁▁█▃▄▁▂▄▃▅▃▅▆▃▄▄▃▄▃▄▄▂▅▅▃▃▄▄▄▃▅▃▅▆▅▄▅▄▄
wandb:             val_recall0.75 ▁▁▁▁▅▁▁▃▄▂▂▇▄▄█▅▅▅▅▄▄▆▃█▂▆▇▇▇▇▆▅▅▅▅▇▅▄▆▆
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.40506
wandb:           test_accuracy0.5 0.41772
wandb:          test_accuracy0.75 0.46835
wandb:                 test_auroc 0.45424
wandb: test_balanced_accuracy0.25 0.41992
wandb:  test_balanced_accuracy0.5 0.42839
wandb: test_balanced_accuracy0.75 0.46229
wandb:         test_precision0.25 0.2
wandb:          test_precision0.5 0.20455
wandb:         test_precision0.75 0.225
wandb:            test_recall0.25 0.45
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0.45
wandb:                train_auroc 1
wandb:                 train_loss 0.00124
wandb:           val_accuracy0.25 0.5619
wandb:            val_accuracy0.5 0.59048
wandb:           val_accuracy0.75 0.6
wandb:                  val_auroc 0.50876
wandb:  val_balanced_accuracy0.25 0.52824
wandb:   val_balanced_accuracy0.5 0.54722
wandb:  val_balanced_accuracy0.75 0.54065
wandb:          val_precision0.25 0.27273
wandb:           val_precision0.5 0.29268
wandb:          val_precision0.75 0.28947
wandb:             val_recall0.25 0.46154
wandb:              val_recall0.5 0.46154
wandb:             val_recall0.75 0.42308
wandb: 
wandb: 🚀 View run vgg16_2d_79_5_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/qbwvlipe
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_5/wandb/run-20250701_184023-qbwvlipe/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_5/execution_datetimes.json

**************************************************  Experiment 79 | Version 6 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 36, 1.0: 28}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 31, 1.0: 33}
    Batch label distribution: {0.0: 32, 1.0: 32}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 26, 1.0: 34}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_6/wandb/run-20250701_185906-ycahh0k3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_6_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ycahh0k3
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▅▆▆▇▇▆▇▆▆▆▆▅▆▇▇▅▆▆▅▆▇▆██▆▆▇▅▆▆▆▇▆▆▆▆▆
wandb:           test_accuracy0.5 ▁▇▇▇▇██▅▇▆▅▆▆▆▅▆▆▅▇▆▆▆▅▆▆▇█▇▆▆▇▆▆▆▅▅▅▅▅▆
wandb:          test_accuracy0.75 █████▂▂▄▅▃▃▃▁▂▂▁▆▄▄▂▅▂▂▃▃▃▅▄▄▃▅▅▇▅▁▂▃▃▃▂
wandb:                 test_auroc ▂▁▄▄▁▅▅▆▆▆▆▄▃▂▄▄▇▆▇▆▅▆▆▆▇█▇▇▇▅▅▅▄▄▄▄▄▄▄▅
wandb: test_balanced_accuracy0.25 ▆▂▃▅▂▅▃▄▃▆▇▄▄▄▅▄▃▅▃▁▆▄▂▂▆▃▆▆▇▇▇█▆▄▃▄█▁▁▁
wandb:  test_balanced_accuracy0.5 ▁▄▄▆▄▆▃▅▃▄▄▅▃▆▄▄▄▂▃▃▆▅▃▅▄▅▅▆█▇▇▇▆▅▃▂▄▃▃▃
wandb: test_balanced_accuracy0.75 ▅▅▅▅▄▄▅▅█▁▄▃▃▂█▃▇▂▄▅▄▄▄▃▅▄▃▄▆▇██▅▄▇▃▃▅▄▄
wandb:         test_precision0.25 ▁▁▁▄▂▂▁▃▃▂▆▄▅▁▃▄▄▂▃▁▄▃▄▅▄▃▄▅▅▅▄█▅▃▁▂▂▁▁▄
wandb:          test_precision0.5 ▃▂█▃▄▂▁▂▂▃▃▂▄▄▂▃▂▂▁▃▃▃▂▄▃▂▃▂▄▄▆▆▅▄▄▂▂▃▂▂
wandb:         test_precision0.75 ▁▁▆▄█▆▅▃▆▃▃▂▃▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃
wandb:            test_recall0.25 ▅▃▁▅▄▃▄▃▃▅▅▃▃▂▄█▄▃▅▅▅▆▆▃▆▃▆▃▆▅▅▄▃▃█▃▃▃▆▃
wandb:             test_recall0.5 ▁▄▂▃▃▂▃▂▂▃▄▃▅▂▃▅▄█▂▄▃▃▃▆▅▅▅█▃▄▇▄▄▄▅▄▄▄▅▄
wandb:            test_recall0.75 ▁▂▃▃▄▂▃▅▃▄▅▄▇▅▅▄▄▅▆▃▄▃▇▄▅▅▅▄▄▄▄█▅▄▄▄▄▅▅▄
wandb:                train_auroc ▁▃▅▆█▇████████▇█████████████████████████
wandb:                 train_loss █▇▇▆▅▄▅▄▃▂▂▂▁▁▁▁▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▅▄█▆▆▇▇▆▄▆▇▅▅▇▅▆▇▅▆▆▅▇▄▅▇▇▅▇▄▅▆▆▄▅▅▅▄▅
wandb:            val_accuracy0.5 ▁▇▅█▇▇▆▇▆▇▅▆▆▇▅▅▅▆▅▅▅▆▄▄▆▅▅▅▅▅▄▅▄▄▄▄▄▄▃▄
wandb:           val_accuracy0.75 ▆█▇██▃▄▆▆▃▆▄▅▅▁▄▄▅▅▄▄▃▄▂▆▆▃▃▄▄▄▄▄▄▅▁▄▁▁▃
wandb:                  val_auroc ▆▄▆▆█▆▆▆▅▅▄▇▂▄▅▃▆▅▃▂▂▁▂▃▃▄▃▃▂▂▁▄▂▂▂▃▃▂▂▁
wandb:  val_balanced_accuracy0.25 █▇▅▇▆▆▅█▆▃▃▅▆▅▄▅▅▄▃▃▃▃▃▄▆▂▄▅▃▅▃▄▄▄▂▂▂▂▂▁
wandb:   val_balanced_accuracy0.5 ▆██▇▇▇▆▆▅▆▅▇▆▅▅▄▄▅▄▃▅▄▃▂▆▅▄▄▄▅▃▄▄▅▅▄▄▁▁▃
wandb:  val_balanced_accuracy0.75 ▆▅▅▆█▇▇▅▇▇▄▆▅▇▅▂▄▅▃▅▅▅▄▄▃▄▅▁▂▄▅▅▄▂▂▂▂▃▄▁
wandb:          val_precision0.25 ▆█▆▅▆▃▄▄▂▃▄▅▃▄▂▂▂▂▁▄▂▂▃▄▃▂▂▃▃▄▃▁▁▃▂▃▂▂▂▂
wandb:           val_precision0.5 ▂▄█▃▄▅▃▃▃▄▁▄▅▃▄▃▁▂▁▂▃▂▃▂▃▂▃▃▁▂▂▂▂▁▂▂▂▂▂▁
wandb:          val_precision0.75 █▄▅▁▆▅▄▆▄▄▄▄▄▅▄▄▄▄▄▄▅▄▂▄▄▄▄▄▂▄▄▃▃▃▃▃▃▃▃▃
wandb:             val_recall0.25 ███▅▄▃▄▂▅▅▂▂▃▄▃▂▂▂▂▂▃▃▂▂▃▃▃▂▃▃▂▂▁▂▂▂▂▂▂▂
wandb:              val_recall0.5 █▇▃▁▁▃▃▃▄▂▃▃▃▂▃▂▂▁▂▂▃▂▂▂▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂
wandb:             val_recall0.75 ▁▂▁▂▄▂▅▆▅▄▄▄▆▄▆█▄▄▄▅▂▅▄▃▃▆▆▄▅▄▄▄▄▇▂▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.55696
wandb:           test_accuracy0.5 0.56962
wandb:          test_accuracy0.75 0.59494
wandb:                 test_auroc 0.56356
wandb: test_balanced_accuracy0.25 0.50508
wandb:  test_balanced_accuracy0.5 0.48051
wandb: test_balanced_accuracy0.75 0.49746
wandb:         test_precision0.25 0.25806
wandb:          test_precision0.5 0.23077
wandb:         test_precision0.75 0.25
wandb:            test_recall0.25 0.4
wandb:             test_recall0.5 0.3
wandb:            test_recall0.75 0.3
wandb:                train_auroc 0.99964
wandb:                 train_loss 0.04061
wandb:           val_accuracy0.25 0.45714
wandb:            val_accuracy0.5 0.50476
wandb:           val_accuracy0.75 0.52381
wandb:                  val_auroc 0.3851
wandb:  val_balanced_accuracy0.25 0.38121
wandb:   val_balanced_accuracy0.5 0.41285
wandb:  val_balanced_accuracy0.75 0.42551
wandb:          val_precision0.25 0.13953
wandb:           val_precision0.5 0.15789
wandb:          val_precision0.75 0.16667
wandb:             val_recall0.25 0.23077
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.23077
wandb: 
wandb: 🚀 View run vgg16_2d_79_6_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ycahh0k3
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_6/wandb/run-20250701_185906-ycahh0k3/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_6/wandb/run-20250701_191836-x8qkm9rk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_6_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/x8qkm9rk
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▂▂▇▅▆▇▇▃▆▃█▇█▇▇▆▅█▆▇▆▆▅▅▇▇▆▆▇▆▆▆▆▆▆▆▆▅▄
wandb:           test_accuracy0.5 ▁▇▃▇██▇▇▇▄▇▇▇▇▇▆▅▆▇▅▇▇▆▇▇▇▅▅▆▆▆▆▆▆▆▆▆▆▇▅
wandb:          test_accuracy0.75 ██▇▆▇▇▆▇▅▆▅▅▅▅▇▅▃▄▅▁▃▃▅▅▆▄▅▃▃▃▁▄▃▃▃▃▆▃▂▃
wandb:                 test_auroc ▄▆▅▆▇▇█▇▅▄▄▃▅▅▅▅▄▁▃▂▂▇▆▄▃▅▃▃▄▄▄▄▄▄▃▅▇▁▃▂
wandb: test_balanced_accuracy0.25 ▄▅█▇▇█▆▅▅▃▅▆▅▂█▅▃▆▁▅█▄▄▆▁▄▅▂▂▂▂▃▃▃▃▃▃▇▃▃
wandb:  test_balanced_accuracy0.5 ▂▂▅▅▆█▅▄▆▃▂▆▁▄▅▄▅▄▂▄▂▄▃▄▅▅▃▄▂▃▂▃▄▄▄▄▄▄▆▃
wandb: test_balanced_accuracy0.75 ▅▅▆▄▆▆▆▅▇▃▇▇▇▇▅▂▆▅██▆▅▅▆▅▅▄▁▄▆▅▅▅▃▆▅▅▇▅▄
wandb:         test_precision0.25 ▄▄▆▆█▆▆▆▅▅▅▃▄▂▂▄▁▄▅▄▂▃▄▄▄▂▂▂▃▂▃▄▃▃▃▄▄▄▄▃
wandb:          test_precision0.5 ▆▇▅▅▇▅▄▅▅▇▆▅▅▄▅█▃▄▄▅▅▅▁▃▅▃▃▄▅▅▅▅▅▅▅▅▅▆▃▄
wandb:         test_precision0.75 ▅▁▁█▆▅▅▅▆▄▆▆▄▄▄▅▅▅▅▅▅▅▅▄▅▃▆▄▄▆▅▅▅▅▅▅▅▅▅▄
wandb:            test_recall0.25 █▄▆▃▂▇▄▃▂▄▂▃▃▃▃▂▁▂▂▃▂▂▂▃▂▂▂▂▂▂▃▂▂▂▂▂▁▄▂▂
wandb:             test_recall0.5 █▁▇▂▂▂▂▃▄▁▂▃▂▃▃▂▃▃▂▃▃▃▃▃▂▁▄▃▂▃▃▃▃▃▃▃▃▃▂▂
wandb:            test_recall0.75 ▁▁▁▃▃▂▂▆▃▃▃▆▅▇▇▆▆▅▆▇▆▆▆▇▇▆▆▂█▇▇▇▇▇▇▇▇▇▇█
wandb:                train_auroc ▁▃▄▆▇▇██████████████████████████████████
wandb:                 train_loss █▆▆▆▅▄▅▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▂
wandb:           val_accuracy0.25 ▁▆▄▅▅▇▇▆▆█▇▇▇▇▇████████▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇
wandb:            val_accuracy0.5 █▅▆▅▄▃▁▅▄▅▅▅▅▆▄▅▅▆▄▄▆▅▄▆▅▄▅▅▅▄▄▄▄▄▄▄▅▆▃▅
wandb:           val_accuracy0.75 ▇█▂▇██▇▆▆▅▆▅▆▅▅▅▅▆▅▆▅▆▆▆▆▄▇▆▅▄▅▅▅▅▄▅▇▁▅▅
wandb:                  val_auroc ▁▁▂▁▂▂▂▃▆▄▃▄▅▅▅▇██▇▂▃▄▄▄▄▅▄▄▄▄▄▄▄▅▄▂▅▄▃▃
wandb:  val_balanced_accuracy0.25 ▃▇▃▆▃▂▁▂▃▄▄▃▆▄█▄▇▆▇█▇▇▇▇█▃▆▃▅▆▄▅▅▇▇▅▅▅▅▄
wandb:   val_balanced_accuracy0.5 ▃▁▃▂▂▃▃▅▅▄▁▇▇▅▅█▇▇▇▇▂▄▃▅▃▄▃▅▄▄▄▄▄▄▄▆▄▂▃▄
wandb:  val_balanced_accuracy0.75 ▂▃▃▃█▂▂▃▅▅▄▁▁▅▇██▆▄▅▄▄▂▃▃▄▄▄▅▃▃▃▃▃▃▃▂▂▃▂
wandb:          val_precision0.25 ▆▅▃▄▄▄▅▅▁▅▃▆▄▃▅█▅▆▅▇██▅▃▆▅▄▅▇▆▅▅▅▅▅▅▁▅▄▅
wandb:           val_precision0.5 ▆▁▅▁▁▆▅▇█▇▅▅▅▄▆▇▇███▇████▄▇▆▆▆▆▆▆▇▆▆▆▆▄▆
wandb:          val_precision0.75 ▁▁▁▁▁▁▆▆▃▇▅▄▅▆▃▄▂▅▇▆██▇▇▆▆▆▆▆▆▆▆▅▆▆▆▆▅▅▄
wandb:             val_recall0.25 ▄▃▅▃▂▁█▂█▅▁▃▃▂▃▃▄▄▂▅▄▂▃▄▁▁▁▂▁▄▂▂▂▃▂▂▂▂▄▂
wandb:              val_recall0.5 █▁▁▁▄▁▁▂▂▃▃▃▃▃▂▁▂▄▂▃▄▄▄▃▃▃▄▁▃▃▃▃▃▃▃▂▁▃▃▂
wandb:             val_recall0.75 ▁▁▁▁▂▄▁▂▁▃▄▇▇▆▂▂█▇▇▇▆▇▇▇▃▅▄▅▅▅▆▄▄▄▅▃▂▄▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.58228
wandb:           test_accuracy0.5 0.63291
wandb:          test_accuracy0.75 0.64557
wandb:                 test_auroc 0.47373
wandb: test_balanced_accuracy0.25 0.48898
wandb:  test_balanced_accuracy0.5 0.48983
wandb: test_balanced_accuracy0.75 0.49831
wandb:         test_precision0.25 0.24
wandb:          test_precision0.5 0.23529
wandb:         test_precision0.75 0.25
wandb:            test_recall0.25 0.3
wandb:             test_recall0.5 0.2
wandb:            test_recall0.75 0.2
wandb:                train_auroc 0.99936
wandb:                 train_loss 0.06518
wandb:           val_accuracy0.25 0.61905
wandb:            val_accuracy0.5 0.65714
wandb:           val_accuracy0.75 0.67619
wandb:                  val_auroc 0.47274
wandb:  val_balanced_accuracy0.25 0.4888
wandb:   val_balanced_accuracy0.5 0.51412
wandb:  val_balanced_accuracy0.75 0.52678
wandb:          val_precision0.25 0.23077
wandb:           val_precision0.5 0.27273
wandb:          val_precision0.75 0.3
wandb:             val_recall0.25 0.23077
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.23077
wandb: 
wandb: 🚀 View run vgg16_2d_79_6_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/x8qkm9rk
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_6/wandb/run-20250701_191836-x8qkm9rk/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_6/wandb/run-20250701_193628-si7lz8ho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_6_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/si7lz8ho
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▃▆█▅▆▆▇▄▆▆▅▆▆▇▅▆▇▅▆█▅▆▅▆▆▅▆▆▆▆▆▆▆▇▄▆▆▅▅
wandb:           test_accuracy0.5 ▇█▇▅█▄▄▅▅▃▄▆▃▂▄▅▄▃▄▅▆▅▅▄▅▃▅▄▄▅▅▄▁▆▃▁▂▄▃▃
wandb:          test_accuracy0.75 ████▇▆█▄▇▆▅▂▃▂▅▂▄▄▄▁▃▃▆▄▃▃▆▃▃▂▄▅▄▄▆▂▂▂▂▁
wandb:                 test_auroc ▂▁▄▅▄▃▆▆▃▃▃▃▄▂▄▄▅▆▅▄▂▄▂▃▂▁▃▅▄▆█▆▆▆▄▂▃▃▁▃
wandb: test_balanced_accuracy0.25 ▁▅▄▆▄▁▂▄▇▄▃█▅▂▄▅▆▄▄▅▇▆▆██▅▅▇▅▅▂▅▅▆▅▂▄▄▅▄
wandb:  test_balanced_accuracy0.5 ▅▅▄██▆▄▃▅▆▄▅▅▅▅▄▅▅▅▄▅▅▆▅▆▃▇▄▆▆█▆▄▅▆▅█▇▁▆
wandb: test_balanced_accuracy0.75 ▃▅▆▃▃▅▃▅▅█▂▃▃▅▅▂▄▅▆▃█▅▃▃▄▅▅▄▇▆▄▅▅▅▄▆▁▁▄▄
wandb:         test_precision0.25 ▅▅▄▅▅▅▇▆▅▅▆▅▇▃▇▅▅▇▅▆▇▄▁▅▆▅▆▇▇▇█▅▅▆▃▇▇▅▄▅
wandb:          test_precision0.5 ▁▅▇▇█▆▅▇▆▃▅▅▇▆▆▇▅▆▆█▆▇▆▆▆▇▇▇▇▆▆▆▆▇▅▆▅▄▆▆
wandb:         test_precision0.75 ▁▁▅██▆▆▄▅▅▅▅▅▅▄▅▄▄▅▆▅▅▅▄▅▅▅▅▅▅▅▅▅▄▅▅▅▅▄▅
wandb:            test_recall0.25 ██▇█▆▆▆▄▆▅▅▄▄▃▅▅▅▅▅▅▅▄▁▅▅▅▅▅▅▆▄▄▅▅▅▅▅▅▅▄
wandb:             test_recall0.5 ▁▁▅▆▇▂▇▅▃▅▆▆▃▇▇▇▆▇▆▇▇▆▇█▇▇▇██▄▄▆▅▇▇▅▃█▇▅
wandb:            test_recall0.75 ▁▁▁▃▃▂▅▃▆▆▂▅▇▄▆▅▄█▆▆▃▆▅▅▇▇▇▆▆▆▇▆▆▆▆▆▅▅▆▆
wandb:                train_auroc ▁▂▂▅▅▇██████████████████████████████████
wandb:                 train_loss ██▇▆▄▄▆▄▂▃▂▂▂▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▂▁▂▂▁▂
wandb:           val_accuracy0.25 ▁▄█▇▇▇▇▇▇▇▇▇▇▇▇▅▆▇█▇▇▆▇█▆▇▇▇▇▇▇▇▇▅▆▆▇▅▆▇
wandb:            val_accuracy0.5 ▇▇▆▅▇▁▆▇▆█▄▅▄▄▄▅▄▄▃▃▄▄▅▅▆▆▄▃▄▄▃▄▃▄▄▃▃▄▃▅
wandb:           val_accuracy0.75 ██▆█▇▄▇▇▄▆▄▃▇▅▅▄▅▅▁▃▅▅▇▄▄▄▂▅▄▅▅▄▂▃▅▂▂▁▆▅
wandb:                  val_auroc ▅▁▂▄▃▄▄▄▂▄▅▅▇▅▄▄▃▂▄▂▅▅▅▆█▆█▇▇▇▅▅▅▅▆▅▄▄▄▄
wandb:  val_balanced_accuracy0.25 ▁▆▃▁▄▄▅▃▅▃▃▄▂▇▇▂▂▄▁▄▄▅█▅▅▄▆▅▆▅▂▆█▄▂▃▄▃▃▆
wandb:   val_balanced_accuracy0.5 █▃▂▂▂▃▃▃▁▃▃▃▃▄▃▆█▁▃▂██▅▅▄▆▇▄▃▄█▄▆▃▃▂▃▁▃▇
wandb:  val_balanced_accuracy0.75 ▁▂▂▂▂▂▂▃▃▁▂▂▃▂▂▃▇▅▂▃▃▅▆▆▆▅▂▅▅▅▇▆▅▄▆▂█▄▂▆
wandb:          val_precision0.25 ▃▃▃▃▃▆▅▅▇▆▁▃▅▄▆▃▅▅▆▅█▄▆▄▆▅▅▅▄▆▆▄▅▅▄▃▄▄▅▆
wandb:           val_precision0.5 ▁▁▇▇▁▆▆▇▆▇▆▇▆▆▆█▆▅▇▆▇▆▇▆▆▇▇▇▇▇▆▆▇▇▅▆▆▆▆▇
wandb:          val_precision0.75 ▁▁▅▅▅▁▄▅▆▇▇▆█▆▆▆▆▆█▇▅▅▅▇▇▇██▇█▇▆▅▆▆▆▇█▇▇
wandb:             val_recall0.25 ██▂▃▄▃▃▁█▆▂▄▅▇▂▆▃▆▇▅▄▃▄▅▇▇▄▅▅▅▅▇▃▆▅▅▄▅▃▄
wandb:              val_recall0.5 █▇▅▁▃▂▅▃▅▃▃▃▄▄▃▃▆▄▆▄▃▆▅▂▇▅▅▄▄▅▄▄▅▄▄▅▄▄▄▆
wandb:             val_recall0.75 ▁▂▃▂▁▆▆▄▄▄▆▆▇▄▄▄█▄▄▃▅▆▄▄▆▅▆▆▆▅▇▆▆▅▅▅▇▇▅▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.51899
wandb:           test_accuracy0.5 0.51899
wandb:          test_accuracy0.75 0.53165
wandb:                 test_auroc 0.44661
wandb: test_balanced_accuracy0.25 0.49619
wandb:  test_balanced_accuracy0.5 0.47966
wandb: test_balanced_accuracy0.75 0.47161
wandb:         test_precision0.25 0.25
wandb:          test_precision0.5 0.23529
wandb:         test_precision0.75 0.22581
wandb:            test_recall0.25 0.45
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.35
wandb:                train_auroc 1.0
wandb:                 train_loss 0.01402
wandb:           val_accuracy0.25 0.55238
wandb:            val_accuracy0.5 0.57143
wandb:           val_accuracy0.75 0.57143
wandb:                  val_auroc 0.50828
wandb:  val_balanced_accuracy0.25 0.53481
wandb:   val_balanced_accuracy0.5 0.53457
wandb:  val_balanced_accuracy0.75 0.50876
wandb:          val_precision0.25 0.2766
wandb:           val_precision0.5 0.27907
wandb:          val_precision0.75 0.25641
wandb:             val_recall0.25 0.5
wandb:              val_recall0.5 0.46154
wandb:             val_recall0.75 0.38462
wandb: 
wandb: 🚀 View run vgg16_2d_79_6_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/si7lz8ho
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_6/wandb/run-20250701_193628-si7lz8ho/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_6/execution_datetimes.json

**************************************************  Experiment 79 | Version 7 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 5}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 6}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 7}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_7/wandb/run-20250701_195749-cyulycyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_7_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/cyulycyj
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁█▅▆▇▆▆▅▄▅▆▆▆▅▅▁▆▆▅▆▆▅▅▆▆▆▆▇▄█▆▆▆▆▆▅▅▅▅▆
wandb:           test_accuracy0.5 ▁▆▇█▇▆▆▅▆▅▆▆▆▆▆▅▅▅▅▅▆▆▅▆▆▅▅▆▆▆▅▅▅▅▅▅▅▅▅▇
wandb:          test_accuracy0.75 █▃▆▁▄▂▃▃▃▃▅▃▂▃▃▁▂▃▂▂▄▃▃▃▄▃▃▃▃▂▃▃▃▂▂▂▃▃▃▃
wandb:                 test_auroc ▁▂▆▄▇▇▇▇▇▇▇▆▇███████████▆▇▇▆▇▆▇▆▆▆▇▇▇▇▆▇
wandb: test_balanced_accuracy0.25 ▂▂▂▁▄▃▃▅▃▅▅▅▆▄▅▅▅▆▇▆▆▆▆▇▅▇▇▆▄▅▆▆▅▆▆▅█▇▄▅
wandb:  test_balanced_accuracy0.5 ▃▁▃▄▅▃▃▃▃▅▅▄▅▆▃▆▅▄▅█▄▄▅▇▆█▆▅▅▆▅▅▅▅▄▄▄▄▇▄
wandb: test_balanced_accuracy0.75 ▅▅▃▁▆▄▇▅▅█▅▂▆▅▆▄▇▃▃█▆▇▆▇▇▅▄▅▇▇▅▆▅▆▆▆▆▇▇▇
wandb:         test_precision0.25 ▁▃▅▅▆▆▅▄▅▅▃▇▇▇▅▅█▆▅▆▅▅▅▅▇▆▇▇▇▆▇▆▆▆▆▅█▄▄▅
wandb:          test_precision0.5 ▁▄▅▃▄▄▄▄▄▄▄▃▄▄▄▃▃▃▄▃▅▆▄▄▃▄▃▄▄▅█▂▃▄▄▄▃▄▄▃
wandb:         test_precision0.75 ▁▁▃▁▆▇▇▇▇▆▇▇▆▆█▇▇▇▆▆▆▇▇▇▆▇▆▆▆▇▆▇▆▆▆▇▇▆▇▇
wandb:            test_recall0.25 █▇▄▄▁▄▅▄▄▄▄▃▄▃▄▅▄▄▄▅▅▄▄▄▄▅▅▄▃▂▄▄▄▄▄▄▄▄▄▄
wandb:             test_recall0.5 █▂▃▃▃▄▅▆▅▇▆▅▆▆▆▆▇▆▆▆▆▅▆▆▄▇▇▆▆▁▆▆▆▆▆▆▆▆▆▄
wandb:            test_recall0.75 ▂▁▂▅▄▇▅▇▇▄▆▄▆▇▆▇▅█▅▇▇▇▇▆▇▇▇▅▇▅▆▇▆▆▇▇▇▆▇▇
wandb:                train_auroc ▁▃▃▄▄▆▆▆▇███████████████████████████████
wandb:                 train_loss ██▆▃▂▁▁▂▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▇▄█▅▆▅█▇▅▇▆▆▆▇▇▆▆▇▆▇▇▇▇▇▆▇█▇▇▆▇▇▆▇▇▇▇
wandb:            val_accuracy0.5 ▁▇▆▇▅▆▆█▅▆▇▆▆▇▆▆▄▆▇▆▆▇▄▇▆▆▆▆▆▆█▇▅▆▅▆▆▆▆▆
wandb:           val_accuracy0.75 █████▆▆▆▅▆▅▆▆▆▁▅▆▅▅▆▅▅██▆▅▅▅▅▅▅▅▅▄▅▅▆▅▅▅
wandb:                  val_auroc ▅▁▂▅▇██▄▆▃▅▅▅▇▆▅▆▅▆▅▅▅▅▄▄▃▃▄▄▇▅▄▅▅▄▄▄▄▂▄
wandb:  val_balanced_accuracy0.25 ▇▂▃▇▄▃▅▆▅▅█▇▇▇▅▆▄▅█▃▅▄▄▄▅█▇▅▅▄▄▄▄▄▅▄▅▅▁▅
wandb:   val_balanced_accuracy0.5 ▅▆▄▃▄▅▄▅▆▁▇▅▆█▆▆▆▆▆▅▅▅▅▅▅▅▆▄▆▅▅▄▄▄▅▄▄▂▄▅
wandb:  val_balanced_accuracy0.75 ▅▅▅▆█▆▅▆▅▅▅▄▄▅▆▁▅▅▇▅▂▇▆▆▅▆▆▆▅▇▅▆▃▅▅▅▅▅▅▄
wandb:          val_precision0.25 ▆█▅▄▅▅▄▅▇▄▂█▆▃▅▄▅▆▅▅▅▄▄▄▅▅▄▁▅▃▃▄▄▄▄▃▄▄▁▄
wandb:           val_precision0.5 ▁▅█▇▄▅▆▃▃▃▄▃▃▄▃▅▄▄▄▄▅▄▄█▃▄▄▃▄▄▄▄▃▄▄▂▃▃▃▃
wandb:          val_precision0.75 ▁▁█▄▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:             val_recall0.25 ██▄▂▄▂▃▄▂▂▂▂▃▂▂▃▂▂▂▃▂▂▂▂▂▃▃▃▂▂▃▂▂▂▂▂▂▃▁▂
wandb:              val_recall0.5 █▁▂▃▃▂▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▃▃
wandb:             val_recall0.75 ▁▃▆▄▆▇▆▆▆▇█▆▇▇▇▇█▇▇▇▆▇▇█▇▇▆▇▅▇▇▇▇▇▇▅▆▆▆▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.58228
wandb:           test_accuracy0.5 0.60759
wandb:          test_accuracy0.75 0.62025
wandb:                 test_auroc 0.62203
wandb: test_balanced_accuracy0.25 0.55508
wandb:  test_balanced_accuracy0.5 0.53898
wandb: test_balanced_accuracy0.75 0.54746
wandb:         test_precision0.25 0.30303
wandb:          test_precision0.5 0.2963
wandb:         test_precision0.75 0.30769
wandb:            test_recall0.25 0.5
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.4
wandb:                train_auroc 0.99948
wandb:                 train_loss 0.0611
wandb:           val_accuracy0.25 0.49524
wandb:            val_accuracy0.5 0.6
wandb:           val_accuracy0.75 0.60952
wandb:                  val_auroc 0.44352
wandb:  val_balanced_accuracy0.25 0.41943
wandb:   val_balanced_accuracy0.5 0.48905
wandb:  val_balanced_accuracy0.75 0.49537
wandb:          val_precision0.25 0.17073
wandb:           val_precision0.5 0.23333
wandb:          val_precision0.75 0.24138
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.26923
wandb: 
wandb: 🚀 View run vgg16_2d_79_7_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/cyulycyj
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_7/wandb/run-20250701_195749-cyulycyj/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_7/wandb/run-20250701_202153-tph8mx6t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_7_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/tph8mx6t
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▃▅▂▄▂▃▇█▂▃▃▄▄▄▄▄▃▆▃▅▅▃▃▁▄▄▅▄▄▂▃▇▅▅▄▄▅▆▆▄
wandb:           test_accuracy0.5 █▇▅▅▅▂▄▃▁▆▄▄▂▃▃▃▃▃▃▃▂▅▂▆▁▃▄▄▃▃▂▃▅▄▄▄▄▄▅▄
wandb:          test_accuracy0.75 ▆▇██▇▇█▆▅▄▂▅▅▅▂▅▃▆▃▂▃▁▂▂▂▂▂▃▁█▅▃▃▄▃▃▂▄▄▄
wandb:                 test_auroc ▁▆██▆▄▄▄▅▅▅▄▅▁▄▄▅▅▅▄▄▃▃█▄▅▅▆▅▄▄▄▄▂▂▂▄▅▅▅
wandb: test_balanced_accuracy0.25 ▃▅▄█▅▅▆▅▃▄▃▂▄▄▅▃▂▂▃▂▄▃▃▁▂▄▄▅▃▃▃▃▄▄▅▁▅▄▄▄
wandb:  test_balanced_accuracy0.5 ▇█▅▇█▁▇▄▄▃▂▃▆▃▃▃▃▂▂▃▄▃▂▂▁▂▂▆▄▆▃▅▆▄▃▄▄▃▄▄
wandb: test_balanced_accuracy0.75 ▄▃▄▆█▅▂▅▅▄▄▃▅▅▅▁▁▅▂▆▄▁▁▁▁▂▃▃▂▄▂▃▇▃▃▃▁▃▃▃
wandb:         test_precision0.25 ▂▄▂▃█▄▅▃▃▃▄▁▄▂▂▆▄▂▃▂▁▁▁▂▃▃▃▂▂▃▄▃▃▄▃▃▂▁▃▂
wandb:          test_precision0.5 ▄▃█▄▆▃▁▄▂▂▃▂▂▁▂▁▂▂▂▂▁▁▂▃▂▃▂▃▃▂▂▃▃▂▂▂▂▂▂▂
wandb:         test_precision0.75 ▁▄▁▁▁█▆▇▄▅▇▅▅█▄▅▆▅▄▄▅▄▅▅▄▅▄▄▄▅▅▄▅▅▄▅▅▅▅▅
wandb:            test_recall0.25 █▄▅▇▂▆█▂▂▄▄▂▇▂▄▁▄▅▂▂▄▄▄▄▅▄▂▄▆▄▄▅▄▂▂▃▅▁▁▃
wandb:             test_recall0.5 ▁▅▃▁▆█▃▃▃▄▃▃▃▃▃▃▄▅▅▄▃▃▃▂▃▃▄▅▃▂▃▄▄▄▅▆▅▆▅▄
wandb:            test_recall0.75 ▁▁▂▂▅▂▄▄▅▅▅▄▄▅▃▄▅▅▇█▅▅▅▅▅▄▄▄▇▆▅▅▅▅▅▇▅▅▅▅
wandb:                train_auroc ▂▁▄▅▇███████████████████████████████████
wandb:                 train_loss █▄▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▃▆▃▇▆█▇▆▅▇▆▇▆▇▅▇▆▆▆▇▆▆▆▆▆█▆▇▆█▅▆▆▇▆████
wandb:            val_accuracy0.5 ▆██▆█▇▆▇▆▆█▅▁▆▅▅▆▆▅▄▅▅▃▅▅▄▃▄▆▆▅▅▅▅▅▃▇▆▆▆
wandb:           val_accuracy0.75 ██▇▅▆▆▅▄▅▅▅▂▃▄▄▄▄▃▃▃▃▃▃▃▃▁▃▁▂▅▅▁▅▄▄▃▃▄▄▄
wandb:                  val_auroc █▂▅▁▂▇▄▄▃▃▄▃▄▄▅▆▆▃▄▄▅▅▅▄▅▇▆▅▅▆▆▆▆▅▅▅▇▇▇▇
wandb:  val_balanced_accuracy0.25 ▃▅▁▃▅▅▆▄▅▅▃█▆▇▇▆▇▆▆▅▆▅▄▄▄▄▃▃▅▄▆▃▄▅▆▄▇▆▇█
wandb:   val_balanced_accuracy0.5 ▁█▄▃▅▃▃▅▄▅▅▄▇█▁▃▆▅▆▆▄▄▂▄▄▄▄▅▆▇▅▅▅▄▅█▇▇▇▆
wandb:  val_balanced_accuracy0.75 ▃▃▆▄▇▂▅▅▃▃▆▄▇▄▁▄▃▆▃▆▃▅▅▇▃▅▄▃▄▃▁█▆▆█▇██▅▆
wandb:          val_precision0.25 ▄▁▁▄▅▅▃▄▅▅▃▄▄▅▅▅▄▆▅▅▄▅▅▅▃▆▅▆▅▅▄▇▅▇██▆▇▇▇
wandb:           val_precision0.5 ▆▅▄▂▁▅▄▄▄▄▄▆▄▃▅▅▇▆▅▅▅▅▅▅▅▅▅▆█▆▆▇▆▆▆▇▇▇▇▇
wandb:          val_precision0.75 ▁▁█▆▇█▆██▅▆▇█▇▇█▆▆▆▅▆▆▆▆▆▆▆▆▆▇▆▆▅▇█▆▇▇█▇
wandb:             val_recall0.25 █▆█▂▃▂▂▅▅▂▂▃▅▂▃▃▃▂▃▃▃▂▃▃▃▃▃▁▃▃▃▃▃▃▄▄▃▃▃▃
wandb:              val_recall0.5 ██▁▁▄▃▃▂▂▃▂▂▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▃▃▃▃▃▂▃
wandb:             val_recall0.75 ▁▁▁▂▃▅▃▅▄▃▅▇▅▃▅▄▅▅▅▅▅▅▅▄█▃▅▄▄▅▄▆▃▄▃▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.53165
wandb:           test_accuracy0.5 0.55696
wandb:          test_accuracy0.75 0.58228
wandb:                 test_auroc 0.54788
wandb: test_balanced_accuracy0.25 0.50466
wandb:  test_balanced_accuracy0.5 0.50508
wandb: test_balanced_accuracy0.75 0.50551
wandb:         test_precision0.25 0.25714
wandb:          test_precision0.5 0.25806
wandb:         test_precision0.75 0.25926
wandb:            test_recall0.25 0.45
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.35
wandb:                train_auroc 0.99944
wandb:                 train_loss 0.04705
wandb:           val_accuracy0.25 0.60952
wandb:            val_accuracy0.5 0.61905
wandb:           val_accuracy0.75 0.62857
wandb:                  val_auroc 0.54211
wandb:  val_balanced_accuracy0.25 0.53408
wandb:   val_balanced_accuracy0.5 0.52751
wandb:  val_balanced_accuracy0.75 0.52093
wandb:          val_precision0.25 0.28571
wandb:           val_precision0.5 0.28125
wandb:          val_precision0.75 0.27586
wandb:             val_recall0.25 0.38462
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.30769
wandb: 
wandb: 🚀 View run vgg16_2d_79_7_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/tph8mx6t
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_7/wandb/run-20250701_202153-tph8mx6t/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_7/wandb/run-20250701_204423-ogvcn0el
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_7_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ogvcn0el
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▇▂▄█▁▃▃▄▇▆▆▃▄▅▇▃▄▄▄▂▃▃▄▄▂▄▄▄▄▅▄▅▅▄▅▅▅▄▅▄
wandb:           test_accuracy0.5 ▁▁█▃███▆▆▅▆▆▇▅▅▅▅▆▄▅▆▅▅▅▅▅▅▆▄▄▅▅▅▅▅▆▅▅▅▅
wandb:          test_accuracy0.75 █▇█▇▇▄▆▄▆▃▄▅▅▃▇▄▄▅▃▃▃▄▃▁▅▃▄▄▄▄▄▄▃▆▄▃▃▄▄▃
wandb:                 test_auroc ▁▃▆▅▅▆▆▇▆█▇▆▆▅█▆▆▆▆▆▆▆▆▆▅▅▆▅▅▆▅▅▅▅▅▅▅▅▅▆
wandb: test_balanced_accuracy0.25 ▆▄▄▃▆▆▄▆▄▆▅▇█▅▂▅▃▄▅▅▇▆▅▇▇▆▆█▁▂▄▄▄▆▅▆▆▄▄▆
wandb:  test_balanced_accuracy0.5 ▂▁▄▁▄▇▇▃▆▅▅▇▆▂▅▃▅▂▅▅▅▅▄█▃▂▂▅▄▂▄▃▄▃▄▅▄▃▄▃
wandb: test_balanced_accuracy0.75 ▅▅▅▅▄▆█▆▇▆▅▄▄▄▅▆▆▆▃▆▆▆▅▅▄▂▂▃▃▃▂▂▃▂▁▃▂▄▄▇
wandb:         test_precision0.25 ▆▃▃▃█▃▄▄▄▁▅▂▂▃▃▃▃▃▅▄▁▂▁▃▁▂▂▃▃▂▂▂▂▃▁▃▄▃▃▃
wandb:          test_precision0.5 ▆▅▁▆█▇▇▇▇▅▇▆▇▇▆▆▅▆▇▇▇▇█▆▆▆▆▆▆▆▆▆█▆▅▇▆▅▆▇
wandb:         test_precision0.75 ▁▁▇▁▁▇▇█▇▇▇▇▆▅▇▆█▆█▆▇▇▇▆▆▆▇▅▅▅▅▅▆▅▅▆▆▆▆▅
wandb:            test_recall0.25 ██▇▄▁▂▃▃▂▂▃▄▂▁▂▅▃▃▃▂▃▃▃▅▂▃▂▃▄▃▃▃▃▂▂▂▃▃▄▃
wandb:             test_recall0.5 █▅▁▂▄▂▄▂▃▅▄▅▄▄▄▄▄▅▄▄▅▄▄▃▃▆▃▄▄▄▄▃▃▃▅▅▃▄▃▅
wandb:            test_recall0.75 ▁▁▁▁▃▂▅▅██▆▇▅▅▅▇▇▇▇▆▆▆▇▆▆▅▅▅▅▅▅▅▅█▅▅▅▆█▅
wandb:                train_auroc ▁▄▆▆▇█████▇█████████████████████████████
wandb:                 train_loss ██▇▇▆▄▃▃▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▂▁██▇█▇▇▆▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇██▇████▇█▇▇▇▇▆
wandb:            val_accuracy0.5 █▁▇▆▄▄▄▅▅▄▄▄▄▅▅▅▅▅▅▅▄▁▅▅▅▄▃▄▄▅▄▄▅▄▄▄▄▄▅▄
wandb:           val_accuracy0.75 ██▇▆▇▅▅▄▁▄▃▃▅▁▂▁█▂▂▃▃▃▃▂▂▂▄▃▂▂▂▂▂▃▂▂▂▂▂▂
wandb:                  val_auroc ▁▄▅▆▆▅▆▇▆▆▅▄▆▆▆▅█▅▆▆▅▆▇▇▆▅▅▆▆▆▆▄▆▅▅▇▆▆▆▆
wandb:  val_balanced_accuracy0.25 ▅▄▅▅▇▆▅▄▆▃▇▄▁▇▅▆▆▆▅▆▆▅▇▇▇▄█▆▆▆▆▃▄▅▅▅▅▅▅▄
wandb:   val_balanced_accuracy0.5 █▄▅▃▆▆▄▃▄▆▁▆▃▅▇▄▅▆▆▅▅▅▄▅▅▇▅▄▅▄▅▅▃▄▃▅▄▃▄▄
wandb:  val_balanced_accuracy0.75 ▄▅▄▅▃▄▅▅▅▅▄▆▅▅▆▇▇▇▇▇▇▇▇▇█▆▆▇▄▅▆▅▄▁▃▃▃▆▅▇
wandb:          val_precision0.25 ▄▃▅▆▃▆▇█▄▁▇▇▆▆▇▇▆▆▆▅▂▇▇▇▇▇▇▇▇▆▃▅▅▇▇▅▅▅▅▅
wandb:           val_precision0.5 ▁█▅▅▅▅▅▅▅▅▆▆▅▄▅▅▅▅▅▅▆▆▅▅▅▅▅▅▆▅▅▅▆▄▅▅▅▅▅▆
wandb:          val_precision0.75 ▁▁▆▃▅▄▅▅▅▅▅▃▆▄▅▅▅▆▅█▅▆▅▆▅▆▆▆▅▅▅▅▄▅▅▅▅▅▅▅
wandb:             val_recall0.25 ████▁▂▂▂▂▂▂▂▃▂▂▃▂▂▂▂▂▂▃▃▄▂▂▂▂▁▂▂▂▃▂▂▃▁▂▂
wandb:              val_recall0.5 █▂▁▂▂▄▃▂▃▃▃▄▃▃▄▃▄▄▄▄▄▃▃▃▃▄▃▃▄▄▃▃▁▃▃▃▃▃▃▃
wandb:             val_recall0.75 ▁▁▁▁▃▄▄▅▅▆▇▆▄▆▇▇▅▇▇▇▇▇█▆▇█▆▆▅▆▄▅▄▅▇▅▅▅▆▆
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.51899
wandb:           test_accuracy0.5 0.5443
wandb:          test_accuracy0.75 0.56962
wandb:                 test_auroc 0.5178
wandb: test_balanced_accuracy0.25 0.49619
wandb:  test_balanced_accuracy0.5 0.51314
wandb: test_balanced_accuracy0.75 0.53008
wandb:         test_precision0.25 0.25
wandb:          test_precision0.5 0.26471
wandb:         test_precision0.75 0.28125
wandb:            test_recall0.25 0.45
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0.45
wandb:                train_auroc 1
wandb:                 train_loss 0.00109
wandb:           val_accuracy0.25 0.58095
wandb:            val_accuracy0.5 0.57143
wandb:           val_accuracy0.75 0.6
wandb:                  val_auroc 0.55818
wandb:  val_balanced_accuracy0.25 0.51509
wandb:   val_balanced_accuracy0.5 0.49586
wandb:  val_balanced_accuracy0.75 0.51485
wandb:          val_precision0.25 0.26316
wandb:           val_precision0.5 0.24324
wandb:          val_precision0.75 0.26471
wandb:             val_recall0.25 0.38462
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.34615
wandb: 
wandb: 🚀 View run vgg16_2d_79_7_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ogvcn0el
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_7/wandb/run-20250701_204423-ogvcn0el/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_7/execution_datetimes.json

**************************************************  Experiment 79 | Version 8 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 19, 1.0: 9}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 16, 1.0: 12}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 21, 1.0: 11}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 11, 1.0: 17}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_8/wandb/run-20250701_210048-ica8qwgk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_8_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ica8qwgk
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading history steps 214-216, summary, console lines 4-5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▅▇▇▇▄▅▅▅▅▆▇▆▆▅▅▆▆▆█▆▆▆▇█▇▇▆█▆▆▇▆▆▆▅▆▆▆▆
wandb:           test_accuracy0.5 ▁███▅▇▆▇▇▅▅▅▅▆▆▇▇▇▆▇▇▆▆▅▆▆▇▇▇▅▆▆█▇▆▇▅▆▆▆
wandb:          test_accuracy0.75 ███████▇▄▆▁▄▄▃▂▅▆▆▁▅▅▅▆▂▅▄▃▃▁▃▄▅▃▆▄▄▅▂▂▃
wandb:                 test_auroc ▁▃▆▆▆▆▇▆▆▅▅▅▇▆▆▅▇▇▆▆▆▇▇▆▆▆▅▆▆▇▆█▇▇▇▇▇▇▆▇
wandb: test_balanced_accuracy0.25 ▁▁▃▅▃▂▅▄▅▂▁▂▄▂▄▃█▃▄▃▄▄▆▅▅▄▆▃▄▄▄▅▄▅▅▄▄▄▃▅
wandb:  test_balanced_accuracy0.5 ▁▃▄▄▂▅▅▃▅▇▂▄▄▄▄▄▃█▅▅▄▄▅▆▆▄▄█▅▄▃▄▅▄▅▄▄▄▄▅
wandb: test_balanced_accuracy0.75 ▂▂▂▂▃▄▂▃▁▁▆▁▁▅▃▂▁▄▄▄▄▄▃▄▄▆█▁▄▄▅▅▃▃▄▅▄▇▆▅
wandb:         test_precision0.25 ▁▁▁▅▂▄▅▅▂▅▄▅▃▅▃▄▃▇▆▆▄▆▄▅▄▅██▅▃▄▇▆▄▄▅▃▄▄▄
wandb:          test_precision0.5 ▅▅▁▇█▆▇█▇█▇▆▇▅▅▆▇▆▆▆▇▆▇▇▇▇▆▇█▇▆▇▆▇▇▇▆▇▆▇
wandb:         test_precision0.75 ▁▁▁▅█▁█▁▅▃▃▃▂▃▃▃▃▃▃▃▄▄▃▃▃▃▃▃▃▄▃▃▄▃▃▃▃▃▃▃
wandb:            test_recall0.25 ██▆▄▄▄▆▄▄▁▂▂▃▄▃▂▂▂▄▃▃▃▃▄▂▂▃▅▂▄▃▄▄▃▃▄▄▄▄▄
wandb:             test_recall0.5 ▂▃▁▃█▅▅▅▄▁▄▄▅▄▂▆▇▃▄▄▇▄▄▄▅▄▅▅▄▄▅▅▄▄▅▅▅▅▅▅
wandb:            test_recall0.75 ▁▁▁▂▁▃▃▂▂▂▃▅▃▅▆▅▂▅▃▃▅▅▅▅▄▅▆▅▅█▄▅▅▆▆▆▅▅▆▅
wandb:                train_auroc ▁▅▆▇████████████████████████████████████
wandb:                 train_loss ██▇▇▆▄▃▃▂▂▂▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁█▃█▇▇▅▆▆▅▆▅▆▇▆▅▆█▇▅▆▆▇▇▆▆▆▅▆▅▆▆▆▆▆▇▆▆▆
wandb:            val_accuracy0.5 ▁▇▇█▇▆▆▇▆▆▆▇▇▅▅▇▆▆▆▇▆▆▅▆▆▆▆▆▅▇▆▆▆▆▆▆▆▆▅▆
wandb:           val_accuracy0.75 ███▇██▇▄▃▄▃▅▃▄▅▅▆▄▂▂▅▅▂▁▄▃▁▅▄▆▄▃▃▃▆▃▃▃▃▂
wandb:                  val_auroc ▅▁▁▄▅█▄▇▄█▇▅▄▅▇▆▆▅▆▄▆▅▆▄▅▄▆▆▄▅▆▆▆▆▆▅▆▆▅▆
wandb:  val_balanced_accuracy0.25 ▆▆▇▆▆▇▃▆▄▁▄▄█▃▅▄▄▅▄▄▄▂▃▄▃▃▃▅▄▄▃▂▄▅▅▄▄▅▅▄
wandb:   val_balanced_accuracy0.5 ▅▄▁▇▇▅█▄▆▂▄▅▄▂▄▃▂▄▂▂▄▄▅▃▂▃▅▆▅▄▄▂▄▃▄▄▅▄▅▅
wandb:  val_balanced_accuracy0.75 ▄▃▄▇▄▄█▇▄▅█▄▄▂▅▄▄▆▄▁▇▃▄▄▁▄▂▃▁▅▄▂▄▁▃▃▂▃▂▃
wandb:          val_precision0.25 ▄▄▄█▁▅▄▂▄▄▄▁▃▃▄▂▁▃▂▃▃▂▄▃▁▁▃▃▁▁▂▃▃▃▃▄▄▄▄▃
wandb:           val_precision0.5 █▇▆▂▃▂▂▃▂▂▂▂▂▃▂▂▂▁▁▂▂▁▂▂▂▁▁▂▂▅▂▂▁▃▂▁▂▂▄▃
wandb:          val_precision0.75 ▁▁▁█▄▃▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▂▂▃▃▃▂▃▃▃▂▃▃
wandb:             val_recall0.25 █▅▄▂▃▃▄▃▃▁▁▁▃▃▄▂▂▂▃▁▂▄▃▂▃▂▂▂▂▂▁▄▃▂▂▃▃▂▂▂
wandb:              val_recall0.5 ▂▁▁▃▂▄▅█▄▃▃▃▅▃▃▂▄▃▄▃█▄▃▃▃▃▂▄▃▃▃▃▄▄▁▄▅▄▄▇
wandb:             val_recall0.75 ▁▁▁▄▃▄▅▅▄▅▅▆▅▅▅▅▃▃▃▅▇▅▅█▅▅▄▅▅▅▅▇▅▅▅▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.58228
wandb:           test_accuracy0.5 0.60759
wandb:          test_accuracy0.75 0.63291
wandb:                 test_auroc 0.63898
wandb: test_balanced_accuracy0.25 0.58814
wandb:  test_balanced_accuracy0.5 0.55551
wandb: test_balanced_accuracy0.75 0.55593
wandb:         test_precision0.25 0.32432
wandb:          test_precision0.5 0.31034
wandb:         test_precision0.75 0.32
wandb:            test_recall0.25 0.6
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0.4
wandb:                train_auroc 0.9995
wandb:                 train_loss 0.05242
wandb:           val_accuracy0.25 0.51429
wandb:            val_accuracy0.5 0.60952
wandb:           val_accuracy0.75 0.60952
wandb:                  val_auroc 0.49951
wandb:  val_balanced_accuracy0.25 0.44499
wandb:   val_balanced_accuracy0.5 0.50828
wandb:  val_balanced_accuracy0.75 0.48247
wandb:          val_precision0.25 0.19512
wandb:           val_precision0.5 0.25806
wandb:          val_precision0.75 0.22222
wandb:             val_recall0.25 0.30769
wandb:              val_recall0.5 0.30769
wandb:             val_recall0.75 0.23077
wandb: 
wandb: 🚀 View run vgg16_2d_79_8_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ica8qwgk
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_8/wandb/run-20250701_210048-ica8qwgk/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_8/wandb/run-20250701_211715-hbzqlmzp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_8_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/hbzqlmzp
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▄▁▃▆▇▁▇▃▇▆▇█▄▅▅█▇▆▆▅▅▅▆▅▆▅█▇▆█▅▇▇▇▇▇▇▆▇▆
wandb:           test_accuracy0.5 ▅▅▅▅▇▇▆▇▆▁▃▆▆▇▅▅▅█▆█▅▅▅▆▅▅▇▅▄▇▆▆▆▆▆▆▅▆▆▆
wandb:          test_accuracy0.75 ████▇▇▆▇▆▁▄▆▂▂▁▃▄▃▆▃▄▁▄▃▆▃▁▄▄▄▄▄▄▄▄▃▄▄▄▃
wandb:                 test_auroc ▃▁█▆▇▇▆▅▆▃▂▂▄▂▁▃▃▃▂▂▂▂▆▄▃▄▃▃▃▃▂▄▄▃▃▃▃▄▄▄
wandb: test_balanced_accuracy0.25 ▁▁▂▃█▅▆▄▃▃▄▂▅▃▃▃▃▃▄▂▃▂▂▂▁▂▂▃▂▄▄▃▃▁▂▂▂▄▂▄
wandb:  test_balanced_accuracy0.5 ▂▃▆▇█▇▇▃▅▁▄▃▃▃▄▄▃▃▃▆▁▄▁▃▂▆▅▃▃▅▄▃▃▅▄▃▄▆▄▅
wandb: test_balanced_accuracy0.75 ▂▃▂▂▄▁█▂▂▃▃▂▂▄▅▁▂▆█▆▃▅▂▂▂▂▆▄▆▄▆▆▃▃▃▅▄▃▃▄
wandb:         test_precision0.25 ▁▄█▄▇▆▄▃▅▆▅▂▄▄▄▁▆▅▄▆▄▄▃▆▂▅▅▅▅▃▂▄▅▄▆▆▆▅▃▅
wandb:          test_precision0.5 ▃▅▅█▄▇▇▅▁▃▁▁▂▁▅▃▇▃▃▂▂▃▂▂▁▅▂▅▄▄▄▃▃▂▃▃▃▄▄▄
wandb:         test_precision0.75 ▁▁▅▅▅▅▁▅▆▆▆▆▅▆▅▅▆▆▆▅▆█▆▆▆▅▅▆▆▆▆▅▅▅▅▅▆▅▅▆
wandb:            test_recall0.25 ▇█▇▇▆▇▇▆▃▂▁▁▄▄▃▃▃▄▂▂▂▄▄▄▂▂▁▃▂▃▂▂▂▂▂▃▄▂▂▂
wandb:             test_recall0.5 ▅▄▁▂▃▇▄▄▄█▅▂▄▄▆▃▃▄▅▅▅▅▅▄▆▂▅▃▂▃▂▄▄▅▅▄▄▄▄▄
wandb:            test_recall0.75 ▁▁▁▁▂▅▅▅▄▇▅▇▅█▃▅▇▇▆▆▆▆▆▄▇▄▇▅▅▅▅▅▆▅▆▆▅▆▅▆
wandb:                train_auroc ▁▄▅▅▆▇▇▇████████████████████████████████
wandb:                 train_loss █▇▆▅▅▄▃▄▃▃▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▃▂▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁█▅▇▇▂▇██▇▇▆▆▁▅▅▃▄▅▅▅▆▆▆▆▆▄▅▆▅▆▄▅▄▅▆▆▄▇▅
wandb:            val_accuracy0.5 ▇▅▁▄▅▇▁█▆█▇▇█▄▇▆▄▅▄▄▃▇▅▅▅▄▇▆▅▅▆▆▅▅▅▃▄▄▄▅
wandb:           val_accuracy0.75 ███▇▆▇▃▅▅▃▅▃▅▃▆▁▇▃▄▁▅▄▂▃▂▃▅▄▃▃▂▁▁▃▃▃▃▁▁▃
wandb:                  val_auroc ▆▁▄▇▆▅▆▄▄▆▆▆▆▇▅▄▆██▇▇▆▇▆▆▆█▅▆▅▆▆▆▆▆▆▇▇▇▇
wandb:  val_balanced_accuracy0.25 ▄▆▄▁▂▆█▅▂▇▅▃▆▅▇▄▆▄▅▄▅▄▄▅▆▆▇▇▄▆▆▆▄▄▃▆▃▅▃▅
wandb:   val_balanced_accuracy0.5 ▁▃▅▆▅█▅▅▇▆▆▅▄▄▅▅▅▅▅▆▆▄▄▄▃▅▅▆▆▄▆▆▅▅▅▅▅▅▅▅
wandb:  val_balanced_accuracy0.75 ▂▂▁▂▃▃▂▂▁▃█▄▄▄▃▄▄▄▃▄▄▂▃▃▃▄▄▄▄▃▅▄▃▅▄▄▄▄▅▄
wandb:          val_precision0.25 ▂▇▇█▃▂▃▄▅▆▅▅▂▄▅▆▂▂▃▂▅▅▅▃▃▂▂▃▄▄▄▅▄▃▄▅▃▅▄▁
wandb:           val_precision0.5 ▁▄▅▅▄▁▃▄▆▅██▇█▇▇▆▄▆▆▅▅▆▆▆▄▄▅▆▆▅▄▆▄▅▆▆▄▅▆
wandb:          val_precision0.75 ▁▁▄▅▆▇▆▆▅▆▇█▆▇█▆▇▇▆▆▆▅█▇▅▆▆▆▆▆▅▆▆▇▆▆▆▆▆▆
wandb:             val_recall0.25 ██▅▄▂▄▃▃▅▄▃▃▂▄▂▂▂▂▅▁▃▃▂▃▃▃▂▃▂▃▂▂▂▃▃▃▂▃▃▃
wandb:              val_recall0.5 ▆▄▆▃▁▄▅▃▇▄▅▆▇▇▆▇█▅▅▇▇▆▆▂▃▅▅▅▅▆▅▇▇▅▇▅▇▇▇▆
wandb:             val_recall0.75 ▁▁▂▁▁▇▆▅▄▅▄▆▇█▄▅▅▆▅▅▅▅▇▄▅▆▅▆▄▇▅▄▄▆▆▆▅▆▇▆
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.56962
wandb:           test_accuracy0.5 0.62025
wandb:          test_accuracy0.75 0.60759
wandb:                 test_auroc 0.55297
wandb: test_balanced_accuracy0.25 0.53008
wandb:  test_balanced_accuracy0.5 0.54746
wandb: test_balanced_accuracy0.75 0.52246
wandb:         test_precision0.25 0.28125
wandb:          test_precision0.5 0.30769
wandb:         test_precision0.75 0.28
wandb:            test_recall0.25 0.45
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.35
wandb:                train_auroc 0.99954
wandb:                 train_loss 0.04662
wandb:           val_accuracy0.25 0.60952
wandb:            val_accuracy0.5 0.62857
wandb:           val_accuracy0.75 0.65714
wandb:                  val_auroc 0.55185
wandb:  val_balanced_accuracy0.25 0.53408
wandb:   val_balanced_accuracy0.5 0.53384
wandb:  val_balanced_accuracy0.75 0.55282
wandb:          val_precision0.25 0.28571
wandb:           val_precision0.5 0.29032
wandb:          val_precision0.75 0.32143
wandb:             val_recall0.25 0.38462
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.34615
wandb: 
wandb: 🚀 View run vgg16_2d_79_8_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/hbzqlmzp
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_8/wandb/run-20250701_211715-hbzqlmzp/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_8/wandb/run-20250701_214006-xz0oqfkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_8_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/xz0oqfkc
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▂▁▁▆▄▇▆█▆█▅▆▇▆▅▇█▅▇▇▆▇▆▆▅▇█▇▆▆▆█▅▅▇▇▇▆█▆
wandb:           test_accuracy0.5 ▁▅███▇▅▃▅▇▂▄▆▅▅▄▃▄▃▅▆▄▅▆▆▄▁▃▄▃▃▃▅▅▄▄▄▄▃▃
wandb:          test_accuracy0.75 ████▇█▅▆▅▅▇▇▄▄▃▁▄▃▃▆▅▄▅▅▄▃▃▃▃▃▄▄▅▃▃▃▃▃▃▅
wandb:                 test_auroc ▃▃▁▆▆▅▃▅▅▅▄▅▅▅▆▇▆▄▅▄▇▇▇▅▅▄▅█▇▇▆▆▆▆▆▅▅▆▇▅
wandb: test_balanced_accuracy0.25 ▆▅▄▆▃▁▃▄█▃▄▄▆▅▆▄▅▅▆▄▆▅▄▅█▄▆▆▆▅▆▆▅▆▅▆▆▃▅▆
wandb:  test_balanced_accuracy0.5 ▁▄▃▆▃█▄▅▄▅█▃▅▄▆▅▆▄▄▅▅▅▆▄▄▄▅▆▄▄▆▄▄▅▄▃▃▆▅▅
wandb: test_balanced_accuracy0.75 ▅▆▄▄▇▅▆▅▅▂▂▄▃▄▅▅▄▄▆▃▄█▆▅▆▃▁▂▂▇▁▂▅▁▂▂▃▂▅▄
wandb:         test_precision0.25 ▅▆▅▅▄▃▄▃▆▄▆▆▄▄▄▁▅▅▅▆▅█▅▆▆▆▆▆▆▅▆▄▄▄▆▄▃▆▇▆
wandb:          test_precision0.5 ▅▁██▆▅▅▆▅▆▇▅▅▆▆▆▅▆▅▄▅▆▅▅▆▆▅▅▅▅▅▅▅▅▆▅▄▅▅▆
wandb:         test_precision0.75 ▁▁▁▁▁█▇█▇▇▆▆▆▆▆▆▆▇▆▇▅▆▆▆▆▇▆▆▇▆▅▅▅▅▆▇▅▇▅▇
wandb:            test_recall0.25 ██▇▃▅▅▅▅▃▁▄▃▂▄▃▂▃▂▃▄▃▄▄▁▃▄▄▄▄▂▂▂▃▃▄▃▅▂▃▄
wandb:             test_recall0.5 ▁▅▅▄▇▅▂▇▅▃▅▂▇▅▆▅▄▄▄▆▆▆▆▆▇█▄▆▇▇▇▇▇▆▅▅▅▇▇▇
wandb:            test_recall0.75 ▁▁▁▂▆▅▄▂▃▅▅▃▅█▅▄▅█▇▆▇▇▅█▄▄▇▅▇▇▇▅▅▆▄▆▅▇▄▆
wandb:                train_auroc ▁▃▅▆▆▆██▇███████████████████████████████
wandb:                 train_loss █▇▇▅▄▃▂▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▄▂▃▇▇▇▇▆▆▆▆▆▇▇▅▆▇▅▅▆█▇▅▆▆▅▅▅▅▇▄▇▆▆▆▄▅▆▅
wandb:            val_accuracy0.5 █▃▇▇▄▃▄▅▃▄▄▃▄▄▄▅▅▂▁▂▃▄▄▆▃▄▃▄▄▂▄▃▃▅▅▄▄▄▄▄
wandb:           val_accuracy0.75 ██▇▇▇▇▆▆▅▄▅▄▁▄▆▄▅▄▃▃▃▅▃▄▃▄▄▄▄▄▄▃▄▅▄▃▄▃▄▅
wandb:                  val_auroc █▂▂▄▄▅▂▂▃▄▃▃▃▃▃▂▃▃▁▄▄▃▅▄▄▄▄▅▄▃▄▃▄▄▄▄▄▄▅▃
wandb:  val_balanced_accuracy0.25 ▄▄▁▂▃▃▃▅▃▃▃▃▄█▃▅▃▆▃▃▅▂▅▄▄▅▄▅▅▅▅▅▄▄▃▃▃▂▆▄
wandb:   val_balanced_accuracy0.5 █▄▃▁▃▄▂▃▂▂▃▃▅▃▂▂▂▂▂▂▃▂▅▂▁▂▄▄▂▄▃▃▅▄▄▃▄▄▅▄
wandb:  val_balanced_accuracy0.75 █▇▂▄▇▂▁▂▆▆▅▅▂▇▅▆▅▄▇▄▁▂▄▇▇▅▃▄▁▅▆▇▅▆▅▇▆▄▇▇
wandb:          val_precision0.25 ▅▅▃▄▂▁▁▂▅▅▅▇▂▆▂▅█▆▅▅▃▃▃▆▇▄▅▄▅▃▄▄▄▄▅▃█▄▇▄
wandb:           val_precision0.5 ▅▂▇█▇▄▅▇▇▂▂▄▄▅▆▆▅▅▆▅▄▅▅▄▆▅▄▅▆▆▆▅▆▁▇▆▅▆▅▆
wandb:          val_precision0.75 ▁▁▁█▅▅▇▆▆▆▆▆▇▅▆▆▆▆▅▆▆▆▅▇▇▆▆▆▆▆▇▇▇▇▇▇▇▆▇▇
wandb:             val_recall0.25 █▆▄▄▃▃▁▂▃▁▃▂▃▂▂▄▃▁▃▄▁▃▃▃▃▃▄▂▃▁▂▁▂▃▂▂▂▂▂▂
wandb:              val_recall0.5 ▁▁▂▂▃▄▃▄▁▂▃▃▄▅▃▃▄▄▃▄▅▄▅▄▅▅▅▅▄▅█▄▄▄▄▄▆▃▅▅
wandb:             val_recall0.75 ▁▃▄▅▄▂▄▄▃▂█▃▅▆▅▄▅▄▄▄▅▅▆▅▃▄▄▆▅▅▆▆█▅▅▅▅▅▅▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.50633
wandb:           test_accuracy0.5 0.50633
wandb:          test_accuracy0.75 0.5443
wandb:                 test_auroc 0.50678
wandb: test_balanced_accuracy0.25 0.50424
wandb:  test_balanced_accuracy0.5 0.48771
wandb: test_balanced_accuracy0.75 0.51314
wandb:         test_precision0.25 0.25641
wandb:          test_precision0.5 0.24324
wandb:         test_precision0.75 0.26471
wandb:            test_recall0.25 0.5
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0.45
wandb:                train_auroc 1
wandb:                 train_loss 0.00443
wandb:           val_accuracy0.25 0.52381
wandb:            val_accuracy0.5 0.55238
wandb:           val_accuracy0.75 0.58095
wandb:                  val_auroc 0.50852
wandb:  val_balanced_accuracy0.25 0.50292
wandb:   val_balanced_accuracy0.5 0.52191
wandb:  val_balanced_accuracy0.75 0.52799
wandb:          val_precision0.25 0.25
wandb:           val_precision0.5 0.26667
wandb:          val_precision0.75 0.275
wandb:             val_recall0.25 0.46154
wandb:              val_recall0.5 0.46154
wandb:             val_recall0.75 0.42308
wandb: 
wandb: 🚀 View run vgg16_2d_79_8_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/xz0oqfkc
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_8/wandb/run-20250701_214006-xz0oqfkc/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_8/execution_datetimes.json

**************************************************  Experiment 79 | Version 9 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 36, 1.0: 28}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 31, 1.0: 33}
    Batch label distribution: {0.0: 32, 1.0: 32}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 26, 1.0: 34}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_9/wandb/run-20250701_215559-1jberh9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_9_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/1jberh9r
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▄▃▄▃█▄▆▆▆▇▆▆▅█▇▆▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇
wandb:           test_accuracy0.5 ▁▇▆█▆▂▆█▄▆█▄▇▆▄▆▂▇▅▄▂▄▇▅▅▅▂▆▅▅▅▄▅▅▅▅▅▅▅▅
wandb:          test_accuracy0.75 ▇▇█▇▇▇▆▄▅▄▃▄▂▂▃▄▃▃▃▁▆▃▃▃▂▂▃▃▅▂▂▃▃▃▂▁▂▃▂▂
wandb:                 test_auroc ▁▂▃▅▅▇█▇▅▇▄▄▆▆▆▆▆▆▇▅▄▅▆▆▆▅█▇▆▆▆▆▆▅▅▆▆▆▆▆
wandb: test_balanced_accuracy0.25 ▃▃▂▁█▃▅▃▆▅▅▅▅▄▆▅▇▆▆▅▆▇▇▇▇█▇▇▇▇█▇▅█▇█████
wandb:  test_balanced_accuracy0.5 ▂▂▁▃▄▂▄▄▅▅▄▄▅▄▅▅▆▇█▆▅▆▆▄▆▇▇▅▆▅▇█▇█▇▇▇▆▇▇
wandb: test_balanced_accuracy0.75 ▂▅▃▁▁▁▄▁▄▂▇▇▅▆▅▅▄▃▂▅▆▆▃█▇▆▆███▆███▅▇▆▇▇▇
wandb:         test_precision0.25 ▁▁▁▁▁▆▂▃▅▄█▄▄█▄▄▂▄▄▄▆▂▅▅▅▅▇▇▅▆▇▆▆▇▇▇▇▇▆▇
wandb:          test_precision0.5 ▄▃▄▃▄▄▅▁▆▆▆▅▅▅▆▅▇▆▆▅█▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:         test_precision0.75 ▁▁▁▁▁▆▇▇▄▇▆▇▆▆▆▆▅█▆█▃▆▆▇▆▆▆▆▆▇▇▆▆▇▇▆▆▆▆▆
wandb:            test_recall0.25 ██▇▅▅▅▂▃▂▁▅▃▄▄▃▃▃▄▃▄▄▄▂▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:             test_recall0.5 ▄▄▃▅▃▂█▁▄▇▇█▇▇█▇▇█▇▆▇▄▇▇▇▆▇▇▇▇▇▇████▇▇▇▇
wandb:            test_recall0.75 ▂▁▂▂▂▁▁▂▂▄▅▆▄▅▅▆▅▃▇▇▆▆▇▄▃█▆█▇█▆▇██▇█▇▇█▇
wandb:                train_auroc ▁▄▅▅▅▇▇▇▇▇██████████████████████████████
wandb:                 train_loss ██▇▆▅▃▃▂▂▂▃▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▂▂▂▆▃▆▇██▅▆▆▅▆▆▅▆▇▇▆▆▆▇▅▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            val_accuracy0.5 ▁▁▆██▆██▆▆▆▅▆▆▇▇▇▇▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:           val_accuracy0.75 █▃██▇▄▃▅▆▇▂▁▂▃▄▃▃▃▃▂▅▂▅▃▃▄▃▃▂▃▂▂▂▄▃▃▂▂▃▃
wandb:                  val_auroc ▄▄▅▅▆▄▄▆█▆▅▃▃▅▅▅▄▂▃▂▂▂▅▇▃▂▃▂▂▂▁▁▂▂▂▂▂▂▂▂
wandb:  val_balanced_accuracy0.25 ▇██▇▆▇█▇▁▃▇▅▄▅▅▅▄▆▅▆▇▄▆▅▅▅▅▄▅▅▅▅▅▅▆▆▆▅▅▅
wandb:   val_balanced_accuracy0.5 ▂▅▆▇▇▅▆▇▂▃▃▁▆▄▇▆▃▅▇▇▄▅▄▃▄█▃▅▄▅▆▄▅▄▅▅▅▆▅▅
wandb:  val_balanced_accuracy0.75 ▄█▇▁▅▄▄▄▅▃▃▂▃▂▃▂▃▃▂▄▄▅▅▄▄▃▅▃▅▄▅▄▅▄▅▅▄▅▅▄
wandb:          val_precision0.25 ▆▇▇▇▆█▇▇▅▅▅▆▄▁▄▄▅▆▇▆▆▄▅▅▆▅▆▅▅▅▅▅▆▅▅▅▅▆▅▆
wandb:           val_precision0.5 ▇▇▄▆▅▇▆▇▆▁█▁▃▆▆▃▆▅▃▃▇▆▆▃▇▃▆▄▅▆▄▅▄▅▅▆▆▆▆▆
wandb:          val_precision0.75 ▂▁▁▃█▃▂▃▃▃▃▂▃▂▃▃▃▂▃▂▃▃▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃
wandb:             val_recall0.25 ▇███▅▄▆▄▆▃▂▅▄▂▄▄▃▁▃▃▂▂▃▂▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:              val_recall0.5 █▂▁▂▃▄▂▃▂▅▂▃▂▃▃▃▃▃▃▃▂▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:             val_recall0.75 ▁▁▁▅▄▅▆▅▅▅▅▅▇▅▅▇▅▆▆▅▅▆▇▆▆▇█▇█▇▇█▆▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.62025
wandb:           test_accuracy0.5 0.62025
wandb:          test_accuracy0.75 0.62025
wandb:                 test_auroc 0.57797
wandb: test_balanced_accuracy0.25 0.63008
wandb:  test_balanced_accuracy0.5 0.59703
wandb: test_balanced_accuracy0.75 0.56398
wandb:         test_precision0.25 0.36111
wandb:          test_precision0.5 0.34375
wandb:         test_precision0.75 0.32143
wandb:            test_recall0.25 0.65
wandb:             test_recall0.5 0.55
wandb:            test_recall0.75 0.45
wandb:                train_auroc 0.99964
wandb:                 train_loss 0.04111
wandb:           val_accuracy0.25 0.51429
wandb:            val_accuracy0.5 0.58095
wandb:           val_accuracy0.75 0.62857
wandb:                  val_auroc 0.43817
wandb:  val_balanced_accuracy0.25 0.44499
wandb:   val_balanced_accuracy0.5 0.48929
wandb:  val_balanced_accuracy0.75 0.50803
wandb:          val_precision0.25 0.19512
wandb:           val_precision0.5 0.23529
wandb:          val_precision0.75 0.25926
wandb:             val_recall0.25 0.30769
wandb:              val_recall0.5 0.30769
wandb:             val_recall0.75 0.26923
wandb: 
wandb: 🚀 View run vgg16_2d_79_9_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/1jberh9r
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_9/wandb/run-20250701_215559-1jberh9r/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_9/wandb/run-20250701_221744-fwavnwvg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_9_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/fwavnwvg
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▃▆▇▆▇▃▇▄▇██▅▇▅▆▅█▇▆▅▆▅█▆▆▇▆▆▆▆▆▆▅▆▆▆▅▆
wandb:           test_accuracy0.5 ▃█▅▇█▇█▇██▆▅▃▅▂▃▂▂▂▂▂▃▆▄▁▃▁▃▃▄▃▃▃▃▃▂▂▄▂▂
wandb:          test_accuracy0.75 ████▇█▇▇█▇▅▇▄▆▇▄▁▆▄▃▇▆▅▅▅▅▃▃▃▄▃▃▃▃▅▂▂▃▃▃
wandb:                 test_auroc ▃▄▆▅▅▅▇██▇▇▆▅▃▅▄▄▅▅▃▁▄▄▃▃▁▅▅▃▂▄▃▂▂▂▁▂▃▁▂
wandb: test_balanced_accuracy0.25 ▅▅▆▆▇▇▆▇▄▇▅▄▄▄▅▃▄▄▅▄▅█▄▄█▅▄▄▆▄▃▁▂▂▄▃▃▁▃▁
wandb:  test_balanced_accuracy0.5 ▅▄▄▃▄▅▄▇▃█▇▃▃▅▂▄▄▃▃▄▃▂▃▁▅▃▂▄▄▄▃▃▃▂▂▂▂▃▃▂
wandb: test_balanced_accuracy0.75 ▃▃▃▃▄▄▃▂▆▅▃▆▆▆▆█▅▄▆▅▃▃▅▂▆▅▅▅▂▂▃▂▁▂▅▃▁▃▂▃
wandb:         test_precision0.25 ▂▂▂▃▂▄▃▆▅▃▅█▆▅▅▅▆▄▃▃▅▃▃▃▂▄▄▃▂▁▃▃▃▃▂▂▃▄▂▁
wandb:          test_precision0.5 ▃▄▃▂▅▁▂▅▇▆█▅█▄▃▆▃▄▃▃▄▄▂▃▄▄▄▃▃▃▄▃▃▄▃▃▃▃▃▃
wandb:         test_precision0.75 ▁▁▁▁▁▅█▅▅▄█▆▇▆▇▆▇▅▅▅▄▅▅▆▅▅▆▄▆▅▅▅▅▅▅▅▅▅▅▅
wandb:            test_recall0.25 ██▇▄▂▄▆▅▁▃▇▁▂▁▂▂▄▃▄▃▅▂▂▄▄▄▅▅▄▄▃▄▄▄▂▂▂▁▁▂
wandb:             test_recall0.5 ▃▂▂▁▂█▇▂█▄▃▅▄▇▃▄▃▅▄▃▄▄▄▄▄▅▃▄▄▃▄▅▄▄▅▃▄▄▅▄
wandb:            test_recall0.75 ▁▁▁▁▂▁▄▂▆▄▇▂█▅▅▅▅▇▆▅▅▄▅▅▅▄▅▅▅▅▅▅▅▅▆▆▆▆▅▆
wandb:                train_auroc ▁▂▃▄▅▆▇▇█████████████████▇▇█████████████
wandb:                 train_loss ▆▆▅▅▄▄▃▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▃▂▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▂▃▂▃▂▃▅▄▇▃█▄▅▆▅▅▅▇▅▆▇▇▆▇▆▆▆▅▆▆▆▆▆▇▇▆▇▇▇
wandb:            val_accuracy0.5 ▁▁▄▂▅▆▂▂▅▄▆█▂▅▇▃▇▅▆▅▇▆▄▅▅▄▆▅▅▅▅▅▅▄▅▄▇▆▆▅
wandb:           val_accuracy0.75 ██▅█▇▆█▆▇▄▆▁▅▅▆▅▅▅▁▄▃▃▃▂▃▄▄▂▃▃▃▃▃▃▃▄▅▃▃▃
wandb:                  val_auroc █▇▁▃▂▂▃▆▅▅▅▅█▆▆▄▅▅▄▃▄▄▄▅▂▄▆▇▅▆▆▆▆▆▆▇▆▇▇▆
wandb:  val_balanced_accuracy0.25 ▅▄▅▄▅▂▆▃▁▃▄▃▇▅▅▄▇▃▄▄▄▆▄▄▅▇▅▆▇▆▆▅▅▇▆▆█▇▆▆
wandb:   val_balanced_accuracy0.5 █▂▄▄▄▅▅▃▁▄▁▅▄▃▅▃▃▁▃▃▂▂▄▃▂▅▂▄▄▄▄▄▄▃▄▄▄▅▄▅
wandb:  val_balanced_accuracy0.75 ▆▆▆▆▆▆▆▆▆█▆▇▆▆▆▅▅▅▅▅▅▅▆▅▆▆▁▆▅▆▇▆▆▆▆▇▇▆▇█
wandb:          val_precision0.25 ▅▅▅▄▄▂▃▄▄▅▅▄▄▇▄▃▄▂▃▁▃▃▁▄▅▅▅▅▅▆▅▅▅▇▇▅▆▆█▅
wandb:           val_precision0.5 ▁▅▂▃█▅▆▇▄▅▂▇▅▇▃▇▅▃▃▄▆▄▅▁▃▂▇▅▄▅▄▅▅▅▅▅▅▆▆▆
wandb:          val_precision0.75 ▁▁▅▁▁▄▅█▆▆▆▇▇▆▆▆▆▅▅▅▆▆▅▄▅▆▅▆▆▅▅▆▆▆▆▆▆▆▆▆
wandb:             val_recall0.25 ██▂▇▇▃▇▃▁▃▄▂▃▃▂▃▃▂▃▃▂▂▂▂▃▁▃▃▃▃▃▃▃▃▃▄▃▃▃▃
wandb:              val_recall0.5 ▂▆▁▁▄▃▅▂▅█▄▅▄▂▂▃▂▄▄▃▄▄▂▄▄▄▄▄▄▄▄▅▅▄▅▆▆▅▄▆
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▂▅▂▃▆█▄▆▄▅▅▅▅▄▅▆▄▄▆▃▅▅▄▅▆▆▇▅▇▆▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.50633
wandb:           test_accuracy0.5 0.5443
wandb:          test_accuracy0.75 0.56962
wandb:                 test_auroc 0.52712
wandb: test_balanced_accuracy0.25 0.47119
wandb:  test_balanced_accuracy0.5 0.48008
wandb: test_balanced_accuracy0.75 0.49703
wandb:         test_precision0.25 0.22857
wandb:          test_precision0.5 0.23333
wandb:         test_precision0.75 0.25
wandb:            test_recall0.25 0.4
wandb:             test_recall0.5 0.35
wandb:            test_recall0.75 0.35
wandb:                train_auroc 0.99964
wandb:                 train_loss 0.04854
wandb:           val_accuracy0.25 0.58095
wandb:            val_accuracy0.5 0.61905
wandb:           val_accuracy0.75 0.6381
wandb:                  val_auroc 0.51047
wandb:  val_balanced_accuracy0.25 0.5409
wandb:   val_balanced_accuracy0.5 0.55331
wandb:  val_balanced_accuracy0.75 0.56597
wandb:          val_precision0.25 0.28571
wandb:           val_precision0.5 0.30556
wandb:          val_precision0.75 0.32353
wandb:             val_recall0.25 0.46154
wandb:              val_recall0.5 0.42308
wandb:             val_recall0.75 0.42308
wandb: 
wandb: 🚀 View run vgg16_2d_79_9_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/fwavnwvg
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_9/wandb/run-20250701_221744-fwavnwvg/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_9/wandb/run-20250701_223906-8lupuzl1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_9_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/8lupuzl1
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▃▂▂▅▄▄▃▅▄▄▆▅▅▅▆▅▅▆▅▅▅▆▅▅▆▅▆▇▇▇▆▆▆▆▆▅▅█
wandb:           test_accuracy0.5 ▁▇▆▃█▆▇▇▅▅▃▆█▇▅▆▄▃▅▅▄▄▄▄▄▄▆▆▅▅▄▅▅▅▆▅▆▅▇▆
wandb:          test_accuracy0.75 ███▇█▆▇▇▇▇▇▆▆▄▁▇▇▆▆▆▃▃▃▅▅▅▂▅▃▅▃▂▅▄▄▄▃▅▆▄
wandb:                 test_auroc ▂▁▃▄▄▆█▄▆▇▅▄▄▄▄▃▄▃▄▄▄▄▃▄▄▅▄▄▆▆▄▅▅▄▄▅▄▄▄▇
wandb: test_balanced_accuracy0.25 ▆▅▅▃▆▅█▄▇▁▄▂▅▁▁▃▂▃▄▄▃▂▄▅▅▄▄▂▄▅▄▄▄▄▅▂▄▆▆▂
wandb:  test_balanced_accuracy0.5 ▂▅▄▄▁▅█▆▅▃▆▆▂▄▃▇▄▅▅▅▂▄▃▂▃▃▂▅▃▄▅▃▄▄▅▃▄▅▅▅
wandb: test_balanced_accuracy0.75 ▄▄▅▅▄▇▅█▆▇▆▅▅▅▄▂▄▆▇▃▆▄▄▃▄▆▅▁▅▅▃▄▃▂▃▆▃▅▆▆
wandb:         test_precision0.25 ▆▆▆▅▇▆▆▅▆▄▂▂▅▂▆▅▄▂▁▃▅▂▃▅▄▅▅▄▇▂▄▃▅▅▆▅▄█▄▃
wandb:          test_precision0.5 ▁▆▁▄█▇▅▇▅█▅▅▅▅▆▅▅▆▆▅▅▆▅▅▅▆▆▅▅▅▅▅▅▅▅▅▅▇▆▆
wandb:         test_precision0.75 ▁▁▁▁▅▁▄██▅▅▅▅▅▇▆▆▄▄▅▅▆▄▄▄▄▄▅▅▅▄▅▅▅▅▅▆▆▄▅
wandb:            test_recall0.25 █▇▇▆▅▅▄▄▄▄▅▂▃▃▃▁▃▃▂▃▄▃▃▃▃▄▃▃▃▄▄▄▄▅▃▂▂▃▂▃
wandb:             test_recall0.5 ██▃▁▄▄▂▆▂▃▄▄▄▃▅▄▆▃▂▃▄▄▄▄▄▅▄▄▃▄▅▄▄▄▅▄▅▄▆▅
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▂▂▂▆▅▁▁▅▅▆▅█▆▅▆▅▆▇▆▅▆▆▇▆▆██▆▆▇▇▅▅
wandb:                train_auroc ▁▁▃▄▅▆▇▇▇▇▇▇███████████▇████████████████
wandb:                 train_loss █▇▇▅▅▅▄▄▄▃▃▄▃▂▁▂▁▇▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▂▄▃▇▆▄▆▆▄▄█▆▆▆▆▆▆▆▆▅▆▆▆▆▅▆▇▆▆▆▆▅▆▆▆▆▆▆▆
wandb:            val_accuracy0.5 ▁▆▅▇█▅▅▅▅▅▄▅▄▅▄▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▄▆
wandb:           val_accuracy0.75 █▇▇▇▇▆▅▅▅▆▅▃▃▃▅▅▅▂▃▄▂▁▂▃▁▃▁▃▂▃▂▂▁▂▃▃▂▃▄▄
wandb:                  val_auroc ███▂▂▃▃▂▂▃▄▂▂▇▃▃▄▂▃▃▂▂▃▂▃▂▃▂▂▂▄▃▃▂▂▃▂▃▁▆
wandb:  val_balanced_accuracy0.25 ▅▅▂▁▅▆▄▅▃▄▃▆▅▅▃▅▆█▄▆▅▅▃▅▅▃▄▄▄▆▃▆▆▃▃▃▆▄▁▅
wandb:   val_balanced_accuracy0.5 █▅▇▆▄▅▅▅▄▄▄▅▄█▂▄▄▂▃▄▅▃▅▄▃▃▆▂▄▂▄▁▅▂▂▆▅▁▁▂
wandb:  val_balanced_accuracy0.75 ▅▅▅▅▅█▆█▆▅▃▃▇▃▂▃▄▄▄▂▄▃▃▂▂▄▂▃▂▆▃▁▄▂▁▂▃▅▄▃
wandb:          val_precision0.25 ▅▆▇▇▅▅▄▆▄▃▇▆▄▆▅▆▇▅▅▆▅▅▃▅▆▆▅▅▅▅▆▄▄▇█▅█▁▅▃
wandb:           val_precision0.5 ▄▄▄▁▃█▂▃▄▃▄▂▃▄▄▃▃▂▃▃▃▃▂▃▃▃▁▃▄▃▂▃▃▃▄▄▃▃▄▂
wandb:          val_precision0.75 ▁▁▁▁▁▅█▆▆▆▅▄▅▅▅▅▆▅▆▆▄▅▅▄▄▅▄▄▅▄▅▄▄▅▄▄▄▅▅▃
wandb:             val_recall0.25 ███▆█▃▅▅▄▃▃▂▃▄▃▁▃▄▃▃▃▃▄▃▃▂▃▄▂▃▃▄▃▃▃▃▃▅▄▃
wandb:              val_recall0.5 ▃▂▄▄▂▂▃▄█▅▄▄▄▄▁▃▄▄▄▅▄▆▄▅▄▄▄▅▄▄▃▄▄▅▄▆▄▄▄▃
wandb:             val_recall0.75 ▁▁▁▁▁▃▄▃▃▆▆▆▆█▃▆█▆▆█▆▇▆▇▇█▇█▇▅▄▇▆██▆▇█▄▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.5443
wandb:           test_accuracy0.5 0.59494
wandb:          test_accuracy0.75 0.63291
wandb:                 test_auroc 0.5322
wandb: test_balanced_accuracy0.25 0.48008
wandb:  test_balanced_accuracy0.5 0.49746
wandb: test_balanced_accuracy0.75 0.52288
wandb:         test_precision0.25 0.23333
wandb:          test_precision0.5 0.25
wandb:         test_precision0.75 0.28571
wandb:            test_recall0.25 0.35
wandb:             test_recall0.5 0.3
wandb:            test_recall0.75 0.3
wandb:                train_auroc 0.99944
wandb:                 train_loss 0.14817
wandb:           val_accuracy0.25 0.55238
wandb:            val_accuracy0.5 0.57143
wandb:           val_accuracy0.75 0.6
wandb:                  val_auroc 0.50511
wandb:  val_balanced_accuracy0.25 0.4574
wandb:   val_balanced_accuracy0.5 0.45716
wandb:  val_balanced_accuracy0.75 0.46324
wandb:          val_precision0.25 0.2
wandb:           val_precision0.5 0.19355
wandb:          val_precision0.75 0.19231
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.19231
wandb: 
wandb: 🚀 View run vgg16_2d_79_9_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/8lupuzl1
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_9/wandb/run-20250701_223906-8lupuzl1/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_9/execution_datetimes.json

**************************************************  Experiment 79 | Version 10 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 5}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 6}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 7}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_10/wandb/run-20250701_230054-s49kcvb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_10_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/s49kcvb7
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▃▅▅▄▆▇▆▇▆▆▇▅▇█▆▅▇▅▆▇▆▆▇▅█▆▅▇▇█▆█
wandb:           test_accuracy0.5 ▄▅▅▆██▆▄▇▅▃▅▅▂▃▅▅▄▄▅▆▂▇▄▅▅▄▄▃▄▅▁▆▆▄▆▆▆▆▆
wandb:          test_accuracy0.75 ███▅▅▇▄▆▇▄▇▅▄▇▅▂▂▂▇▄▅▅▃▅▂▄▁▄▅▂▂▄▅▄▅▅▅▄▄▄
wandb:                 test_auroc ▁▁▂▂▃▇██▇█▆▄▄▄▄▄▅▄▅▄▅▅▄▅▅▄▄▆▅▅▆▅▅▆▅▅▅▄▅▄
wandb: test_balanced_accuracy0.25 ▂▂▂▂▂▁▁▂▅██▃█▄▅▅▅▃▄▅▆▄▆▄▆▆▅▄▂▅▄▄▆▆▇▇▂▄▅▅
wandb:  test_balanced_accuracy0.5 ▁▂▄▄▃▄█▆▇▅▆▆▆▅▆▆▅▆▅▇▅▅▅▆▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆
wandb: test_balanced_accuracy0.75 ▄▄▆▆▅▅▁▁▁▃▆█▇▇▄▆▆▇▄▅▄▃▇▇▆▆▅▇▇▇▇█▆▇█▆▅▇▅▇
wandb:         test_precision0.25 ▁▁▁▁▄▁▅▃▆▅▄▂▃▄▂▂▄▃▂▄▄▄▂▃▄▃▄▃▃▆▃▄▆▆▃▄▄█▆▆
wandb:          test_precision0.5 ▁▂▄▄▃███▇█▇▆█▆▆▆▆▇▇█▆▇█▇▅▆▇▇▇▇▇██▅▇▇▇▆▆▅
wandb:         test_precision0.75 ▁██▁█▁▁▂▃▃▃▃▃▃▄▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test_recall0.25 ████▇▇▇▆▅▅▄▂▄▄▃▄▃▂▁▄▃▄▅▃▄▄▂▃▄▃▄▃▄▃▄▂▄▄▃▃
wandb:             test_recall0.5 ▁▅███▁▂▂▄▇▆▅▅▄▅▅▄▆▆▄▅▅▅▂▅▄▅▄▄▇▄▄▅▄▄▅▄▄▆▄
wandb:            test_recall0.75 ▁▁▄▂▄▄▄▇▃▅▅▆▅▇▇▅▅▅▅▇▇▄▅▅▅▆▄▆▆▆▆▆▆▆▇▆▇██▆
wandb:                train_auroc ▁▂▂▅▆▇▇▇▇███████████████████████████████
wandb:                 train_loss █████▇▆▆▅▅▅▅▅▄▃▃▃▃▂▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▂▂▂▄▂▃▃▅▄▅▇▇▇█▇█▆▆▇█▆▅▆▆▅▆▇▅▆▅▆▄▆▅▆▆▇
wandb:            val_accuracy0.5 ▆▆▇▇▄▃▆█▁▂▅▄▁▄▆█▇▄▅▃▅▆▆▆▆▂▇▂▆▆▇▅▂▅▆▆▆▅▅▂
wandb:           val_accuracy0.75 ███████▆▇▆▇▇▆▆▅▆▇▇▆▆▆▆▆▇▆▅▆▆▆▄▃▄▆▁▅▅▅▅▅▆
wandb:                  val_auroc ▁▄▂▂▂▂▂▁▁▃▄▅▅▄▆▅▄▆█▄▅▃▄▄▄▄▄▄▄▃▃▃▅▃▄▄▄▄▄▃
wandb:  val_balanced_accuracy0.25 ▇▇▇▇▇▅▂▆▄▅▅▄▃▃▄█▆▇▇█▃▅▇▃▅▂▅▅▁▄▃▅▂▄▄▅▃▄▅▄
wandb:   val_balanced_accuracy0.5 ▅▄▄▆▅▁▅▄▄▆▂▄▅▄▄▂▄█▅▆█▆▃█▄█▆▆▅▄█▅▆▅▅▆▄▆▆▆
wandb:  val_balanced_accuracy0.75 ▅▅▅▅▇▇▅▅▃▅▆▅▄▃▅▅▆▅▅▃▄█▅▅▅▇▅▅▅▆▅▄▁▅▅▄▅▅▂▅
wandb:          val_precision0.25 ▆▆▆▆▆▆▃▃▅▅▅▃▃▄█▃▅▄▂▃▄▅▅▄▂▄▆▁▆▃▃▃▃▄▃▂▂▃▃▃
wandb:           val_precision0.5 ▂▃▅▃▄▇▅▁▃▂▆▇▂▄▂▄▄▂▆▅▅▇▆▄▃▄▁▆▄▅▇█▅▅▅▄▄▄▃▁
wandb:          val_precision0.75 ▁▁▇▇▆█▆▆▆▅▅▄▅▄▄▅▆▅▆▅▅▅▅▆▅▅▄▅▅▅▅▅▅▄▅▅▄▄▄▅
wandb:             val_recall0.25 █████▇▇▄▅▂▂▄▂▄▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▂▃▂▁▂▂▂▂▂▂
wandb:              val_recall0.5 ▁▆▄▂▅▃▃▅▄▅▃▄▄▅▄▄▆▅▅▅▅▅▄▅▅▅▆▅█▆▅▅▅▅▃▅▄▅▅▅
wandb:             val_recall0.75 ▁▁▁▁▄▅▅▅▄▅▅▆▆▅▅▅▄▅▅▅▅▅▅▄▆▄██▆█▅▇██▆▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.58228
wandb:           test_accuracy0.5 0.60759
wandb:          test_accuracy0.75 0.59494
wandb:                 test_auroc 0.54534
wandb: test_balanced_accuracy0.25 0.55508
wandb:  test_balanced_accuracy0.5 0.53898
wandb: test_balanced_accuracy0.75 0.49746
wandb:         test_precision0.25 0.30303
wandb:          test_precision0.5 0.2963
wandb:         test_precision0.75 0.25
wandb:            test_recall0.25 0.5
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.3
wandb:                train_auroc 0.99984
wandb:                 train_loss 0.0804
wandb:           val_accuracy0.25 0.55238
wandb:            val_accuracy0.5 0.6
wandb:           val_accuracy0.75 0.62857
wandb:                  val_auroc 0.43671
wandb:  val_balanced_accuracy0.25 0.4703
wandb:   val_balanced_accuracy0.5 0.50195
wandb:  val_balanced_accuracy0.75 0.52093
wandb:          val_precision0.25 0.21622
wandb:           val_precision0.5 0.25
wandb:          val_precision0.75 0.27586
wandb:             val_recall0.25 0.30769
wandb:              val_recall0.5 0.30769
wandb:             val_recall0.75 0.30769
wandb: 
wandb: 🚀 View run vgg16_2d_79_10_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/s49kcvb7
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_10/wandb/run-20250701_230054-s49kcvb7/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_10/wandb/run-20250701_232924-jwfg0mu0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_10_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/jwfg0mu0
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▂▄▃▄▅▆▆▄▇▆▆▇▅▆▇▇▇▅▇▇▆▇▇▇▇▇▅▅▇▇▇▇▇▆▆▇█▇▇
wandb:           test_accuracy0.5 ▆▄▆▇▇▇▇▇▇▆█▇▅▃▆▄▄▅▄▃▁▅▅▅▄▃▅▄▃▄▄▂▅▄▄▃▃▄▄▄
wandb:          test_accuracy0.75 █▇▆▆▆▅▆▅▃▃▃▃▃▃▁▂▃▃▃▂▂▂▃▄▃▃▂▃▂▃▂▃▄▆▃▃▃▃▃▃
wandb:                 test_auroc ▄▄▄▅▅█▆▆▆▃▄▃▃▁▃▂▂▃▂▁▃▃▂▂▂▁▂▅▃▃▂▂▄▄▃▄▄▂▄▄
wandb: test_balanced_accuracy0.25 ▁▁▁▁▂▃▃▆▄▅█▇▆▄▆▇▃▄▄▅▅▄▇▃▂▄▄▄▆▇▆▄█▃▆▃▄█▇█
wandb:  test_balanced_accuracy0.5 ▂▃▄▆▅▄▄▄▅▆▅▅▄█▁█▃▆▂▂▇▃▃▆▇▃▇▅▆▅▃▅▄▇▅▄▅▂▅▃
wandb: test_balanced_accuracy0.75 ▄▂▄▄▂▃▂▂▂▆▂▃▃▁▂▂▃▂▂▄▂▆▅▅▃▂▃▃▄▅▆▄▆▃█▅▅▅▅▅
wandb:         test_precision0.25 ▁▁▁▂▂▂▃█▂▄▅▄▂▃▅▄▃▃▃▃▃▁▄▄▃▃▄▃▂▃▃▄▃▃▄▅▄▄▄▄
wandb:          test_precision0.5 ▁▄▇█▆▆▆▆▆▅▇▇▅█▅▇▅▆▇▅▆▅▅▇▇▅▇█▆▇▆▇▆▆▇▇▇▆▆▆
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▄▁▁▁▆█▇▅▅▅▆▆▆▅▅▅▅▆▅▆▅▆▅▆▅▆▆▅▇▆▆▆▆
wandb:            test_recall0.25 █▇▄▇▆▆▃▆▄▅▅▅▅▅▅▅▅▃▅▄▅▆▅▅▅▅▅▃▅▅▂▅▅▅▅▄▅▅▁▅
wandb:             test_recall0.5 ▁▄▄▃▃▆▇▄▆▄▆▆▃▃█▇▆▄▆▆▄▄▄▇▆▄▄▄▄▄▅▄▆▇▅▅▆▅▅▃
wandb:            test_recall0.75 ▁▁▁▁▁▄▆▇▅▅▅▅▅▅▆▅▅▇▅▅▅▇▅▅▄▅▅▅█▆▇▅▅▇▇▆▅▅▅▅
wandb:                train_auroc ▁▂▃▄▅▆▆▇▇▇▇█████████████████████████████
wandb:                 train_loss █▇▇▇▆▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▃▃▃▄▄▃▆▆▄▆▆▆▄▅▆▆▅▅▆▆▆▇▅▆▅▆▆▆▆▆▆▇▆▆▆▅▄█▆
wandb:            val_accuracy0.5 ▄▂▁▄▅██▅▃▄▇▇▅▃▂▆▅▆▄▅▅▇▃▃▇█▅▅▃▅▄▅▄▅▅▄▆▅▅▅
wandb:           val_accuracy0.75 ███▇▇▇▇██▇▇▆▇▆▇▆▅▂▅▆▄▄▅▄▂▄▆▄▄▁▂▃▃▄▁▅▄▄▄▄
wandb:                  val_auroc ▁▅▁▄▄▃▇▄▅█▇▇▇▇▇██▇▇▇█▇▇▇▅▆▇▇▇▇▇▇█▇▆▇▇███
wandb:  val_balanced_accuracy0.25 ▄▃▃▁▁▂▃▂▄▂▆▇▅▇▅▅█▆▆▇▇▆▆▄▅▅▆▅▆▆▇▅▇▅▆▆▅▇▇▅
wandb:   val_balanced_accuracy0.5 ▂▇▁▃▄▄▄▆▅▅▄▆▅▇▇▇▇▆▆▇▆▆▇██▇▆▇▅▇▇▆▆▆▆▇▆▇▇█
wandb:  val_balanced_accuracy0.75 ▂▁▂▁▄▄▆▇▄▅▅▃█▇▆▇▅▅▅▄█▆▄▅▅▅▅▇▅▄▅▆▄▅▄▆▆█▇▇
wandb:          val_precision0.25 ▂▃▁▄▁▄▃▄▄▇▄▆▇▆▇▄▄▆▇█▁▃▇▇▆▇▆▅▅▆▆▆▇▅▅▆▆█▆▇
wandb:           val_precision0.5 ▁▇▂▂▃▅▅▅▆▆▅▆▆█▇▇▆▆▇▅▄▆▆▅▆▆█▆▇▆▆▆▆▆▆▆▆▇▇▆
wandb:          val_precision0.75 ▄▄▄▄▁█▆█▆▇▆▆▆▇▇▆▇▆▇▆▇▇▆▆▇▆▆▆▇▆▆▆▆▇▇▇▆▇▆▇
wandb:             val_recall0.25 █▆▆▆▁▁▃▃▁▂▃▄▃▂▃▄▂▄▃▃▁▂▄▃▂▃▄▄▂▄▄▄▄▃▄▃▄▄▃▃
wandb:              val_recall0.5 ▁▄▃▃▄▅▂█▆▃▃▇▆▅▅▅▆▇▅▆▅█▃▅▆▆▇▅▆▅▇▄▅▅▆▇▅▆▆▆
wandb:             val_recall0.75 ▁▁▁▁▁▂▂▃▃▃▃▄▃▅▅▃▅▅▆▆▆▅▅██▆▄▆▆▆▆▇▇▆▄▇▅▆▆▆
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.55696
wandb:           test_accuracy0.5 0.55696
wandb:          test_accuracy0.75 0.58228
wandb:                 test_auroc 0.54534
wandb: test_balanced_accuracy0.25 0.53814
wandb:  test_balanced_accuracy0.5 0.50508
wandb: test_balanced_accuracy0.75 0.48898
wandb:         test_precision0.25 0.28571
wandb:          test_precision0.5 0.25806
wandb:         test_precision0.75 0.24
wandb:            test_recall0.25 0.5
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.3
wandb:                train_auroc 0.99948
wandb:                 train_loss 0.05675
wandb:           val_accuracy0.25 0.6
wandb:            val_accuracy0.5 0.60952
wandb:           val_accuracy0.75 0.62857
wandb:                  val_auroc 0.57181
wandb:  val_balanced_accuracy0.25 0.57936
wandb:   val_balanced_accuracy0.5 0.55988
wandb:  val_balanced_accuracy0.75 0.57254
wandb:          val_precision0.25 0.31818
wandb:           val_precision0.5 0.30769
wandb:          val_precision0.75 0.32432
wandb:             val_recall0.25 0.53846
wandb:              val_recall0.5 0.46154
wandb:             val_recall0.75 0.46154
wandb: 
wandb: 🚀 View run vgg16_2d_79_10_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/jwfg0mu0
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_10/wandb/run-20250701_232924-jwfg0mu0/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_10/wandb/run-20250702_000035-urbubm68
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_10_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/urbubm68
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▂▂▂▄▅█▄▄▄▇▅▆▅▅▆▅▄▄▅▅▅▄▄▇▄▅▅▄▄▅▄▅▅▅
wandb:           test_accuracy0.5 ▆▁▇▆▅▄▆█▇▇██▇▇▃▇▇▆▄▃▄▂▄▄▄▄▄▃▄▅▄▄▃▄▅▄▄▄▄▄
wandb:          test_accuracy0.75 █████████▇▇▆▇██▆▁▄▄▂▄▆▃▂▃▄▂▆▃▃▅▃▂▃▃▃▃▄▂▂
wandb:                 test_auroc ▁▃▄▅▆▅█▇█▆▆▆▆▆▆▇▇▅▆▆▆▅▅▅▆▆▅▅▆▅▅▅▆▆▆▆▆▆▆▅
wandb: test_balanced_accuracy0.25 ▅▃▂▄▄▇▆▅▄▃▆▃▄▆▆▅▄▅▅▄▄▄█▄▆▆▃▃▁▂▅▃▄▂▄▃▃▃▄▄
wandb:  test_balanced_accuracy0.5 ▆▁▆▆▇▇▆▅▇█▆█▇▇▁█▆▃▆▂▁▇▂▂▅▆▅▂▂▂▂▁▅▃▂▂▅▄▄▂
wandb: test_balanced_accuracy0.75 ▃▃▃▃▃▃▃▆▄▅▇█▇▆▇▅▅▆▁▁▄▃▃▃▃▃▅▃▃▃▁▁▁▃▂▃▂▂▂▂
wandb:         test_precision0.25 ▄▄▄▄▄▅▄▃▄▄█▅▄▄▄▅▅▃▅▂▂▁▃▅▄▅▂▃▃▅▄▃▂▅▃▅▅▄▄▃
wandb:          test_precision0.5 ▃▄▁▅▆██▅▇▅█▇▆▆▄▄▆▆▃▃▃▃▄▄▃▃▃▄▃▄▃▃▄▃▃▃▃▃▃▃
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▇▁▆█▆▅▆▅▄▅▆▆▄▄▄▅▄▄▄▄▄▄▅▅▄▅▄▅▄▄▄▅
wandb:            test_recall0.25 ████▆▆▄▄▅▄▃▁▅▃▃▃▄▅▃▄▂▃▂▂▂▃▂▅▂▃▁▂▂▂▄▄▂▄▄▃
wandb:             test_recall0.5 ▄▆▃▃▂▅▅▂▅▃▄▄▆▆▄▄▄▇▆▃▄▄▄▅█▄▅▆▄▆▅▄▄▄▄▁▂█▅▄
wandb:            test_recall0.75 ▁▁▁▁▁▂▃▃▅▆▆▆▆▅▅▆▆▆▆▆▅▆▆▆▆▆▅▆▄▄▅▆▇▆▃█▇▇▆▇
wandb:                train_auroc ▁▄▄▅▅▆▇▇████████████████████████████████
wandb:                 train_loss █▇▇▇▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▂▁▁
wandb:           val_accuracy0.25 ▁▁▂▁▂▁▁▂▆▇▅▆▆▆▅▇▆█▇▆▆▇▆▅▇▇▇▇▇█▇██▇▇▇▇▇▇█
wandb:            val_accuracy0.5 ▁▂▆▆▆▅█▇▅▅▅▅▅▅▄▄▅▄▅▄▄▄▃▅▃▄▄▄▅▅▃▄▅▅▄▄▃▄▄▄
wandb:           val_accuracy0.75 ██▇▇▇▇▇█▇▇▇▇▅▅▆▄▄▂▃▂▂▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▅▅▁▂
wandb:                  val_auroc ██▇▆▄▁▁▁▂▃▃▄▅▄▄▅▄▄▄▃▂▃▄▄▃▄▄▃▃▄▃▃▃▃▃▄▃▄▃▄
wandb:  val_balanced_accuracy0.25 ▅▅▅▆▆▁▂▂▄▂▄▂▇▄▆▅█▃▅█▆█▇▅▇▄▄▇▂▅▆▆▄▅▅▇▆▅▅▇
wandb:   val_balanced_accuracy0.5 ▅▄▃▂▂▁▆▆▂▆▇▄▆▆▅▄▃▅▄▃█▁▅▂▁▃▁▆▂▂▃▄▅▂▃▁▄▅▆▅
wandb:  val_balanced_accuracy0.75 ▄▄▄▄▄▃▃▃▂▃█▃▆█▄▅▃▃▃▂▃▃▂▂▄▂▄▃▃▃▂▄▄▃▃▆▄▁▄▇
wandb:          val_precision0.25 ▄▅▃▂▅▁▁▂▂▅▄█▄▄▅▃▆▆▃▁▇▄▆▅▃▅▇▅▅▄▂▄▄▅▅▄▅▆▅▇
wandb:           val_precision0.5 ▁▇▆▇▇▅▆█▆█▆█▆▇▆▆▆▆▇▆▆▅▄▆▅▆▅▆▅▅▅▅▆▅▆▆▆▆▆▆
wandb:          val_precision0.75 ▁▁▁▁▁▆▅██▇▅▄▄▄▄▅▄▄▄▄▄▅▅▄▄▅▅▄▅▅▅▄▅▅▅▆▄▆▄▅
wandb:             val_recall0.25 █████▂▃▂▂▄▅▃▃▂▃▁▃▂▃▁▄▃▃▄▂▃▁▁▄▂▃▂▂▂▂▁▄▃▃▃
wandb:              val_recall0.5 ▁▆█▆▃▃▂▂▂▄▃▄▃▄▄▄▃▆▅▃▄▄▃▃▄▄▄▅▄▄▃▄▄▄▄▃▂▅▅▅
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▄▂▂▂▃▄▄▃▅▅▅▅▅▄▄▆▄▅▅▅▅▅▅▆▇█▄███▅
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.51899
wandb:           test_accuracy0.5 0.53165
wandb:          test_accuracy0.75 0.58228
wandb:                 test_auroc 0.53983
wandb: test_balanced_accuracy0.25 0.49619
wandb:  test_balanced_accuracy0.5 0.48814
wandb: test_balanced_accuracy0.75 0.50551
wandb:         test_precision0.25 0.25
wandb:          test_precision0.5 0.24242
wandb:         test_precision0.75 0.25926
wandb:            test_recall0.25 0.45
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.35
wandb:                train_auroc 1
wandb:                 train_loss 0.01286
wandb:           val_accuracy0.25 0.55238
wandb:            val_accuracy0.5 0.55238
wandb:           val_accuracy0.75 0.53333
wandb:                  val_auroc 0.47931
wandb:  val_balanced_accuracy0.25 0.52191
wandb:   val_balanced_accuracy0.5 0.50901
wandb:  val_balanced_accuracy0.75 0.44474
wandb:          val_precision0.25 0.26667
wandb:           val_precision0.5 0.25581
wandb:          val_precision0.75 0.18919
wandb:             val_recall0.25 0.46154
wandb:              val_recall0.5 0.42308
wandb:             val_recall0.75 0.26923
wandb: 
wandb: 🚀 View run vgg16_2d_79_10_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/urbubm68
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_10/wandb/run-20250702_000035-urbubm68/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_10/execution_datetimes.json

**************************************************  Experiment 79 | Version 11 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 19, 1.0: 9}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 16, 1.0: 12}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 21, 1.0: 11}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 11, 1.0: 17}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_11/wandb/run-20250702_002150-tpwqg5gw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_11_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/tpwqg5gw
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▂▄▂▃▇▆▆▅▆▆▇▄▆▇█▇▅▆▇▆▆▆▆█▆▇▆█▆█▇▆▇▇▆
wandb:           test_accuracy0.5 ▁▁▆▆▇▇███▇█▆▇▇▇▇█▅▅█▆▇▆▅▆▆▆▇▆▆▇▆▅▆▇▆▆▇▇▆
wandb:          test_accuracy0.75 ▇▇▇▇█▇▇▆▇▄▄▅▄▅▅▂▄▅▅▄▅▅▃▃▂▄▃▂▃▃▁▁▂▄▃▂▂▁▂▂
wandb:                 test_auroc ▁▁▂▂▄▄▆▇██▇▆▇▆▆▆▅▆▆▆▆▅▅▆▅▅▄▅▅▄▅▅▄▅▅▅▅▅▅▅
wandb: test_balanced_accuracy0.25 ▁▁▂▁▁▁▁▇▆█▇▅▆▅▆▅▅▆▄▅▄▄▄▄▅▃▃▃▄▄▄▄▄▄▂▄▄▄▄▃
wandb:  test_balanced_accuracy0.5 ▁▁▂▄▂▄▇▅█▃▄▃▅▅▃▆▅▃▄▄▄▆▃▄▃▃▄▄▄▄▄▄▅▆▃▅▅▃▄▃
wandb: test_balanced_accuracy0.75 ▃▃▃▃▃▅▅▅▅▅▃▃▃▂▁▂▆▆▆▅▂▂▃▆▅█▇▄▆▄▆▅▅▆▃▅▄▄▅▄
wandb:         test_precision0.25 ▁▁▁▁▁▁█▃▆▆▃▃▃▃▆▃▄▅▃▄▃▂▃▃▂▂▂▂▃▃▃▄▃▃▃▃▃▂▃▂
wandb:          test_precision0.5 ▂▂▁▂▂█▂██▆▇▆▆▆▆▄▄▄▅▅▄▆▅▆▃▄▃▃▂▄▆▃▃▄▃▄▃▃▂▃
wandb:         test_precision0.75 ▁▁▁▁▁█████▁▁▁▁▁▄▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:            test_recall0.25 ███████▇▇▆▃▅▅▄▂▂▂▂▃▃▂▃▂▂▂▂▂▁▂▂▂▁▂▁▅▃▂▂▂▁
wandb:             test_recall0.5 █▇▃▂▂▁▂▂▃▄▃▂▂▅▃▂▃▄▄▄▄▄▄▄▄▄▄▄▃▄▃▄▃▃▃▄▄▅▅▄
wandb:            test_recall0.75 ▁▂▂▁▂▁▂▁▂▂▅▁▂▄▅▃▃▃▃▃▅▆▄▅▆▆▆▅▅▅▅▅▆▆█▆▅▅▅▅
wandb:                train_auroc ▂▁▁▂▂▂▃▅▅▆▇▇▇███████████████████████████
wandb:                 train_loss ██▇▇▇▅▄▄▄▄▃▃▃▃▃▂▃▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▂▂▁▂▃▄▄▇▃▆▆▄▇▇▅▆▇▇▆▇▇▅▆▅▆█▆▇▇█▇█▃▆▅▆
wandb:            val_accuracy0.5 ▁▄▆▆▇▇▇▇▆▅▇▆▆▆▇▇█▇▆▇▆▆▅▇▇▇▇█▆▇▇▇▆▆▆▇▆▆▆▆
wandb:           val_accuracy0.75 █████████▄▇█▃▇▇▂▅▆▆▄▄▅▃▆▄▄▄▂▅▂▄▄▄▃▅▁▄▄▄▄
wandb:                  val_auroc ▁▄▄▂▂▁▆▇▅▇█▇▇▇▇▆▇█▆▆▆▆▆▆▆▅▆▅▆▆▆▆▄▂▅▅▅▅▅▅
wandb:  val_balanced_accuracy0.25 ▆▆▆▆▆▃▂▂▄▆▆▄▆▇▆▆▅▄█▄▆▆▃▄▇▆█▆▃▄▆▇▂▇▁▅▆▆▆▆
wandb:   val_balanced_accuracy0.5 ▂▁▄▅▅▆▅▅▆▅▅▆▅▅▄▅▆▅▄▆▅▄▅▆▆▅▆▄▄▆▅▆▆▆▅▆█▆▅▅
wandb:  val_balanced_accuracy0.75 ▄▄▄▃█▅▇▇▆▅▁▅▇▇▃▁▆▃▅▅▄▃▄▆▃▃▁▃▃▄▂▄▃▄▄▆▆▁▂▂
wandb:          val_precision0.25 ▅▅▅▂▁▆▂▆▅▅▅▄▅▅▄▆▆▅▆▄▂▃▃▄▃▄▄▇▄▇▅▃█▆▃▄▂▃▄▅
wandb:           val_precision0.5 ▆▁▁▄▄▂▅▄▆▅▄▄▃▄▆▅▅▄▇▄█▄▅▇▅▃▂▃▄▅▅▆▂▇▅▇▂▅▄▄
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▆█▇▆▅▅▄▆▄▃▄▅▅▅▄▄▄▄▅▄▄▄▄▄▄▄▅▄▅▃▅▄
wandb:             val_recall0.25 █████▄▄▅▅▄▂▄▄▂▂▂▂▄▃▃▃▃▂▃▂▁▂▂▂▁▂▁▂▁▂▂▂▂▂▂
wandb:              val_recall0.5 █▂▂▁▁▂▂▂▂▂▂▁▂▃▁▃▁▂▂▁▁▄▂▂▃▂▂▂▂▂▃▃▃▂▃▂▄▁▂▂
wandb:             val_recall0.75 ▁▁▁▁▁▄▄▄▆▆▄▅▅▇▄▄▄▄▄▄▅▄▄▄▆▄▆▄▄▄▅█▄▄█▆▅▆▆▆
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.59494
wandb:           test_accuracy0.5 0.59494
wandb:          test_accuracy0.75 0.64557
wandb:                 test_auroc 0.5678
wandb: test_balanced_accuracy0.25 0.56356
wandb:  test_balanced_accuracy0.5 0.49746
wandb: test_balanced_accuracy0.75 0.53136
wandb:         test_precision0.25 0.3125
wandb:          test_precision0.5 0.25
wandb:         test_precision0.75 0.3
wandb:            test_recall0.25 0.5
wandb:             test_recall0.5 0.3
wandb:            test_recall0.75 0.3
wandb:                train_auroc 0.99968
wandb:                 train_loss 0.05931
wandb:           val_accuracy0.25 0.59048
wandb:            val_accuracy0.5 0.64762
wandb:           val_accuracy0.75 0.64762
wandb:                  val_auroc 0.46154
wandb:  val_balanced_accuracy0.25 0.48272
wandb:   val_balanced_accuracy0.5 0.49489
wandb:  val_balanced_accuracy0.75 0.48199
wandb:          val_precision0.25 0.22581
wandb:           val_precision0.5 0.2381
wandb:          val_precision0.75 0.21053
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.19231
wandb:             val_recall0.75 0.15385
wandb: 
wandb: 🚀 View run vgg16_2d_79_11_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/tpwqg5gw
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_11/wandb/run-20250702_002150-tpwqg5gw/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_11/wandb/run-20250702_005113-bq7c4xor
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_11_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/bq7c4xor
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▃▃▂▄▄▅▅▅▅▄▅█▅▅▅█▇▇▆▆▅▆▇▆▇▆▇▆▆▆▆▆▆▆▆▇▇▅
wandb:           test_accuracy0.5 █▇▁▆▅▅▅▆▆▅▄▅▅▅▅▄▄▂▂▂▂▁▂▂▂▂▁▁▂▂▂▁▁▁▁▁▁▂▂▁
wandb:          test_accuracy0.75 █████▇▇▇▇▆▆█▆▄▇▃▄▃▃▃▃▂▃▃▃▂▂▂▂▄▂▂▁▂▂▂▃▄▁▁
wandb:                 test_auroc ▁▁▂▂▃▄▆▇██▆▆▆▆▅▄▃▄▄▃▃▂▂▂▃▃▂▃▂▂▂▂▂▁▁▂▂▁▂▂
wandb: test_balanced_accuracy0.25 ▂▂▁▂▃▃▆▇▇▆▆█▅▇▆▆▄▆▆▅▆▆▅▅▅▆▅▆▃▂▅▄▅▅▅▅▅▆▅▃
wandb:  test_balanced_accuracy0.5 ▂▃▁▃▃▄▄▄▃▂█▅▄▆▆▅▅▂▇▂▃▆▅▂▄▃▃▅▄▄▄▂▃▃▁▃▂▂▄▂
wandb: test_balanced_accuracy0.75 ▅▅▄▄▄▅▄▅▄▅▄▃▆█▃▃▄▆▇▄▃▆▃▄▃▄▂▃▃▃▁▁▄▅▇▅▇▂▅▃
wandb:         test_precision0.25 ▁▁▁▁▂▁▄▅▃█▄▅▅▄▇▄▅▆▄▄▆▅▆▅▆▄▃▅▅▅▄▅▄▄▄▅▃▃▅▄
wandb:          test_precision0.5 ▁▆▆▆▅▆▆▇▇▆█▇▅███▇▇▇▇▆▇▆▆▅▆▅▅▆▆▅▅▅▆▅▆▅▆▆▅
wandb:         test_precision0.75 ▁▁▁▁▁▅▁▁▇▁▁█▅▇▇▅▅▅▅▅▅▅▆▅▅▆▆▅▅▅▅▅▅▅▅▅▆▅▅▆
wandb:            test_recall0.25 █▇▇▆▆▆▆▆▆▅▆▅▅▆▅▁▅▅▃▅▄▅▄▄▃▂▂▂▁▃▄▄▃▂▂▄▄▄▄▂
wandb:             test_recall0.5 ▂▂▂▁▄▂▂▂▂▂▁▄▃▅▄▄▄█▂▃▄▄▄▇▆▃▆▂▆▅▆▂▇▂▂▃▄▅▃▅
wandb:            test_recall0.75 ▁▁▁▁▁▃▂▃▁▄▇▄▄▅▅▆▆▆▅▅▆▆▇▆▆▅▆▆▆▆▆▇▆▆▆▅▆▇██
wandb:                train_auroc ▁▂▂▂▃▄▅▆▆▆▇▇▇▇▇▇████████████████████████
wandb:                 train_loss █▇▆▆▆▅▅▃▃▃▃▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▃▃▃▄▃▄▃▄▆▆██▇▇▇▇█▆▇▇▇▇▆▆▇█▇▇▇▇▇▇▇▇▇
wandb:            val_accuracy0.5 ▇▁▃▂▅▃▄▅█▅█▃▇▇▇▇▅▅▆▅▅▅▅▆▅▇▅▅▂▆▂▆▄▅▅▅▄▄▁▄
wandb:           val_accuracy0.75 ███▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▄▅▅▄▄▅▅▅▃▁▃
wandb:                  val_auroc ▁▅▆▆▅▄▄▃▃▅▄▅▅▅▅▆▇▆▆▆█▇▇▇██▇▇▇▇██▇█▇▇▇▇█▇
wandb:  val_balanced_accuracy0.25 ▃▃▁▂▄▂▃▂▃▄▄▆▆▅▆▆▇▆▇█▆▆▇▆▇▆▆▇▆▅▆▇▆▆▇▆▄▇▆▅
wandb:   val_balanced_accuracy0.5 ▃█▄▁▁▃▄▄▅▄▄▄▅▆▆▆▅▆▅▄▆▅▅▅▅▆▇▇▇▆▇▅▇▇▆▇▆▅▇▄
wandb:  val_balanced_accuracy0.75 ▂▂▂▂▂▂▁▁▅▃▅▆▅▆▆▆▆▅▄█▆██▆▇▇▄▇▇▇▇█████▅▄▇▅
wandb:          val_precision0.25 ▃▃▃▂▃▁▃▃▃▄▄▆▇▅▆██▇▇▆▆▇▆▆▇▇▄▆▆▆▆▇▅▆▅▆▇▄█▇
wandb:           val_precision0.5 ▁▇▇▆▆▆▇▆█▇▆▇▇▇▆▇█▇▇▇██▇▇███▇▇▇█▇▇▇▇▇▇▇██
wandb:          val_precision0.75 ▁▁▆▆▁▁▁▇▇▆█▇█▇▇▆▅▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▅▆▆▆
wandb:             val_recall0.25 ██▆▆▄▃▅▁▅▁▄▃▅▂▄▄▃▃▄▃▅▃▅▃▅▃▄▁▃▃▃▃▃▄▃▃▃▃▅▄
wandb:              val_recall0.5 ▇█▇▆▂▁▃▃▃▃▃▄▄▄▃▃▄▄▅▅▅▅▅▆▅▆▅▅▆▅▅▅▄▆▅▅▆▄▅▄
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▃▅▅▄▅▅▆▇▅▅▆▆█▅▇▇▇▆▇█▇▇▆
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.46835
wandb:           test_accuracy0.5 0.48101
wandb:          test_accuracy0.75 0.56962
wandb:                 test_auroc 0.51483
wandb: test_balanced_accuracy0.25 0.52839
wandb:  test_balanced_accuracy0.5 0.47076
wandb: test_balanced_accuracy0.75 0.53008
wandb:         test_precision0.25 0.27083
wandb:          test_precision0.5 0.23077
wandb:         test_precision0.75 0.28125
wandb:            test_recall0.25 0.65
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0.45
wandb:                train_auroc 0.99976
wandb:                 train_loss 0.04982
wandb:           val_accuracy0.25 0.50476
wandb:            val_accuracy0.5 0.55238
wandb:           val_accuracy0.75 0.60952
wandb:                  val_auroc 0.58471
wandb:  val_balanced_accuracy0.25 0.52897
wandb:   val_balanced_accuracy0.5 0.54771
wandb:  val_balanced_accuracy0.75 0.58569
wandb:          val_precision0.25 0.26786
wandb:           val_precision0.5 0.28571
wandb:          val_precision0.75 0.32558
wandb:             val_recall0.25 0.57692
wandb:              val_recall0.5 0.53846
wandb:             val_recall0.75 0.53846
wandb: 
wandb: 🚀 View run vgg16_2d_79_11_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/bq7c4xor
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_11/wandb/run-20250702_005113-bq7c4xor/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_11/wandb/run-20250702_012744-60qopu9u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_11_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/60qopu9u
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: uploading history steps 304-306, summary, console lines 4-5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▂▂▂▂▅▅▃▇▅▅▆▅▅▇▅█▅▆▇▆▄▆▅▆▇▅▆▄▅▆▅▅▆▇▇▅
wandb:           test_accuracy0.5 █▅▅▆▆▆▆▆▇▅▇▅▆▆▃▆▄▇▃▄▃▄▄▃▁▃▄▃▄▄▃▆▁▃▂▃▄▄▃▂
wandb:          test_accuracy0.75 ██████████▇▇▇█▇█▄█▄▃▅▃▂▃▃▂▃▂▃▂▂▁▁▂▄▃▂▂▂▂
wandb:                 test_auroc ▁▂▂▄▃▂▃▅▆▇█▇▅▇▇▇▇▇█▇▇█▆▆▅▆▅▆▆▅▄▅▇▅▅▆▆▆▆▅
wandb: test_balanced_accuracy0.25 ▅▅▁▂▂█▇▇█▅▅▆▆▆▃▇▅▆▇▆▄▃▇▄▅▃▆▆▆▇▅▆▆▅▅▅▄▆▃▄
wandb:  test_balanced_accuracy0.5 ▄▃▅▅▄▇███▇▇▅▅█▅▅▂▁▃▄▃▅▄▄▂▅▃▄▅▅▅▃▃▄▄▆▆▄▅▅
wandb: test_balanced_accuracy0.75 ▃▃▃▃▃▄▃▄▄▆█▅▇▅█▅▃▂▇▇▄▃▄▄▂▂▄▂▂▁▁▂▁▁▂▃▂▃▂▂
wandb:         test_precision0.25 ▄▄▄▄▄▂▂▁▄▃▅▄▄▅▅▆▅▂▄█▄▃▄▄▇▄▅▄▁▄▅▄▄▅▂▂▄▄▆▂
wandb:          test_precision0.5 ▁▁▆▅▅▅▇▆▅▇▅▇▇▇█▇▆▅▅▆▅▆▅▄▆▅▅▅▅▆▅▅▆▅▅▅▅▆▅▅
wandb:         test_precision0.75 ▁▁▁▁▁▇▆▅▇▁██▅█▇▅▅▅▆▅▄▄▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test_recall0.25 ████████▄▅▄▅▃▆▂▅▅▂▅▃▄▅▅▂▄▃▃▂▅▃▂▃▂▂▂▂▁▁▂▂
wandb:             test_recall0.5 ▁▁▅▃▄▅▅▅▃▅▆▅▅▅▅▇▅▅▅▅▅▅▅▅▅█▆▅▅▅▄▅▅▅▅▅▅▅▅▆
wandb:            test_recall0.75 ▁▁▁▁▁▁▂▂▄▃▃▅▇▆▆▅▆▇▇▇▆▇▆▇▇▇▇▆▇▅▇█▇▇▇▇█▆▇▇
wandb:                train_auroc ▁▁▃▄▃▅▇▇▇▇▇▇▇█▇█████████████████████████
wandb:                 train_loss █████▇▇▆▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▃▄▄▄▆█▄▆▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆
wandb:            val_accuracy0.5 ▆██▆▆▃▆▂▄█▄▅▇▄▄▅▃▄▃▂▄▃▃▄▃▄▁▄▃▄▃▃▄▂▂▃▃▄▃▂
wandb:           val_accuracy0.75 ██▇▇████████▇█▄▇▇▇▇▆▄▆▄▃▃▄▄▃▃▂▂▂▂▂▁▂▁▂▂▄
wandb:                  val_auroc █▇▇▅▅▂▂▁▁▁▁▁▂▂▃▄▄▄▄▄▄▄▄▄▄▃▄▄▃▄▄▄▃▄▃▃▃▃▃▃
wandb:  val_balanced_accuracy0.25 ▅▅▅▅▅▁▂▃▁▂▁▅▃▃▆▅▅▅▆▇▆▆▆▇▆▄▅█▄▇▄▆▅█▆██▇▇▆
wandb:   val_balanced_accuracy0.5 ▆▅█▇▂▂▁▄▄▇▄▅▄▃▅▃▃▅▅▅▅▆▄█▆▄▇▄▂▅▆▂▂▆▂▄▄▂▂▅
wandb:  val_balanced_accuracy0.75 ▃▃▃▃▂▂▂▂▆▆█▆▅▄▆▁▂▃▂▃▃▃▁▂▄▃▂▂█▂▁▂▄▆▅▆▄▂▃▃
wandb:          val_precision0.25 ▅▅▅▅▆▆▄▁▃▁▁▄▄▆▅▄▅▅▆▇▅▆▇█▇██▅▆▇▅▆▅█▆▇▆▅█▆
wandb:           val_precision0.5 ▁▇▆▆▇▆▇▄▅▆█▇▅▅▅▅▅▅▅▆▄▅▆▅▄▅▅▅▅▄▅▅▅▅▄▅▅▅▅▅
wandb:          val_precision0.75 ▁▁▁▁▁▇▇██▆▆▆▄▄▅▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄
wandb:             val_recall0.25 ███▇▅▃▁▃▁▂▂▁▂▂▁▃▃▂▃▄▂▄▃▄▄▃▁▃▂▃▄▃▄▄▂▁▃▁▂▁
wandb:              val_recall0.5 ▁██▇▃▃▄▅▅▅▅▄▅▅▅▄▆▄▆▆▇▆▅█▆▅▇▆▅▅▅▇▆▅█▆▅▆▅▇
wandb:             val_recall0.75 ▁▁▁▃▃▄▃▃▅▅▅▅▆▆▅▆▅▅▅▄▅▅▅▆▅▅▅▆▅▆▅▅▆▇▆█▆▇▇▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.46835
wandb:           test_accuracy0.5 0.51899
wandb:          test_accuracy0.75 0.53165
wandb:                 test_auroc 0.52034
wandb: test_balanced_accuracy0.25 0.47881
wandb:  test_balanced_accuracy0.5 0.49619
wandb: test_balanced_accuracy0.75 0.47161
wandb:         test_precision0.25 0.2381
wandb:          test_precision0.5 0.25
wandb:         test_precision0.75 0.22581
wandb:            test_recall0.25 0.5
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0.35
wandb:                train_auroc 1
wandb:                 train_loss 0.01957
wandb:           val_accuracy0.25 0.52381
wandb:            val_accuracy0.5 0.55238
wandb:           val_accuracy0.75 0.54286
wandb:                  val_auroc 0.48807
wandb:  val_balanced_accuracy0.25 0.50292
wandb:   val_balanced_accuracy0.5 0.50901
wandb:  val_balanced_accuracy0.75 0.46397
wandb:          val_precision0.25 0.25
wandb:           val_precision0.5 0.25581
wandb:          val_precision0.75 0.21053
wandb:             val_recall0.25 0.46154
wandb:              val_recall0.5 0.42308
wandb:             val_recall0.75 0.30769
wandb: 
wandb: 🚀 View run vgg16_2d_79_11_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/60qopu9u
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_11/wandb/run-20250702_012744-60qopu9u/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_11/execution_datetimes.json

**************************************************  Experiment 79 | Version 12 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 36, 1.0: 28}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 31, 1.0: 33}
    Batch label distribution: {0.0: 32, 1.0: 32}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 26, 1.0: 34}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_12/wandb/run-20250702_014738-ikfgjy21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_12_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ikfgjy21
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▂▂▇▆▆▄▆▇▅▇▇▇▇▇▇▆▇▇▇▇▇▇█▇█▇▇█▇▇█▇▅▇
wandb:           test_accuracy0.5 ▁▁▅▆▆▆▇██▇█▆▇▆▆▆▇▆▆▆▇▆▆▆▆▆▆▅▆▅▆▆▆▆▅▆▅▆▅▅
wandb:          test_accuracy0.75 ▇▇▇▇█████▇▆▆▅▅▆▆▆▆▅▅▅▅▄▅▃▆▂▁▄▅▂▂▃▁▄▂▁▂▁▄
wandb:                 test_auroc ▁▁▁▂▂▃▇█████▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▅▅▅▅▅▅▅▄▄▅▅▄▄
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▂▂▅▅█▆▇▅▅▄▅▅▄▄▆▄▄▅▄▃▃▃▄▃▃▄▅▃▄
wandb:  test_balanced_accuracy0.5 ▂▁▁▂▂████▄▅▅▄▅▄▄▅▄▃▃▃▄▄▃▃▅▄▄▄▃▄▄▃▄▄▃▃▃▃▄
wandb: test_balanced_accuracy0.75 ▂▂▂▂▄▄▄▂▂▇▄▄▅▇▄█▅▇▇▆▁▇▅▄▅█▄▅▅▆▇▅▇▇▅▅▅▅▆▅
wandb:         test_precision0.25 ▂▂▂▂▂▁▁▂▂▂▂▆▇▇▆█▅▆▅▇▅▅▅▆▅▆▅▅▇▅▅▆▆▅▅▆▅▄▅▄
wandb:          test_precision0.5 ▁▂▂▃█▇█▇▄▄▅▅▃▃▃▃▃▃▃▃▂▃▃▃▂▄▃▃▂▂▃▃▃▃▂▃▂▂▂▃
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁█▁█▁▁▃▁▃▃▃▄▄▃▄▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃▃
wandb:            test_recall0.25 █████▇▇▆▅▅▅▄▅▅▅▄▃▃▃▃▃▃▂▃▂▂▃▂▂▁▂▁▁▂▁▁▁▁▁▄
wandb:             test_recall0.5 ██▇▃▂▂▃▁▁▃▃▃▂▃▂▄▃▅▅▃▃▃▃▄▄▃▄▄▃▃▄▃▃▃▃▃▃▃▃▄
wandb:            test_recall0.75 ▁▁▁▂▂▂▂▂▂▁▁▃▃▅▃▃▆▆▅▅▆▆▆▇▅▆▆▇██▆███▇█▆█▇▇
wandb:                train_auroc ▁▁▂▂▃▅▆▆▆▇▇▇▇▇██████████████████████████
wandb:                 train_loss ███▇▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▂▂▂▂▃▃▄▄▅▆▆▇▆▇▇▇▇▆█▆▇██▇▆█▅██▅▆█▆▇
wandb:            val_accuracy0.5 ▁▄▅▅▅▄▇▃▆▅▅█▆▄▅▃▅▄▇▂▄▄▂▃▃▂▄▅▄▄▄▄▆▅▅▆▂▄▄█
wandb:           val_accuracy0.75 ████████▇▇▇▇▇▇▆▅▅▂▄▃▃▂▄▂▂▂▂▁▂▂▂▂▂▁▂▂▁▁▁▂
wandb:                  val_auroc ▄▄▄▁▁▁▂▃▅▄▅▇▇█▇█▆▇█▆▇▇▇▅▅▄▅▆▅▃▄▅▄▄▃▅▅▄▃▃
wandb:  val_balanced_accuracy0.25 ▅▅▅▅▅▁▇▄▆▇▆▄▅▇▆▄▇▅▄▆▇█▆▆▄▃▄▅▂▄▇▃▆▄▃▄▅▅▃▁
wandb:   val_balanced_accuracy0.5 ▃▃▇▃▃▆▅█▅▃▆▅▇▆▆▅▅▆▄▄▃▃▆▅▄▅▃▅▅▅▄▅▁▆▅▆▇▆▃▇
wandb:  val_balanced_accuracy0.75 ▄▄▄▃▄▅▅▆▅▆█▅▅▆▆▅▅▆▄▃▁▃▃▅▄▁▁▂▁▄▃▃▃▂▂▂▃▃▃▂
wandb:          val_precision0.25 ▅▅▅▅▅▆▆▆▅▅▃▄▄▆▇▃▆▄▆▇█▆█▆▄▁▃▅▄▁▆▅▄▅▂▃▄▃▅▄
wandb:           val_precision0.5 ▁▇▆▆▇▆▇▆▆▇▆▆▆▆▆▆▇▆▆▆▆▆▇▆▇▆▇▇▆▇▆▆▆▇▆▆▇▇▇█
wandb:          val_precision0.75 ▁▁▁▁▄▅████▅▅▅▅▅▅▅▅▅▄▅▄▃▄▄▃▃▄▃▃▃▄▄▃▄▄▄▄▃▄
wandb:             val_recall0.25 ██████████▅▅▄▄▄▃▃▂▂▂▂▃▂▂▂▂▂▂▃▂▂▃▂▂▂▂▂▂▂▁
wandb:              val_recall0.5 █▇▇▂▂▁▁▃▃▂▃▂▂▂▂▁▃▃▂▂▅▁▂▁▁▂▂▁▂▁▂▂▂▁▃▃▅▂▃▁
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▂▃▃▃▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▇▅▅▅▇▅▆▅█▆▇▇▆█
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.59494
wandb:           test_accuracy0.5 0.60759
wandb:          test_accuracy0.75 0.65823
wandb:                 test_auroc 0.55847
wandb: test_balanced_accuracy0.25 0.56356
wandb:  test_balanced_accuracy0.5 0.52246
wandb: test_balanced_accuracy0.75 0.53983
wandb:         test_precision0.25 0.3125
wandb:          test_precision0.5 0.28
wandb:         test_precision0.75 0.31579
wandb:            test_recall0.25 0.5
wandb:             test_recall0.5 0.35
wandb:            test_recall0.75 0.3
wandb:                train_auroc 0.99964
wandb:                 train_loss 0.1002
wandb:           val_accuracy0.25 0.57143
wandb:            val_accuracy0.5 0.64762
wandb:           val_accuracy0.75 0.64762
wandb:                  val_auroc 0.43574
wandb:  val_balanced_accuracy0.25 0.47006
wandb:   val_balanced_accuracy0.5 0.50779
wandb:  val_balanced_accuracy0.75 0.49489
wandb:          val_precision0.25 0.21212
wandb:           val_precision0.5 0.26087
wandb:          val_precision0.75 0.2381
wandb:             val_recall0.25 0.26923
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.19231
wandb: 
wandb: 🚀 View run vgg16_2d_79_12_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/ikfgjy21
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_12/wandb/run-20250702_014738-ikfgjy21/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_12/wandb/run-20250702_023004-61yth9aj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_12_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/61yth9aj
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▂▃▅▅▅▆▆▆▆▄█▅▆▆▅▅▅▆▆▅▇▅▅▅▆▇▆▆▆▆▆▅▆▆▆▆▆
wandb:           test_accuracy0.5 █▄▄▅▇▅▇▅▇▇▇▇▇▇▇▇▄▇▄▅▆▅▅▅▅▅▄▂▃▂▁▂▂▁▂▂▂▂▂▁
wandb:          test_accuracy0.75 █████████▇██▇█▇████▆▆▄▃▅▃▃▃▃▂▁▂▁▃▁▂▁▁▁▁▁
wandb:                 test_auroc ▂▁▁▁▄▄▅▅▅▆▆▇███▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▁▂▂▁
wandb: test_balanced_accuracy0.25 ▁▁▁▁▂▁▁▁▂▃▆▇██▆▅▇▆▅▄▆▇▆▅▆▄▄▅▅▄▄▅▆▆▄▃▄▅▆▅
wandb:  test_balanced_accuracy0.5 ▆▃▃▃▃▂▂▂▂▃▄▄▅▃▄██▆▇▇▅▃▆█▅▃▅▄▅▃▃▂▂▃▁▃▁▁▁▂
wandb: test_balanced_accuracy0.75 ▄▄▄▄▄▄▄▄▄▄▄▄▃▆▇██▆▃▃▄▂▃▃▂▃▃▂▅▃▁▂▃▃▅▂▄▂▃▃
wandb:         test_precision0.25 ▁▁▁▁▂▁▁▁▄▆▅▆▅▄▄▄▄▅▄▅▆▃▅▅▅▅▇▇▃▃▇▅▆▆▇▅▅█▅█
wandb:          test_precision0.5 ▁▁▅▅▆▅▆▆▆▆███▇▇▇▇▇▇▆▆▆▅▅▅▆▅▅▅▅▅▅▅▆▅▅▅▅▅▅
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▄▅▇▇▆█▇▅▅▅▄▆▅▄▅▄▅▄▄▄▅▄▄▄▄▅▄▅▄▄
wandb:            test_recall0.25 ██▇▇▅▅▅▅▆▆▆▆▄▅▄▄▅▄▄▄▄▃▅▅▂▃▅▄▄▄▅▄▁▃▃▄▄▄▄▂
wandb:             test_recall0.5 ▁▇▇▇▇▅▃▄▄▃▄▅█▇▇▆▆▅▆▇▅▅▇▅▅▅▆▅▅▅▅▄▅▅▅▅▅▅▅▅
wandb:            test_recall0.75 ▁▁▁▁▁▂▁▁▁▂▁▄▅▄▄▄▄▄▄▄▄▄▅▄▄▄▅▅█▄▄▅▅▄▅▅▅▅▄▅
wandb:                train_auroc ▂▁▁▁▁▃▄▄▅▅▆▆▇▇▆▇▇▇▇▇▇██▇████████████████
wandb:                 train_loss ███▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▂▃▃▄▅▅▅▆▆▇▆▇▇▇██▇▇▇████▇██▇▇▇▇█▇▇▇▇▇██
wandb:            val_accuracy0.5 ▂▁▆▆▇▅▆▆▆▆▆▆▅▇▅▇▇▇▆▅▄▆▅▃▇▇▅▅▆▅▅▆█▆▅▄▅▅▄▄
wandb:           val_accuracy0.75 ███▇▇▇▇▇▇▇▆▇▇▇▇▇▆▆▆▇▆▅▆▅▆▄▄▅▄▅▃▅▆▅▃▇▁▂▁▃
wandb:                  val_auroc ▁▆▆▅▃▃▂▂▂▃▃▅▅▅▆▆▇▇█▇▇▇██▇▇▇▇▇█▇█▇▇▇█▇▇██
wandb:  val_balanced_accuracy0.25 ▄▄▄▄▄▃▂▁▂▃▃▃▆▅▆▃▇▆▆▆▇▇▆▆▇██▅▆▆▇█▆▆▇▆▇▇▆▆
wandb:   val_balanced_accuracy0.5 ▃█▅▅▃▁▃▃▄▄▄▅▆▅▅▄▆▄▆▆▇▇▇▇▇▇█▅▇▅▆▆▇█▇▇▆▇▇▆
wandb:  val_balanced_accuracy0.75 ▂▂▂▁▂▂▂▂▂▁▂▄▃▃▃▄▃▄▄▄▄▅▅▅▅▇▇▇▆▆▆█▅█▆▇▇▇▇▆
wandb:          val_precision0.25 ▄▄▄▄▄▁▃▃▃▃▃▄▄▄▄▄▄▆▄▆▆▆▇▇▇▆▆▇▇█▇██▇██▆▇▇▇
wandb:           val_precision0.5 ▁▆▇▆▆▅▄▄▄▆▆▇█▇▇▆▆█▇▇████▇▇███▇█▇████▇██▇
wandb:          val_precision0.75 ▁▁▁▁▁▅▁▁▆█▅▆▅▅▅▆▅▅▅▅▅▅▅▅▅▅▅▅▄▄▅▄▅▅▅▅▅▅▄▅
wandb:             val_recall0.25 █▆▆▆▅▄▃▁▁▁▁▁▁▂▁▂▄▄▁▃▃▃▂▂▂▂▂▁▃▂▃▂▂▂▃▂▂▂▃▂
wandb:              val_recall0.5 ▁▁▅▃▄▄▅▅▄▅▅▅▅▄▄▅▅▅▅▄▅▆▆▅▅▆▆▅▆▇▆▆▆█▇▇▇█▇▇
wandb:             val_recall0.75 ▁▁▁▁▁▂▂▂▂▂▁▁▁▁▂▃▃▃▃▅▃▃▅▄▄▄▇▅▇▇▇▇█▆▇██▇▇▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.53165
wandb:           test_accuracy0.5 0.53165
wandb:          test_accuracy0.75 0.5443
wandb:                 test_auroc 0.52924
wandb: test_balanced_accuracy0.25 0.60381
wandb:  test_balanced_accuracy0.5 0.50466
wandb: test_balanced_accuracy0.75 0.48008
wandb:         test_precision0.25 0.31915
wandb:          test_precision0.5 0.25714
wandb:         test_precision0.75 0.23333
wandb:            test_recall0.25 0.75
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0.35
wandb:                train_auroc 0.99908
wandb:                 train_loss 0.10768
wandb:           val_accuracy0.25 0.57143
wandb:            val_accuracy0.5 0.60952
wandb:           val_accuracy0.75 0.62857
wandb:                  val_auroc 0.59688
wandb:  val_balanced_accuracy0.25 0.61198
wandb:   val_balanced_accuracy0.5 0.59859
wandb:  val_balanced_accuracy0.75 0.58544
wandb:          val_precision0.25 0.32727
wandb:           val_precision0.5 0.33333
wandb:          val_precision0.75 0.33333
wandb:             val_recall0.25 0.69231
wandb:              val_recall0.5 0.57692
wandb:             val_recall0.75 0.5
wandb: 
wandb: 🚀 View run vgg16_2d_79_12_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/61yth9aj
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_12/wandb/run-20250702_023004-61yth9aj/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_12/wandb/run-20250702_030951-clqpugxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_12_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/clqpugxi
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▂▃▅▅▆▆▆▇▅▆▆▅▅▅▅▅▇▆▅▅▅█▇▅▄▆▅▆▅▅▅▅
wandb:           test_accuracy0.5 ▇▁▄▅▆▇▇██▇▇██▇▇▆▇▆▇▆▅▅▆▆▆▅▅▅▄▇▅▃▅▅▄▅▅▄▅▄
wandb:          test_accuracy0.75 ▇▇▇▇▇▇▇▇▇▆▇▇▆▇█▆▆▇▅▃▆▃▅▅▃▅▂▃▂▃▅▂▂▁▅▁▄▂▂▂
wandb:                 test_auroc ▁▂▃▂▃▃▃▃▃▃▅▆▅▆▆█▇███▇▇▇▇█▆▆▆▇▇▇▇▇▅▆▅▅▅▆▆
wandb: test_balanced_accuracy0.25 ▄▄▄▄▄▄▁▂▁▁██▆▅█▇▅▆▆▅▄▃▆▆▅▄▅▇▃▅█▅▅▆▃▅▅▄▄▄
wandb:  test_balanced_accuracy0.5 ▃▁▃▃▃▅▆▆▆▇▆▆█▅█▆▇▇▅▄▅▆▄▅▄▄▄▄▄▄▄▄▂▅▄▃▄▄▃▄
wandb: test_balanced_accuracy0.75 ▃▃▃▃▃▃▃▂▂▂▄▇▅▇▃▆▇█▆▅▇▇▇▅▆▅▅▅▅▅▅▅▁▁▃▂▄▄▂▄
wandb:         test_precision0.25 ▃▃▁▂▂▄▄▄▅▃▃▃▂▄▃▇▃▂▃▂▄▅▂▂▁▄▂▂▇█▅▄▂▄▃▃▄▂▂▂
wandb:          test_precision0.5 ▁▂▁▃▂▄▂▄▅▅▄█▃▃▄▄▅▄▂▃▃▂▄▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▂
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▃▆▇▆▇▆█▇▇▆▅▅▆▅▅▆▅▅▅▄▄▅▄▅▄▄▄▄
wandb:            test_recall0.25 ████▆▄▃▅▃▃▂▂▃▃▂▃▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▃▅▂▂▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▂▃▁▅▅▆▇▇▇▇▇▇▇▇▆▇█▆▇█▆▇▇▆▇▇▆▆▇██████
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▂▁▂▂▄▃▅▆▆▆▆▅▆▆▆▆▆▇▆▆▆█▆▆▆▆█▆▆▆▆▇
wandb:                train_auroc ▁▁▂▂▃▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb:                 train_loss ██▇▇▇▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▂▄▄▄▅▅▆▅▆▇▇▇█▇▇▇▇▇▇▇▇▆█▇▇▇▇▆██▆▆█▇
wandb:            val_accuracy0.5 ▇▁▁▂▃█▆▇▅▆▆▇▇▆▇▆▆██▆▆▇▅▆▅▄▅▅▅▅▅▅▅▅▅▅▅▄▅▅
wandb:           val_accuracy0.75 ████▇▇▇▇▇▇▇▇███▇█▆▅▆▅▅▄▄▄▄▂▃▃▂▃▂▃▂▃▁▁▂▂▂
wandb:                  val_auroc █▅▄▄▃▂▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▄▃▄▄
wandb:  val_balanced_accuracy0.25 ▄▄▄▄▄▁▃▃▃▂▄▂▄▃▄▆▃▅▇▆▆▆▅▅▆▆▃▆▇▆██▇▅▄▆▄▅▇▅
wandb:   val_balanced_accuracy0.5 ▄█▄▄▂▃▂▄▂▃▁▅▃▄▄▃▂▄▃▄▄▂▁▄▂▂▄▃▂▁▁▂▁▄▃▁▂▅▃▃
wandb:  val_balanced_accuracy0.75 ▃▃▃▃▃▁▁▁▃▂▄▆▆▇▄▄▄▂▅▄▆▄▅▃▂▃▂▄▃▄▃▃█▂▂▅▁▃▂▄
wandb:          val_precision0.25 ▄▄▄▄▄▄▄▄▄▃▁▂▃▁▁▂▅▄▅▄▅▅▆▆▇▆▆▅▇▇▇▅▆▅▆▆█▇▇▅
wandb:           val_precision0.5 ▃▅█▆▁▃▆▃█▄▅▂▅▅▁▃▂▃▂▂▃▂▁▂▂▃▁▃▁▁▅▂▃▃▃▄▃▂▁▃
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▇▆█▆▇▆▇▆▆▆▆▆▅▅▄▅▄▄▄▅▅▅▄▅▅▄▄▄▅▄▄▄▅
wandb:             val_recall0.25 ██▇▄▄▃▄▄▃▃▂▃▃▃▃▃▃▃▃▃▁▁▃▃▂▂▃▃▃▃▄▂▃▂▃▄▃▃▂▁
wandb:              val_recall0.5 ▁██▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃▄▄▄▃▃▃▄▃▃▃▃▅▃▅▄▅▅▄▅▄▅▄
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▃▃▄▄▆▅▆▅▆▆▄▆▆▇▇▇▅▇▆██▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.4557
wandb:           test_accuracy0.5 0.50633
wandb:          test_accuracy0.75 0.53165
wandb:                 test_auroc 0.53305
wandb: test_balanced_accuracy0.25 0.47034
wandb:  test_balanced_accuracy0.5 0.48771
wandb: test_balanced_accuracy0.75 0.48814
wandb:         test_precision0.25 0.23256
wandb:          test_precision0.5 0.24324
wandb:         test_precision0.75 0.24242
wandb:            test_recall0.25 0.5
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0.4
wandb:                train_auroc 1
wandb:                 train_loss 0.03795
wandb:           val_accuracy0.25 0.53333
wandb:            val_accuracy0.5 0.55238
wandb:           val_accuracy0.75 0.59048
wandb:                  val_auroc 0.51655
wandb:  val_balanced_accuracy0.25 0.54796
wandb:   val_balanced_accuracy0.5 0.52191
wandb:  val_balanced_accuracy0.75 0.53432
wandb:          val_precision0.25 0.28302
wandb:           val_precision0.5 0.26667
wandb:          val_precision0.75 0.28205
wandb:             val_recall0.25 0.57692
wandb:              val_recall0.5 0.46154
wandb:             val_recall0.75 0.42308
wandb: 
wandb: 🚀 View run vgg16_2d_79_12_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/clqpugxi
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_12/wandb/run-20250702_030951-clqpugxi/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_12/execution_datetimes.json

**************************************************  Experiment 79 | Version 13 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 5}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 6, 1.0: 6}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 5, 1.0: 11}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 8, 1.0: 8}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 7, 1.0: 9}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 9, 1.0: 7}
    Batch label distribution: {0.0: 6, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 7}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 14, 1.0: 2}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 6}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_13/wandb/run-20250702_033845-72lrvwj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_13_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/72lrvwj2
    Batch label distribution: {0.0: 12, 1.0: 4}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 11, 1.0: 5}
    Batch label distribution: {0.0: 13, 1.0: 3}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▄▅▅▆▆▅▅▇▇▇█▇▇▇▇▇██
wandb:           test_accuracy0.5 ▁▂▂▃▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████████▇█
wandb:          test_accuracy0.75 ▇▇▇▇███████████████▇▇▇▇▇▅▅▅▅▇▇▄▇▄▅▂▂▂▁▁▁
wandb:                 test_auroc ▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▆▆▇███████████▇▇▇████▇
wandb: test_balanced_accuracy0.25 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▅▂▆▆█▇█▆█████
wandb:  test_balanced_accuracy0.5 ▃▃▁▂▃▃▃▄▃▃▄▄▄▃▃▄▄▅▄▅▇▆▇▆▇▇█▇▇▇█▇▇▇▇████▇
wandb: test_balanced_accuracy0.75 ▂▂▂▂▂▂▂▂▇▇▇▇▇▇▇▇▇▇▇▇▇▂▇▂▂▂▂▂▁▁▅▄▇▇█▇▄▄▅▂
wandb:         test_precision0.25 ▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▁▂▂▂▄▄▄▃▄▄▇▇▇█▇▇▇██▇
wandb:          test_precision0.5 ▁▄▄▄▄▃▃▃▄▄▅▄▄▄▆▅▅▅▄▆██▇█▇▇▇▇██▇███▇▇▇█▇▇
wandb:         test_precision0.75 ▁▁▁▁███████████████▁▁▁▁▁▁▁▁▅▅▄▄▃▄▃▃▃▃▃▃▃
wandb:            test_recall0.25 ███████████▇▇▇▇▇▇▇▇▅▅▅▅▅▅▅▅▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:             test_recall0.5 ▇█▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▃▃▄▄▄
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▁▁▁▁▅█▅██████
wandb:                train_auroc ▁▁▂▂▂▂▁▂▂▂▂▂▂▂▃▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇█████████
wandb:                 train_loss ████▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▅▄▄▄▄▄▃▃▃▃▃▂▂▂▃▂▂▂▂▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▅▆▅▇▆▆▆▇▇▇▇▇▇██▇██▇
wandb:            val_accuracy0.5 ▂▁▁▁▂▂▂▇▇▇███████▇▇▇▇████▇▇█▇██▇▇▇▇▇▇██▇
wandb:           val_accuracy0.75 ███████████████████▆▃▆▆▆█▆████▆▃▆▆▁▁▁▃▃▃
wandb:                  val_auroc ▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▆▇▇▇▇█▇▇▇███████
wandb:  val_balanced_accuracy0.25 ▅▅▅▅▅▅▅▅▆▆▆▇██▇▆▆▇▇█▅▆▁▃▂▃▃▅▃▆▅▆▅▅▄▅▅▅▅▅
wandb:   val_balanced_accuracy0.5 ▁▆█▃▁▄▄▄▅▄▄▄▄▄▅▅▅▅▆▅▅▅▆▅▅▆▆▅▅▆▆▅▆▆▅▅▅▅▆▆
wandb:  val_balanced_accuracy0.75 ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▆▆▆▆▆▆██▇▇▆▆▆▆▆▆███▅
wandb:          val_precision0.25 ▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆█▆█▅▁▃▁▁▁▄▇▇▇▅▅▆▇▄▃▆▅▅▄
wandb:           val_precision0.5 ▆▆▆▆▂▁▁▅▃▃▂▂▃▃▅▆█▇▆▄▇▆▆▅▄▅▅▇▆▇▇▇▇▆▆▅▅▅▅▇
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▇▇▅▇▇█▇▆▆▆▆▇▇▇▇▇▆▇▆
wandb:             val_recall0.25 ██████████████▇▇▇▆▆▆▄▄▄▃▃▃▂▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:              val_recall0.5 ▆████▅▄▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▅▅▅▅▆▆▆▆▆▆▆██▆▆█████
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.55696
wandb:           test_accuracy0.5 0.6962
wandb:          test_accuracy0.75 0.70886
wandb:                 test_auroc 0.62627
wandb: test_balanced_accuracy0.25 0.60424
wandb:  test_balanced_accuracy0.5 0.59831
wandb: test_balanced_accuracy0.75 0.50763
wandb:         test_precision0.25 0.32558
wandb:          test_precision0.5 0.4
wandb:         test_precision0.75 0.28571
wandb:            test_recall0.25 0.7
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.1
wandb:                train_auroc 0.98065
wandb:                 train_loss 0.66483
wandb:           val_accuracy0.25 0.53333
wandb:            val_accuracy0.5 0.6381
wandb:           val_accuracy0.75 0.71429
wandb:                  val_auroc 0.51753
wandb:  val_balanced_accuracy0.25 0.50925
wandb:   val_balanced_accuracy0.5 0.50146
wandb:  val_balanced_accuracy0.75 0.51339
wandb:          val_precision0.25 0.25532
wandb:           val_precision0.5 0.25
wandb:          val_precision0.75 0.3
wandb:             val_recall0.25 0.46154
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.11538
wandb: 
wandb: 🚀 View run vgg16_2d_79_13_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/72lrvwj2
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_13/wandb/run-20250702_033845-72lrvwj2/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_13/wandb/run-20250702_044947-gwp30dsl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_13_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/gwp30dsl
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▂▂▂▂▃▃▃▃▃▄▅▅▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▇▇▇███▇██
wandb:           test_accuracy0.5 █▄▃▄▄▁▄▄▅▅▅▅███▇▇▇▆▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆
wandb:          test_accuracy0.75 ██████████▆▆▆▆▆▆▆▆██▃▆▆▃▁▁▁▁▁▁▁▁▁▃▁▁▁▃▆▆
wandb:                 test_auroc ▂▂▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇██████
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▂▂▂▁▁▁▂▂▂▄▅▅▆▅▅▅▅▆▇▆▇▇████▇▆███▇
wandb:  test_balanced_accuracy0.5 ▄▄▄▄▁▄▃▆▇▇▇▇▇▇▇▇▆▆▆▆▅▄▅▆▆▅▅▅▅▅▆▆▆▆▆▆▆▆▆█
wandb: test_balanced_accuracy0.75 ▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▂▄▄▄▄▂▂▄▁▁▁▁▁▁▁▁▁▁▁▄▄███
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▄▄▅▅▅▅▆▆▅▇▇▇█▇█▇▇▇█▇
wandb:          test_precision0.5 ▁▁▆▆▇▇▇████▇▇▇▇▇▇▇▆▇▆▆▇▆▆▆▆▆▇▇▇▇▇▇▇▇▇███
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄█
wandb:            test_recall0.25 ███████▆▆▃▃▃▃▃▃▃▃▁▁▁▁▁▃▃▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▁
wandb:             test_recall0.5 ▁▁▁▅▅▅▅▅▅▆▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇█▇▇
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▆▆▆█
wandb:                train_auroc ▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇████
wandb:                 train_loss ████▇▇▇▆▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▂▂▃▃▃▃▃▄▄▄▃▄▄▄▄▄▄▄▄▄▅▇▇▇▇▇█▇███▇▆▇▇
wandb:            val_accuracy0.5 █▃▃▃▂▁▁▁▁▁▂▃▄▄▃▆▆▆▆▆▆▆▆▆▇▆▇▆█▇▇▆▇▆▆▆▆▇██
wandb:           val_accuracy0.75 ▆▆▆▆▆▅▃▃▃▃▁▃▃▃▅▃▃▃▃▃▃▃▃▅▆▅▅▅▆▆▆▆▆▆█▆▆▆▆▅
wandb:                  val_auroc ▁▇█▇▇▆▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇████
wandb:  val_balanced_accuracy0.25 ▇▇▇▇▇▇▄▄▆▄▆▇▇▇▇▅▆█▅▅▅▅▃▁▄▅▇▆▆▆▇▇█▇▃▄▇▆▅▂
wandb:   val_balanced_accuracy0.5 ▅▅▄▃▃▂▂▁▂▁▃▃▃▄▄▆▆▆▇▆▆▆▇█▇▇▇█▇▇▇█▇▇▇█▇▇▇█
wandb:  val_balanced_accuracy0.75 ▂▂▂▂▂▂▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▂▂▂▂▅▃▅▄▄▄███████▇
wandb:          val_precision0.25 ████▇▇▆█████▇▇█▆▆▆▆▄▃▅▄▄▃▁▂▂▄▄▆▆▄▆▆▅▁▃▂▅
wandb:           val_precision0.5 ▁▁▃▄▄▃▃▃▃▄▄▄▄▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇█▇█▇
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▄▄▄▄▁▄▁▄▄▄▄▄▄▄▆▇▅▆▆▆▆▇▇█▇▇▇▇▇▆
wandb:             val_recall0.25 █████▇▇▇▇▇▆▆▆▆▆▆▆▅▄▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁
wandb:              val_recall0.5 ▁▁▁▃▄▄▃▃▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb:             val_recall0.75 ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▄▄▅▅▇▇▇▇▇▇▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.56962
wandb:           test_accuracy0.5 0.63291
wandb:          test_accuracy0.75 0.72152
wandb:                 test_auroc 0.63136
wandb: test_balanced_accuracy0.25 0.64576
wandb:  test_balanced_accuracy0.5 0.53941
wandb: test_balanced_accuracy0.75 0.5161
wandb:         test_precision0.25 0.34783
wandb:          test_precision0.5 0.30435
wandb:         test_precision0.75 0.33333
wandb:            test_recall0.25 0.8
wandb:             test_recall0.5 0.35
wandb:            test_recall0.75 0.1
wandb:                train_auroc 0.96493
wandb:                 train_loss 0.77989
wandb:           val_accuracy0.25 0.48571
wandb:            val_accuracy0.5 0.68571
wandb:           val_accuracy0.75 0.74286
wandb:                  val_auroc 0.51607
wandb:  val_balanced_accuracy0.25 0.4647
wandb:   val_balanced_accuracy0.5 0.55891
wandb:  val_balanced_accuracy0.75 0.54528
wandb:          val_precision0.25 0.22
wandb:           val_precision0.5 0.34783
wandb:          val_precision0.75 0.44444
wandb:             val_recall0.25 0.42308
wandb:              val_recall0.5 0.30769
wandb:             val_recall0.75 0.15385
wandb: 
wandb: 🚀 View run vgg16_2d_79_13_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/gwp30dsl
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_13/wandb/run-20250702_044947-gwp30dsl/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_13/wandb/run-20250702_055505-3npflm96
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_13_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/3npflm96
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▆▅▆▇▇▇▇▇▇▇▇▇▇▇█▆██▇▇
wandb:           test_accuracy0.5 █▁▂▂▄▄▅▅▅▅▄▅▅▆▆▅▇▆▆▇▆▆▆▆▆▇▆▆▆▆▆▆▅▅▅▅▅▆▅▅
wandb:          test_accuracy0.75 ██████████▆▆▆▆▃▃▅▅▅▅▁▅▅▃▃▅▅▅▅█▆███▆▆▅▆▆▆
wandb:                 test_auroc ▁▂▃▄▃▃▃▂▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█▇█▇██▇██▇
wandb: test_balanced_accuracy0.25 ▅▅▅▅▅▅▅▅▅▅▅▆▅▄▄▁▂▄▄▄▄▄▄▅▅▅▅▇▇▇▇▇▇▇▆█▇█▇▇
wandb:  test_balanced_accuracy0.5 ▃▁▂▃▁▂▂▃▃▄▅▆▆▆▅▂▄▅▅▅▅▅▆▆▆▆▆▇▆██▇█▇▆▆▆▅▆▆
wandb: test_balanced_accuracy0.75 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▃▃▃▃▄▄▃▄▄▄▄▃▅▄█▄▇▇█▆▇
wandb:         test_precision0.25 ▄▄▄▄▄▄▄▄▄▄▅▄▅▃▂▁▂▂▃▃▄▆▅▆▇▆▇▆▇▇▇▇▇▇▆█▆▇▇▆
wandb:          test_precision0.5 ▁▁▁▆▅▅▅▅▅▅▆▅▅▅▆▆▆▇▆▆▆▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▆▇▆
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇█▇▇▇▇▇▆▇▆▆
wandb:            test_recall0.25 ███████████████▃▂▂▂▂▃▃▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁
wandb:             test_recall0.5 ███▆▄▃▃▃▃▃▂▂▁▁▂▂▃▃▃▃▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▂▂▅▅▃▅▅▅██▇▇█████
wandb:                train_auroc ▁▂▃▂▃▃▃▄▄▅▅▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:                 train_loss █████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▁▂▂▃▄▄▄▄▅▅▆▆▅▆▆▆▆▇▆▇▇▇██
wandb:            val_accuracy0.5 █▂▁▁▁▂▅▅▅▄▄▄▄▄▅▅▆▆▆▆▆▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅▅
wandb:           val_accuracy0.75 █████▇▅▅▆▅██████▇█▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▁
wandb:                  val_auroc ▆██▃▃▂▂▃▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▄
wandb:  val_balanced_accuracy0.25 ▆▆▆▆▆▆▆▆▆▆▆▆▅▃▃▁▂▃▃▄▃▆▂▄▆▃▅▄▅▃▅▅▅▅▆▇█▇▇▇
wandb:   val_balanced_accuracy0.5 ▄▃█▅▁▂▂▂▁▁▃▂▅▄▅▅▄▄▅▄▄▃▆▄▄▄▄▄▃▄▅▄▅▄▄▃▅▅▄▅
wandb:  val_balanced_accuracy0.75 ▂▂▂▂▁▁▁▁▁▁▂▂▂▂▃▃▅▆▆▆▇▇▇▆▇▇▆█▇█▅▅▅▅▅█▆▇▆▇
wandb:          val_precision0.25 ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▂▁▁▂▃▃▅▃▂▁▆▄▁▃▃▃▅▅▆█▇▇▇█▇▇
wandb:           val_precision0.5 █▇▆▇▆▇▁▃▃▃▂▃▂▃▃▇▇████▆▅▆▆▆▆▆█▇▆▇▆▆▆▆▄▇▆█
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▄▄▄▄▆▆▇█▆██████▇▇▇▇▇▇▇▇▇▇▆▇▆▆▅
wandb:             val_recall0.25 ██████████▆▅▅▄▄▄▄▄▃▄▃▁▃▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▂▁
wandb:              val_recall0.5 ▁▁▁██▇▅▅▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▂▂▄▃▃▄▅▅▅▅▅▆▅▅▅▅▅▅▆▅▅▆▇▆▆▆▅▇█▇
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.49367
wandb:           test_accuracy0.5 0.62025
wandb:          test_accuracy0.75 0.6962
wandb:                 test_auroc 0.57288
wandb: test_balanced_accuracy0.25 0.54534
wandb:  test_balanced_accuracy0.5 0.54746
wandb: test_balanced_accuracy0.75 0.56525
wandb:         test_precision0.25 0.28261
wandb:          test_precision0.5 0.30769
wandb:         test_precision0.75 0.375
wandb:            test_recall0.25 0.65
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.3
wandb:                train_auroc 0.99027
wandb:                 train_loss 0.46711
wandb:           val_accuracy0.25 0.52381
wandb:            val_accuracy0.5 0.60952
wandb:           val_accuracy0.75 0.67619
wandb:                  val_auroc 0.51874
wandb:  val_balanced_accuracy0.25 0.51582
wandb:   val_balanced_accuracy0.5 0.52118
wandb:  val_balanced_accuracy0.75 0.53968
wandb:          val_precision0.25 0.26
wandb:           val_precision0.5 0.27273
wandb:          val_precision0.75 0.31818
wandb:             val_recall0.25 0.5
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.26923
wandb: 
wandb: 🚀 View run vgg16_2d_79_13_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/3npflm96
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_13/wandb/run-20250702_055505-3npflm96/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_13/execution_datetimes.json

**************************************************  Experiment 79 | Version 14 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 17, 1.0: 15}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 11, 1.0: 21}
    Batch label distribution: {0.0: 19, 1.0: 9}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 18, 1.0: 14}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 16, 1.0: 12}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 13, 1.0: 19}
    Batch label distribution: {0.0: 14, 1.0: 18}
    Batch label distribution: {0.0: 21, 1.0: 11}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 16, 1.0: 16}
    Batch label distribution: {0.0: 19, 1.0: 13}
    Batch label distribution: {0.0: 15, 1.0: 17}
    Batch label distribution: {0.0: 11, 1.0: 17}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 6, 1.0: 3}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 5, 1.0: 4}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 22, 1.0: 10}
    Batch label distribution: {0.0: 26, 1.0: 6}
    Batch label distribution: {0.0: 23, 1.0: 9}
    Batch label distribution: {0.0: 8, 1.0: 1}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_14/wandb/run-20250702_070052-61ecflj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_14_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/61ecflj6
    Batch label distribution: {0.0: 25, 1.0: 7}
    Batch label distribution: {0.0: 24, 1.0: 8}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▂▂▂▃▄▄▄▅▅▆▇▇▇█
wandb:           test_accuracy0.5 ▆▂▁▁▁▁▁▂▂▃▃▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███
wandb:          test_accuracy0.75 ▆▆▆▆▆▆▆▆▆▆▆▆▆█████████████▆▆▆▆▆▆▆▆▆▆▃▁▁▁
wandb:                 test_auroc ▁▂▂▂▃▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▅▅▇▇▇▇▇█████████████
wandb: test_balanced_accuracy0.25 ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▂▃▃▃▃▁▂▂▂▂▂▂▄▄▄▂▅▆▆▆█
wandb:  test_balanced_accuracy0.5 ▃▃▃▂▂▂▁▁▃▃▃▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▅▅▄▇▆▄▇▇▇▆▇▇█
wandb: test_balanced_accuracy0.75 ▄▄▄▄▄▄▄▄▄▄▄▄█████████████████▄▄▄▄▄▄▄▄▄▄▁
wandb:         test_precision0.25 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▃▂▆▅▅▆▅▆█
wandb:          test_precision0.5 ▁▂▄▅▄▄▄▅▅▄▅▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇████▇██
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ███████████████████▇▇▇▅▄▄▄▄▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▇▇▆▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▂▂▂▅▅▆▅▄▅▅▆▆▅▆▇▇▇█
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁███████████████▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▁▃▃▃▃▃▃▃▄▃▄▃▄▄▅▄▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇█████████
wandb:                 train_loss ██████▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▃▄▅▅▅▅▅▅▅▅▅▆▆▇██
wandb:            val_accuracy0.5 ▁▁▁▂▂▆▇▇▇▇▇▇▇▇▇▇▇█████▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:           val_accuracy0.75 ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▃▁▁▁▃▃▃▃▃▃▆█▆█▆▆▆▃▃▃
wandb:                  val_auroc ▂▅▅▁▁▁▂▁▂▂▁▁▁▁▁▂▂▂▂▂▄▄▄▅▅▅▅▆▆▆▅▅▆▆▆█████
wandb:  val_balanced_accuracy0.25 ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆██▇▇▇▇▆▄▅▅▄▃▄▄▂▁▄▅▃▃▄▄▅▅▆
wandb:   val_balanced_accuracy0.5 ▄▇▇██▅▁▃▄▅▅▅▆▆▆▄▅▅▆▆▇▇▇▇▇▇▆▇▇▅▅▆▄▅▅▅▅▆▆▅
wandb:  val_balanced_accuracy0.75 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▅▇▆▆█▇█▇▇▇
wandb:          val_precision0.25 ▆▆▆▆▆▆▆▆▆▆▇▇▇████▇▇▇▇▇▅▄▅▃▄▁▃▄▃▃▃▃▃▄▃▄▄▆
wandb:           val_precision0.5 ▁▆▆▆▇▅▆▆▇▇▇▆▆▆▆▆▆▇▆▇█▇█▇█████▇▇▇▇▇▇▆▆▇▇▇
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▇▇▇▇▇▇███▇▇▇▇▇
wandb:             val_recall0.25 ██████████████████████▇▅▅▄▄▃▃▃▂▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁███▇▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅████
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.49367
wandb:           test_accuracy0.5 0.73418
wandb:          test_accuracy0.75 0.73418
wandb:                 test_auroc 0.65763
wandb: test_balanced_accuracy0.25 0.57839
wandb:  test_balanced_accuracy0.5 0.62373
wandb: test_balanced_accuracy0.75 0.49153
wandb:         test_precision0.25 0.3
wandb:          test_precision0.5 0.47059
wandb:         test_precision0.75 0
wandb:            test_recall0.25 0.75
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0
wandb:                train_auroc 0.94604
wandb:                 train_loss 1.00932
wandb:           val_accuracy0.25 0.48571
wandb:            val_accuracy0.5 0.62857
wandb:           val_accuracy0.75 0.74286
wandb:                  val_auroc 0.49464
wandb:  val_balanced_accuracy0.25 0.51631
wandb:   val_balanced_accuracy0.5 0.49513
wandb:  val_balanced_accuracy0.75 0.55818
wandb:          val_precision0.25 0.25862
wandb:           val_precision0.5 0.24
wandb:          val_precision0.75 0.45455
wandb:             val_recall0.25 0.57692
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0.19231
wandb: 
wandb: 🚀 View run vgg16_2d_79_14_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/61ecflj6
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_14/wandb/run-20250702_070052-61ecflj6/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_14/wandb/run-20250702_080656-l3pnsqz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_14_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/l3pnsqz3
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 ████████████▇▇▆▃▃▃▁▂▁▁▁▂▁▂▂▂▂▂▂▂▂▄▄▃▃▃▃▃
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▇█▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▅▅▆▆▅▅▅▅▅▆▆▅▅▅▅▅▅▅
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▂▂▂▂▂▁▁▃▄▄▇▆▇▇▇█▆▆▇▆▆▄▆▄▃▃▃▃▃▃▄▅▃▁▁▁▁▁▁▂
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁▁▁▁▁▁▁▁▇▇▇▇▇████▇█████▇██▇▇▇▇▇▇▇▆▆▆▆▆
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▅▅▅▇▇▇▇███▇▇▇▇▆▅▅▅▅▅▄▅▃▃▃
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▁▅█▆█▇▇▄▆▇▇▃▅▄▃▄▅▃▅▃▄▂▅▂▅▁▃▄▅▆▃▂▄▃▄▂▄▄▅▄
wandb:                 train_loss █████████████▇▇▇▇▇▇▇▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▃▂▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ███████▆▆▄▃▃▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▃
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▂▁▁▁▁▃▅▆▆▆▇▇▇████████████████▇▇▇▇▇▇▇▇▇▇▆
wandb:  val_balanced_accuracy0.25 █████████████████████████████████████▁▁▁
wandb:   val_balanced_accuracy0.5 ▃▃▃▃▃▃▂▂▁▂▂▂▂▂▂▂▂▂▆▇▇▇█▇▇▇▇▆▇▇▅▃▃▃▁▁▁▁▁▂
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ████████████████████████████████████▁▁▁▁
wandb:           val_precision0.5 ▁▁▁▁▁▁▁▁▁▁▄▅▆▆▅▆▆▆▆▆█████▇▇██▆▅▅▅▅▅▅▅▅▅▅
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 █████████████████████████████████████▁▁▁
wandb:              val_recall0.5 ▁▁▁▁▁▁▁▁▁▃▃▃▃▄▄▅▆████████▆▆▆▆▆▅▅▃▃▃▃▃▃▃▃
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.63291
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.55085
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.48983
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.23529
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0.2
wandb:            test_recall0.75 0
wandb:                train_auroc 0.76224
wandb:                 train_loss 1.79965
wandb:           val_accuracy0.25 0.22857
wandb:            val_accuracy0.5 0.59048
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.49708
wandb:  val_balanced_accuracy0.25 0.46154
wandb:   val_balanced_accuracy0.5 0.46981
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.23301
wandb:           val_precision0.5 0.2069
wandb:          val_precision0.75 0
wandb:             val_recall0.25 0.92308
wandb:              val_recall0.5 0.23077
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_14_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/l3pnsqz3
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_14/wandb/run-20250702_080656-l3pnsqz3/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_14/wandb/run-20250702_081930-rj7f04p7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_14_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/rj7f04p7
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: uploading history steps 998-999, summary, console lines 4-5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▂▂▃▃▃▃▃▄▄▅█▇▇▇█▇████
wandb:           test_accuracy0.5 ██▁▂▄▆▆▇▇▇▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:          test_accuracy0.75 ████████████████████▆▆▆▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▃▆
wandb:                 test_auroc ▁▁▃▃▃▃▃▃▃▄▄▄▄▄▄▃▃▃▄▄▅▅▆▆▅▆▆▇▆▇▇▇▇███████
wandb: test_balanced_accuracy0.25 ▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▅▅▅▁▂▁▁▂▂▂▁▂▂▃▃▅▆▅▆▆▆▇▇▇█
wandb:  test_balanced_accuracy0.5 ▄▃▃▂▄▄▁▁▁▄▄▆▆▆▄▄▃▄▅▆▄▅▆▇▆▆▆▅▆▆▆▇████▇█▇█
wandb: test_balanced_accuracy0.75 ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▃▂▂▂▂▂▄▄▆█▆
wandb:         test_precision0.25 ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▂▂▃▃▁▁▁▂▂▅▅▆▅▅▅▇▇█▇▆▇▇▇█
wandb:          test_precision0.5 ▁▁▅▆▆▆▅▅▆▆▆▆▇▆▅▆▆▆▇▇▆▇█▇▇▇▇▇▇▇▇█▇██████▇
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▆▄▆▇██▆▇
wandb:            test_recall0.25 ████████████████▇▇▇▇▃▁▁▁▁▁▁▁▁▂▂▂▁▂▁▁▁▁▁▁
wandb:             test_recall0.5 ▁███▇▄▄▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▆▆▆█▆██
wandb:                train_auroc ▁▁▂▂▂▂▂▂▃▃▃▄▄▄▅▄▅▅▅▅▆▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇████
wandb:                 train_loss ██████████▇▇▇▇▇▆▆▅▅▅▅▅▅▅▅▄▄▄▃▄▃▃▂▂▂▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▂▂▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇█
wandb:            val_accuracy0.5 ██▇▁▁▂▂▄▆▅▅▅▅▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▄▅▄▅▅▅▅▅
wandb:           val_accuracy0.75 ██████████▃▁▁▁▁▃▃▃▃▃▃▃▁▃▃▅▅▅▆▅▆▆▆▆████▆▆
wandb:                  val_auroc ██▇▇▇▇▇▆▅▄▄▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄
wandb:  val_balanced_accuracy0.25 ▇▇▇▇▇▇▇▇▇▇█████▇▇▅▄▄▁▁▂▂▂▄▄▃▃▄▄▁▃▄▄▁▄▄▅▅
wandb:   val_balanced_accuracy0.5 ▄▃▅▆▆▆▅▇██▅▅▅▅▅▅▄▄▂▁▁▁▂▂▂▃▄▄▄▄▃▃▃▄▄▄▄▅▅▄
wandb:  val_balanced_accuracy0.75 ▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁▃▄▄▄▄▄▄▄▅▅▆▇▇▇▆▆█████▇
wandb:          val_precision0.25 ███████████████▅▅▅▃▃▄▂▁▃▃▃▃▃▄▂▃▄▄▄▆▂▃▂▃▆
wandb:           val_precision0.5 █▇▆▆▅▆▇▇▇▇▇▇▅▁▂▃▃▃▄▄▄▅▅▅▄▅▄▄▅▅▅▅▅▆▆▅▆▆▆▆
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▅▅▅▅▅▆▆▆▆▆█▇▇▇██▇▇▇
wandb:             val_recall0.25 ███████████████▇▇▇▇▇▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb:              val_recall0.5 ▁██▇▆▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▅▅
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▂▄▅▅▅▅▇▇▇▇▇▇▇██████
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.49367
wandb:           test_accuracy0.5 0.65823
wandb:          test_accuracy0.75 0.72152
wandb:                 test_auroc 0.57373
wandb: test_balanced_accuracy0.25 0.56186
wandb:  test_balanced_accuracy0.5 0.57288
wandb: test_balanced_accuracy0.75 0.53263
wandb:         test_precision0.25 0.29167
wandb:          test_precision0.5 0.34783
wandb:         test_precision0.75 0.375
wandb:            test_recall0.25 0.7
wandb:             test_recall0.5 0.4
wandb:            test_recall0.75 0.15
wandb:                train_auroc 0.96723
wandb:                 train_loss 0.77183
wandb:           val_accuracy0.25 0.45714
wandb:            val_accuracy0.5 0.60952
wandb:           val_accuracy0.75 0.73333
wandb:                  val_auroc 0.4983
wandb:  val_balanced_accuracy0.25 0.45862
wandb:   val_balanced_accuracy0.5 0.52118
wandb:  val_balanced_accuracy0.75 0.55185
wandb:          val_precision0.25 0.21818
wandb:           val_precision0.5 0.27273
wandb:          val_precision0.75 0.41667
wandb:             val_recall0.25 0.46154
wandb:              val_recall0.5 0.34615
wandb:             val_recall0.75 0.19231
wandb: 
wandb: 🚀 View run vgg16_2d_79_14_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/rj7f04p7
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_14/wandb/run-20250702_081930-rj7f04p7/logs
/nas-ctm01/homes/mipaiva/.conda/envs/pipeline/lib/python3.11/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:100: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout
  A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.7)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:114: UserWarning: Argument(s) 'mean' are not valid for transform GaussNoise
  A.GaussNoise(std_range= (0.1, 0.15), mean = (0.0, 0.0), p=1.0), # Introduces too much noise
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:41: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform
  super().__init__(always_apply=always_apply, p=p)
/nas-ctm01/homes/mipaiva/pipeline_template_pl/src/modules/data/data_augmentation/ct_image_augmenter.py:133: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion
  A.OpticalDistortion(distort_limit=0.2, shift_limit=0.0, p=0.7)
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_14/execution_datetimes.json

**************************************************  Experiment 79 | Version 15 **************************************************
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']

✅ Saved split assignments to 'lung_metadata_with_splits.csv'

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

Using regular DataLoader for train subset
Data Aug
Original shape: 210, New Shape: 316

✅ Set train dataloaders with 3 folds
  - Fold 1: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 36, 1.0: 28}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 31, 1.0: 33}
    Batch label distribution: {0.0: 32, 1.0: 32}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 2: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 29, 1.0: 35}
    Batch label distribution: {0.0: 33, 1.0: 31}
    Batch label distribution: {0.0: 30, 1.0: 30}
  - Fold 3: 316 samples
    Label distribution: {0: 158, 1: 158}
    Batch label distribution: {0.0: 27, 1.0: 37}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 35, 1.0: 29}
    Batch label distribution: {0.0: 26, 1.0: 34}

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

Using regular DataLoader for validation subset

✅ Set validation dataloaders with 3 folds
  - Fold 1: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 30, 1.0: 11}
  - Fold 2: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 52, 1.0: 12}
    Batch label distribution: {0.0: 27, 1.0: 14}
  - Fold 3: 105 samples
    Label distribution: {0: 79, 1: 26}
    Batch label distribution: {0.0: 48, 1.0: 16}
    Batch label distribution: {0.0: 31, 1.0: 10}

Using regular DataLoader for test subset

Using regular DataLoader for test subset

Using regular DataLoader for test subset

✅ Set test dataloaders with 3 folds
  - Fold 1: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 2: 79 samples
    Label distribution: {0: 59, 1: 20}
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}
  - Fold 3: 79 samples
    Label distribution: {0: 59, 1: 20}
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_15/wandb/run-20250702_092734-icqe4k5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_15_fold1
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/icqe4k5b
    Batch label distribution: {0.0: 49, 1.0: 15}
    Batch label distribution: {0.0: 10, 1.0: 5}

Running model pipeline for data fold 1...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▄▇▇▅▇██
wandb:           test_accuracy0.5 ▂▂▁▁▁▃▃▃▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:                 test_auroc ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇███
wandb: test_balanced_accuracy0.25 ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆███▃▃▃▃▃▃▁▁▃▃▆
wandb:  test_balanced_accuracy0.5 ▆█▄▄▆█▁▃▆▇▂▄▂▂▂▃▂▃▂▂▄▃▄▄▄▂▂▃▃▄▄██▆▆▆▆▂▄█
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████
wandb:         test_precision0.25 ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆████▅▅▅▅▅▅▆▇▇▁▁▇
wandb:          test_precision0.5 ▅▅▅▅▄▃▄▃▃▃▃▃▃▃▃▃▃▃▄▃▁▁▂▃▂▄▄▄▄███▆▆▆▆▂▁▂█
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:            test_recall0.25 ████████████████████████▆▆▆▆▆▆▆▆▆▆▁▁▁▁▁▁
wandb:             test_recall0.5 ▃▇████████▇▇▆▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:                train_auroc ▂▂▁▂▂▁▂▂▁▂▂▃▂▂▃▃▃▂▃▂▃▃▃▃▄▄▄▄▅▄▅▇▇▇▇▇▇▇██
wandb:                 train_loss ██████▇▇▇▇▆▆▆▅▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▅▆▆█▇██▇▇▇▇▆
wandb:            val_accuracy0.5 ▂▁▁▂▂▂▂▃▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:           val_accuracy0.75 ███████████████████████████████████▁▅▅▅█
wandb:                  val_auroc ▁▇▇▇██▇▆▆▅▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇█
wandb:  val_balanced_accuracy0.25 ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▅▆▆▄▃▁
wandb:   val_balanced_accuracy0.5 ▅▃▁▄▅▇▇▇▇▆▇▇█▇▄▃▂▅▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▇▇▇▇▇▇▇
wandb:  val_balanced_accuracy0.75 ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▂▂▁▂▂▂▂▂▆█▇
wandb:          val_precision0.25 ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇███████▇▅▅▂▃▁
wandb:           val_precision0.5 ▅▆▆▆▆▅▁▂▁▁▂▃▄▅▄▄▄▄▄▄▅▅▄▄▄▄▄▄▄▄▂▂▃▃▇▇▆▆██
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:             val_recall0.25 ████████████████████████████████▇▇▆▆▆▅▄▁
wandb:              val_recall0.5 ▁▁▁█████▆▅▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅█
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.32911
wandb:           test_accuracy0.5 0.6962
wandb:          test_accuracy0.75 0.75949
wandb:                 test_auroc 0.62712
wandb: test_balanced_accuracy0.25 0.50127
wandb:  test_balanced_accuracy0.5 0.51568
wandb: test_balanced_accuracy0.75 0.525
wandb:         test_precision0.25 0.25373
wandb:          test_precision0.5 0.3
wandb:         test_precision0.75 1
wandb:            test_recall0.25 0.85
wandb:             test_recall0.5 0.15
wandb:            test_recall0.75 0.05
wandb:                train_auroc 0.88774
wandb:                 train_loss 1.33368
wandb:           val_accuracy0.25 0.29524
wandb:            val_accuracy0.5 0.6381
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.4445
wandb:  val_balanced_accuracy0.25 0.41553
wandb:   val_balanced_accuracy0.5 0.51436
wandb:  val_balanced_accuracy0.75 0.5258
wandb:          val_precision0.25 0.20732
wandb:           val_precision0.5 0.26923
wandb:          val_precision0.75 0.5
wandb:             val_recall0.25 0.65385
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.07692
wandb: 
wandb: 🚀 View run vgg16_2d_79_15_fold1 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/icqe4k5b
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_15/wandb/run-20250702_092734-icqe4k5b/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_15/wandb/run-20250702_104434-n2qcui9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_15_fold2
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/n2qcui9y
...model pipeline for data fold 1 has run!

Running model pipeline for data fold 2...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb: Finishing previous runs because reinit is set to True.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           test_accuracy0.5 █████████▇▇▆▆▆▅▅▃▃▄▄▃▃▃▂▂▂▁▁▁▁▁▂▂▂▂▁▁▂▂▂
wandb:          test_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 test_auroc ▁▂▂▄▅▇██▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb: test_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  test_balanced_accuracy0.5 ▄▄▄▄▄▄▄▄▄▄▄▃▃▃▂▃▂▁▆▆▇▆▇▇▇▆▆███▇▇▇▇▇█▆▆▆▆
wandb: test_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         test_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          test_precision0.5 ▁▁▁▁▁▁▁▁▁▁▁▅▃▅▅▅▄▅▆███▇▇█▇▇▇▇▇▇█████▇▇▇▇
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▄▄▅▅▇▇▇██████████████▇▇▇
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_auroc ▁▄▅▆▆▇▇███████▇▇▇█▇██▇▇▇▇▇▇▆▇▇▆▆▇▇▇▆▆▇▇▇
wandb:                 train_loss ██████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▅▄▄▄▃▃▃▂▂▂▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            val_accuracy0.5 ███████████▇▆▆▆▅▄▃▃▃▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb:           val_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  val_auroc ▂▂▁▂▂▆▆▆▇▇▇▇▇▇▇▇████████████████████████
wandb:  val_balanced_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_balanced_accuracy0.5 ▅▅▅▅▅▅▅▅▅▅▅▅▄▄▃▃▁▄▅▄▆▅▅▅▅▆▆████████▇▇▇█▇
wandb:  val_balanced_accuracy0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          val_precision0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           val_precision0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▄▃▄▄▄▆▇▇▇▇▇▇▇▇▇████████████
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_recall0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              val_recall0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▆▆▆▆▆▆█████████████▇
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.25316
wandb:           test_accuracy0.5 0.59494
wandb:          test_accuracy0.75 0.74684
wandb:                 test_auroc 0.54153
wandb: test_balanced_accuracy0.25 0.5
wandb:  test_balanced_accuracy0.5 0.54703
wandb: test_balanced_accuracy0.75 0.5
wandb:         test_precision0.25 0.25316
wandb:          test_precision0.5 0.3
wandb:         test_precision0.75 0
wandb:            test_recall0.25 1
wandb:             test_recall0.5 0.45
wandb:            test_recall0.75 0
wandb:                train_auroc 0.74912
wandb:                 train_loss 1.98409
wandb:           val_accuracy0.25 0.24762
wandb:            val_accuracy0.5 0.55238
wandb:           val_accuracy0.75 0.75238
wandb:                  val_auroc 0.53944
wandb:  val_balanced_accuracy0.25 0.5
wandb:   val_balanced_accuracy0.5 0.53481
wandb:  val_balanced_accuracy0.75 0.5
wandb:          val_precision0.25 0.24762
wandb:           val_precision0.5 0.2766
wandb:          val_precision0.75 0
wandb:             val_recall0.25 1
wandb:              val_recall0.5 0.5
wandb:             val_recall0.75 0
wandb: 
wandb: 🚀 View run vgg16_2d_79_15_fold2 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/n2qcui9y
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_15/wandb/run-20250702_104434-n2qcui9y/logs
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_15/wandb/run-20250702_110040-zce0awwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vgg16_2d_79_15_fold3
wandb: ⭐️ View project at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: 🚀 View run at https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/zce0awwc
...model pipeline for data fold 2 has run!

Running model pipeline for data fold 3...
Label column '5y' found in metadata. Available columns: ['pid', 'study_yr', 'path', 'sct_slice_num_og', 'stage', '1y', '2y', '5y', '10y', 'fup_days', 'lung_side', 'de_stag', 'de_stag_7thed', 'sct_slice_new', 'sct_nod_err']
Label weights: tensor([3.0204], device='cuda:0', dtype=torch.float64)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          test_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▄▄▆▆▆▆▆███▇
wandb:           test_accuracy0.5 ████▇▂▂▁▁▂▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇
wandb:          test_accuracy0.75 ██████████████████████████████████▆▃▃▃▃▁
wandb:                 test_auroc ▁▃▄▄▄▅▅▅▆▆▆▆▆▅▆▅▅▅▅▅▄▄▅▄▄▅▅▅▆▆▇▇▇▇▇█████
wandb: test_balanced_accuracy0.25 ▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇█▃▄▅▆▆▆▃▄▅▄▅▁▁▁▁▁▁▃▃▃
wandb:  test_balanced_accuracy0.5 ▆▆▂▁▁▂▃▄▅▄▅▄▄▄▄▄▄▄▄▅▅▅▅▄▄▄▄▄▅▅▅▇▇▇▇▇███▇
wandb: test_balanced_accuracy0.75 ████████████████████████████████▆▃▆▃▃▃▃▁
wandb:         test_precision0.25 ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▅▅▆▆▆▆▅▅▆▄▁▁▁▁▂▂▂▂▂▃
wandb:          test_precision0.5 ▃▂▃▂▃▂▂▂▃▃▁▂▂▂▃▁▂▅▁▁▁▁▂▅▇▇▆▆▆▆▆▆▆██▇▇▅▇▅
wandb:         test_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test_recall0.25 ██████████████████████▆▆▆▆▆▆▆▆▅▃▃▁▁▁▁▁▁▁
wandb:             test_recall0.5 ▁▁███▇▇▇▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁
wandb:                train_auroc ▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▃▃▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████
wandb:                 train_loss █████▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▃▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:           val_accuracy0.25 ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▂▂▂▃▃▃▂▄▅▄▄▅▇████
wandb:            val_accuracy0.5 ▇▃▃▂▂▁▁▁▁▁▄▅▇███████▆▆▆▆▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:           val_accuracy0.75 ██████████████▆▆▆▅▅▃▃▃▃▁▁▁▁▁▁▁▁▁▃▃▃▁▁▁▅▅
wandb:                  val_auroc ▇▇██████▇▆▆▆▆▆▆▅▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂
wandb:  val_balanced_accuracy0.25 ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▅▂▂▂▂▁▁▂▃▃▂▃▄▅▅▅▄▄▅▅
wandb:   val_balanced_accuracy0.5 ▃▁▆▆▆█▇▇▇▇▅▅▅▇█▇▆▄▅▄▅▅▃▂▂▂▂▂▁▂▃▃▃▄▄▄▃▃▄▄
wandb:  val_balanced_accuracy0.75 ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▄▄▄▅▅███
wandb:          val_precision0.25 ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▃▂▂▂▁▂▂▁▁▄▃▄▄▅▅▃▅▄▄
wandb:           val_precision0.5 ▅▅▅▅▄▄▄▃▄▄▄▆▆▇▆█▅▂▂▂▂▂▂▂▂▁▁▁▂▂▃▃▄▄▃▄▃▄▄▄
wandb:          val_precision0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▄▄▆▆███
wandb:             val_recall0.25 ████████████████████▇▇▇▆▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:              val_recall0.5 ▁▃████▇▇▆▆▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:             val_recall0.75 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▆███
wandb: 
wandb: Run summary:
wandb:          test_accuracy0.25 0.35443
wandb:           test_accuracy0.5 0.64557
wandb:          test_accuracy0.75 0.70886
wandb:                 test_auroc 0.52627
wandb: test_balanced_accuracy0.25 0.46864
wandb:  test_balanced_accuracy0.5 0.53136
wandb: test_balanced_accuracy0.75 0.47458
wandb:         test_precision0.25 0.23729
wandb:          test_precision0.5 0.3
wandb:         test_precision0.75 0
wandb:            test_recall0.25 0.7
wandb:             test_recall0.5 0.3
wandb:            test_recall0.75 0
wandb:                train_auroc 0.90971
wandb:                 train_loss 1.20112
wandb:           val_accuracy0.25 0.39048
wandb:            val_accuracy0.5 0.65714
wandb:           val_accuracy0.75 0.73333
wandb:                  val_auroc 0.47639
wandb:  val_balanced_accuracy0.25 0.45302
wandb:   val_balanced_accuracy0.5 0.52702
wandb:  val_balanced_accuracy0.75 0.52605
wandb:          val_precision0.25 0.22059
wandb:           val_precision0.5 0.29167
wandb:          val_precision0.75 0.375
wandb:             val_recall0.25 0.57692
wandb:              val_recall0.5 0.26923
wandb:             val_recall0.75 0.11538
wandb: 
wandb: 🚀 View run vgg16_2d_79_15_fold3 at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da/runs/zce0awwc
wandb: ⭐️ View project at: https://wandb.ai/maria-i-paiva-inesc-tec/cs_vgg_lung_da
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_15/wandb/run-20250702_110040-zce0awwc/logs
...model pipeline for data fold 3 has run!
Saving execution datetimes to /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_79/version_15/execution_datetimes.json
Finish time: 2025-07-02 12:20:21
