_wandb:
    value:
        cli_version: 0.19.11
        m: []
        python_version: 3.11.11
        t:
            "1":
                - 1
                - 5
                - 9
                - 41
                - 48
                - 50
                - 53
                - 55
                - 80
                - 103
            "2":
                - 1
                - 5
                - 9
                - 41
                - 48
                - 50
                - 53
                - 55
                - 80
                - 103
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.11.11
            "5": 0.19.11
            "8":
                - 5
            "10":
                - 20
            "12": 0.19.11
            "13": linux-x86_64
data:
    value: '{''dataset_name'': ''NLST'', ''data_preprocessing_protocol_number'': 4, ''dimension'': 2.5, ''dataloader'': {''dataset_name'': ''${..dataset_name}'', ''data_preprocessing_protocol_number'': ''${..data_preprocessing_protocol_number}'', ''data_type'': ''${..metadataframe.data_type}'', ''data_augmentation'': {''apply'': False, ''augmented_to_original_data_ratio'': 2, ''parameters'': {''number_of_augmentations'': 3, ''random_rotation_degrees'': 10, ''random_translation_fraction'': 0.1, ''random_brightness_intensity_factor'': 0.3, ''random_contrast_intensity_factor'': 0.3, ''random_gaussian_blur'': {''kernel_size'': [3, 3], ''sigma'': [0.1, 1.0]}, ''random_gaussian_noise_variance'': 0.001, ''random_elastic_alpha'': 10.0, ''random_elastic_sigma'': 5.0}}, ''image_numpy_arrays_dir_path'': ''${...experiment_execution.paths.preprocessed_data_dir_path}/protocol_${..data_preprocessing_protocol_number}/${..metadataframe.data_type}_numpy_arrays'', ''number_of_k_folds'': 0, ''seed_value'': ''${...seed_value}'', ''test_fraction_of_entire_dataset'': 0.2, ''torch_dataloader_kwargs'': {''batch_size'': 4, ''num_workers'': 14}, ''validation_fraction_of_train_set'': 0.1, ''dimension'': ''${..dimension}'', ''roi'': ''lung'', ''resample'': False, ''resample_z'': False}, ''metadataframe'': {''dataset_name'': ''${..dataset_name}'', ''data_preprocessing_protocol_number'': ''${..data_preprocessing_protocol_number}'', ''data_type'': ''whole_slice'', ''label'': ''5y'', ''resample'': False, ''dimension'': ''${..dimension}''}}'
experiment_execution:
    value: '{''ids'': {''experiment_id'': 96, ''experiment_version_id'': 1}, ''info'': {''who'': ''Maria Amaro'', ''what'': ''ResNEt502d''}, ''paths'': {''experiment_dir_path'': ''/nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_96'', ''experiment_version_dir_path'': ''/nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_96/version_1'', ''preprocessed_data_dir_path'': ''/nas-ctm01/datasets/public/medical_datasets/lung_ct_datasets/nlst/preprocessed_data'', ''python_project_dir_path'': ''/nas-ctm01/homes/mipaiva/pipeline_template_pl''}}'
hyperparameter_grid_based_execution:
    value: '{''apply'': True, ''hyperparameter_combination'': {''index'': 1, ''used'': {''model.pytorch_lightning_model.hyperparameters.optimiser.kwargs.lr'': 0.001, ''data.dataloader.torch_dataloader_kwargs.batch_size'': 4, ''seed_value'': 1}}, ''hyperparameter_grid'': {''model.pytorch_lightning_model.hyperparameters.optimiser.kwargs.lr'': [0.001, 0.0001, 1e-05], ''data.dataloader.torch_dataloader_kwargs.batch_size'': [4, 8, 16, 32], ''seed_value'': [1]}}'
model:
    value: '{''model_id'': ''VGG16'', ''model_name'': ''VGG16'', ''dimension'': ''${..data.dimension}'', ''model_pipeline'': {''model_id'': ''${..model_id}'', ''model_name'': ''${..model_name}'', ''callbacks'': {''model_checkpoints'': [{''monitor'': ''val_auroc'', ''filename'': ''mod=${....model_id}-exp=X-ver=Y-dtf=Z-{epoch}-var={${.monitor}:.3f}'', ''mode'': ''max'', ''save_top_k'': 1}, {''monitor'': ''val_loss'', ''filename'': ''mod=${....model_id}-exp=X-ver=Y-dtf=Z-{epoch}-var={${.monitor}:.3f}'', ''mode'': ''min'', ''save_top_k'': 1}, {''filename'': ''mod=${....model_id}-exp=X-ver=Y-dtf=Z-{epoch}-var=last_epoch''}], ''model_early_stoppings'': [{''monitor'': ''val_auroc'', ''patience'': 15, ''mode'': ''max'', ''verbose'': False}]}, ''enable_logging'': True, ''enable_model_early_stopping'': True, ''finalization'': {''delete_model_checkpoints'': True, ''save_used_data_file_names'': True}, ''pytorch_lightning_model'': ''${..pytorch_lightning_model}'', ''pytorch_lightning_trainer_kwargs'': {''accelerator'': ''gpu'', ''enable_checkpointing'': True, ''enable_model_summary'': False, ''enable_progress_bar'': False, ''log_every_n_steps'': 1, ''min_epochs'': 0, ''max_epochs'': 200}}, ''pytorch_lightning_model'': {''model_id'': ''${..model_id}'', ''model_name'': ''${..model_name}'', ''hyperparameters'': {''device'': ''cuda'', ''number_of_classes'': 2, ''optimiser'': {''type'': ''Adam'', ''kwargs'': {''lr'': 0.001}}, ''criterion'': {''apply_weights'': True, ''device'': ''${..device}'', ''metadataframe'': ''${.....data.metadataframe}''}, ''model'': {''number_of_classes'': 2, ''dimension'': ''${....dimension}''}}}}'
results_analysis:
    value: '{''model_test_performance_metrics_dataframe'': {''monitored_variables'': [''val_auroc'', ''val_loss'', ''last_epoch'']}, ''model_training_performance_metrics_figure'': {''maximum_number_of_epochs'': ''${...model.model_pipeline.pytorch_lightning_trainer_kwargs.max_epochs}''}}'
seed_value:
    value: 1
wandb:
    value: '{''project_name'': ''comparative_study_25_norm'', ''entity'': ''nlst'', ''name'': ''vgg16_25d''}'
