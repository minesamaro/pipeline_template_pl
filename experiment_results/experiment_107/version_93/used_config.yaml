data:
  dataset_name: NLST
  data_preprocessing_protocol_number: 4
  dimension: 2.5
  resize: false
  dataloader:
    dataset_name: NLST
    data_preprocessing_protocol_number: 4
    data_type: whole_slice
    data_augmentation:
      apply: false
      augmented_to_original_data_ratio: 2
      parameters:
        number_of_augmentations: 3
        random_rotation_degrees: 10
        random_translation_fraction: 0.1
        random_brightness_intensity_factor: 0.3
        random_contrast_intensity_factor: 0.3
        random_gaussian_blur:
          kernel_size:
          - 3
          - 3
          sigma:
          - 0.1
          - 1.0
        random_gaussian_noise_variance: 0.001
        random_elastic_alpha: 10.0
        random_elastic_sigma: 5.0
    image_numpy_arrays_dir_path: /nas-ctm01/datasets/public/medical_datasets/lung_ct_datasets/nlst/preprocessed_data/protocol_4/whole_slice_numpy_arrays
    number_of_k_folds: 0
    seed_value: 1
    test_fraction_of_entire_dataset: 0.2
    torch_dataloader_kwargs:
      batch_size: 64
      num_workers: 14
    validation_fraction_of_train_set: 0.1
    dimension: 2.5
    resize: false
    roi: lung
    resample: false
    resample_z: false
  metadataframe:
    dataset_name: NLST
    data_preprocessing_protocol_number: 4
    data_type: whole_slice
    label: 5y
    resample: false
    dimension: 2.5
experiment_execution:
  ids:
    experiment_id: 107
    experiment_version_id: 93
  info:
    who: Maria Amaro
    what: ResNEt502d
  paths:
    experiment_dir_path: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_107
    experiment_version_dir_path: /nas-ctm01/homes/mipaiva/pipeline_template_pl/experiment_results/experiment_107/version_93
    preprocessed_data_dir_path: /nas-ctm01/datasets/public/medical_datasets/lung_ct_datasets/nlst/preprocessed_data
    python_project_dir_path: /nas-ctm01/homes/mipaiva/pipeline_template_pl
hyperparameter_grid_based_execution:
  apply: true
  hyperparameter_combination:
    index: 5
    used:
      model.pytorch_lightning_model.hyperparameters.optimiser.kwargs.lr: 0.001
      data.dataloader.torch_dataloader_kwargs.batch_size: 64
      seed_value: 1
  hyperparameter_grid:
    model.pytorch_lightning_model.hyperparameters.optimiser.kwargs.lr:
    - 0.001
    - 0.0001
    - 1.0e-05
    data.dataloader.torch_dataloader_kwargs.batch_size:
    - 4
    - 8
    - 16
    - 32
    - 64
    seed_value:
    - 1
model:
  model_id: VGG16
  model_name: VGG16
  dimension: 2.5
  model_pipeline:
    model_id: VGG16
    model_name: VGG16
    callbacks:
      model_checkpoints:
      - monitor: val_auroc
        filename: mod=VGG16-exp=X-ver=Y-dtf=Z-{epoch}-var={val_auroc:.3f}
        mode: max
        save_top_k: 1
      - monitor: val_loss
        filename: mod=VGG16-exp=X-ver=Y-dtf=Z-{epoch}-var={val_loss:.3f}
        mode: min
        save_top_k: 1
      - filename: mod=VGG16-exp=X-ver=Y-dtf=Z-{epoch}-var=last_epoch
      model_early_stoppings:
      - monitor: val_auroc
        patience: 15
        mode: max
        verbose: false
    enable_logging: true
    enable_model_early_stopping: true
    finalization:
      delete_model_checkpoints: true
      save_used_data_file_names: true
    pytorch_lightning_model:
      model_id: VGG16
      model_name: VGG16
      hyperparameters:
        device: cuda
        number_of_classes: 2
        optimiser:
          type: Adam
          kwargs:
            lr: 0.001
        criterion:
          apply_weights: true
          device: cuda
          metadataframe:
            dataset_name: NLST
            data_preprocessing_protocol_number: 4
            data_type: whole_slice
            label: 5y
            resample: false
            dimension: 2.5
        model:
          number_of_classes: 2
          dimension: 2.5
    pytorch_lightning_trainer_kwargs:
      accelerator: gpu
      enable_checkpointing: true
      enable_model_summary: false
      enable_progress_bar: false
      log_every_n_steps: 1
      min_epochs: 0
      max_epochs: 200
  pytorch_lightning_model:
    model_id: VGG16
    model_name: VGG16
    hyperparameters:
      device: cuda
      number_of_classes: 2
      optimiser:
        type: Adam
        kwargs:
          lr: 0.001
      criterion:
        apply_weights: true
        device: cuda
        metadataframe:
          dataset_name: NLST
          data_preprocessing_protocol_number: 4
          data_type: whole_slice
          label: 5y
          resample: false
          dimension: 2.5
      model:
        number_of_classes: 2
        dimension: 2.5
results_analysis:
  model_test_performance_metrics_dataframe:
    monitored_variables:
    - val_auroc
    - val_loss
    - last_epoch
  model_training_performance_metrics_figure:
    maximum_number_of_epochs: 200
seed_value: 1
wandb:
  project_name: comparative_study_25_norm_resize
  entity: nlst
  name: vgg16_25d
